{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d629e794-1413-4cc0-ac83-5b13ff0382fb",
   "metadata": {},
   "source": [
    "# TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e7686b-cf3a-43ca-9e70-f4ef524801ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from sksurv.util import Surv\n",
    "# from sksurv.metrics import concordance_index_ipcw, concordance_index_censored\n",
    "\n",
    "# models \n",
    "import lifelines\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# others\n",
    "from numpy import inf\n",
    "from random import sample, seed\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "import itertools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "from lifelines.utils import concordance_index\n",
    "import sys \n",
    "import os\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment',  None)\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f2daea-e10f-4d92-b9b1-dde6a565fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import copy\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_error,brier_score_loss\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926db770-3f52-4918-8dbb-e75d2029320c",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1bb9fd-9016-4179-8ca5-be70c4612f27",
   "metadata": {},
   "source": [
    "## id_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afcbfbe-06cd-4766-9c5a-505fa061a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given list of IDs, split ids into train with p proportion\n",
    "# return list of train id and test id\n",
    "def id_train_test_split(id_list, seed_number = 1, p=0.7) :\n",
    "    id_list = np.unique(id_list)\n",
    "    \n",
    "    n_train = round(len(id_list)*0.7)\n",
    "    n_test = len(id_list) - n_train\n",
    "    \n",
    "    # IDs within train set and test set\n",
    "    seed(seed_number)\n",
    "    train_id = list(sample(set(id_list), n_train))\n",
    "    test_id = list(set(id_list).difference(set(train_id)))\n",
    "    return train_id, test_id\n",
    "    \n",
    "# Train_test split of rows example) \n",
    "## train = data[data[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "## test = data[data[ID_col].isin(test_id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df5b02-1f17-4398-9c78-8b13989510a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a18fce7-cb7d-48e4-90c5-63d868652f72",
   "metadata": {},
   "source": [
    "## id_bootstrapping_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c9da63-10de-47e9-8c74-3a7dd152d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_bootstrapping_split(id_list, seed_number) :\n",
    "    return inbag_id_count, outbag_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6690e6f-97a4-4009-8f35-3a9469d1b7c2",
   "metadata": {},
   "source": [
    "## id_kfold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5230f66-93e2-40a1-a523-893391d4c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given list of IDs, split ids into k-fold train/validation set \n",
    "class id_kfold :\n",
    "    def __init__(self,id_list, n_split,seed_number=1) : \n",
    "        self.id_list = np.unique(id_list)\n",
    "        self.n_split = n_split\n",
    "        self.seed_number=  seed_number\n",
    "\n",
    "        self.kf = KFold(n_splits = n_split, shuffle =True, random_state = seed_number)\n",
    "        \n",
    "        self.n_iter = 0 # initializing iteration\n",
    "        \n",
    "        train_fold_id = [] ; validation_fold_id = []\n",
    "        for train_unique_id_idx, validation_unique_id_idx in self.kf.split(self.id_list) :\n",
    "                train_fold_id.append(self.id_list[train_unique_id_idx])\n",
    "                validation_fold_id.append(self.id_list[validation_unique_id_idx])\n",
    "\n",
    "        self.train_fold_id = train_fold_id\n",
    "        self.validation_fold_id = validation_fold_id\n",
    "        \n",
    "        return\n",
    "                \n",
    "    def __iter__(self) : \n",
    "        return \n",
    "    \n",
    "    def __next__(self) : \n",
    "        if self.n_iter > self.n_split :\n",
    "            raise StopIteration\n",
    "            \n",
    "        else :\n",
    "            self.n_iter += 1\n",
    "            return self.train_fold_id[self.n_iter-1], self.validation_fold_id[self.n_iter-1]\n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0354ee8-f304-4611-9859-e9dfb0a1c184",
   "metadata": {},
   "source": [
    "## landmarker_cont & landmarker_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d03254-8e67-4c66-8507-bf06b0c9f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given original form of data,\n",
    "# Return landmarked dataset in continuous form\n",
    "def landmarker_cont(data,ID_col, T_col,E_col,window,S,measure_T_col) :\n",
    "    super_set = pd.DataFrame()\n",
    "    \n",
    "    for t in S :\n",
    "        # LM point 이후 생존자\n",
    "        # R_t_idx = np.where(data[T_col] > t )\n",
    "        R_t_idx = np.where( (data[T_col] > t ) & (data[measure_T_col] <= t ) )\n",
    "        R_t = data.loc[R_t_idx].reset_index(drop=True)\n",
    "        \n",
    "        # LM point - 변수로 지정. strata로 나중에 지정하려고\n",
    "        R_t['LM'] = t\n",
    "        \n",
    "        # time & event 수정 필요한 그룹. -> t+w 시점에서 censoring된 것으로 처리\n",
    "        occurance_out_index = np.where(R_t[T_col] > t+window)\n",
    "        for idx in occurance_out_index :\n",
    "            R_t.loc[idx,T_col] = t+window\n",
    "            R_t.loc[idx,E_col] = 0\n",
    "            \n",
    "        super_set = pd.concat([super_set,R_t],axis=0)\n",
    "        \n",
    "        # Leave only last measurements per each id & lm points\n",
    "        super_set = super_set.drop_duplicates([ID_col,'LM'],keep='last')\n",
    "        \n",
    "        # Time elapsed from measurement & LM time\n",
    "        super_set['diff'] = super_set['LM'] - super_set[measure_T_col]\n",
    "                \n",
    "    return  super_set.drop(columns = [measure_T_col], axis=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Given landmarked dataset in continuous form(output from Landmarker_cont),\n",
    "# Return discretized landmarked dataset.\n",
    "## Note that, if arg train == True, then \n",
    "def landmarker_disc(data,ID_col, T_col,E_col,window,S,measure_T_col, k_bin, train=True) :\n",
    "    super_set = data\n",
    "    discretized_set = pd.DataFrame()\n",
    "\n",
    "    for s in S :\n",
    "        temp = super_set[super_set['LM'] == s].reset_index(drop=True)\n",
    "        temp_bin = np.linspace(s, s+window, k_bin)\n",
    "\n",
    "        temp_digitize = np.digitize(temp[T_col],temp_bin, right =True)\n",
    "        temp['bin'] = temp_digitize    \n",
    "\n",
    "        \n",
    "        for i in range(temp.shape[0]) :\n",
    "            temp2 = temp.copy().iloc[i,:]\n",
    "            if train :\n",
    "                for j in range(1,temp_digitize[i]) :\n",
    "                    temp2['bin'] = j\n",
    "                    temp2[E_col] = 0\n",
    "                    discretized_set = pd.concat([discretized_set,temp2],axis=1)\n",
    "                    \n",
    "                temp2['bin'] = temp_digitize[i]\n",
    "                temp2[E_col] = temp.loc[i,E_col]\n",
    "                discretized_set = pd.concat([discretized_set,temp2],axis=1)\n",
    "                \n",
    "            else :\n",
    "                for j in range(1,k_bin) :\n",
    "                    temp2['bin'] = j\n",
    "                    temp2[E_col] = 0\n",
    "                    discretized_set = pd.concat([discretized_set,temp2],axis=1)\n",
    "                \n",
    "        \n",
    "    discretized_set = discretized_set.T\n",
    "    \n",
    "    return discretized_set.drop(columns = [T_col], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d5253-6d1d-402e-bce6-c5224cefc938",
   "metadata": {},
   "source": [
    "## set_hyperparams(model_specifics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40772cc-7cfc-48e6-9b8f-102293b5573f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d484d577-0abd-4eaa-a0af-b26c356a2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given model_specifics(dictionary)\n",
    "# Create list of model instances with hyperparameters from model_specifics(baseline)\n",
    "def set_hyperparams(model_specifics) :\n",
    "    model_list = []\n",
    "    for g_1 in range(model_specifics.shape[0]) : \n",
    "        model_name = model_specifics.loc[g_1,'model_name'] \n",
    "        model_hyperparams = model_specifics.loc[g_1,'hyperparams']\n",
    "        model_type = model_specifics.loc[g_1,'type']\n",
    "\n",
    "        param_combinations = list(itertools.product(*list(model_hyperparams.values())))\n",
    "        param_names = list(model_hyperparams.keys())\n",
    "\n",
    "        # change hyperparameters according to model_hyperparameter grid\n",
    "        for g_2 in range(len(param_combinations)) :\n",
    "            model_instance = deepcopy(model_specifics.loc[g_1,'model_instance'])\n",
    "            for param_idx in range(len(param_names)) :\n",
    "                setattr(model_instance, param_names[param_idx], param_combinations[g_2][param_idx])\n",
    "            model_list.append(model_instance)    \n",
    "    return model_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4496c-81a2-446c-896b-831da357c079",
   "metadata": {},
   "source": [
    "# CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740a3e4-15f3-47e7-8f6d-9fe133bfcfa8",
   "metadata": {},
   "source": [
    "## id_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02f972f-6ebc-487e-a965-3ad781ea3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given list of IDs, split ids into k-fold train/validation set \n",
    "class id_kfold :\n",
    "    def __init__(self,id_list, n_split,seed_number=1) : \n",
    "        self.id_list = np.unique(id_list)\n",
    "        self.n_split = n_split\n",
    "        self.seed_number=  seed_number\n",
    "\n",
    "        self.kf = KFold(n_splits = n_split, shuffle =True, random_state = seed_number)\n",
    "        \n",
    "        self.n_iter = 0 # initializing iteration\n",
    "        \n",
    "        train_fold_id = [] ; validation_fold_id = []\n",
    "        for train_unique_id_idx, validation_unique_id_idx in self.kf.split(self.id_list) :\n",
    "                train_fold_id.append(self.id_list[train_unique_id_idx])\n",
    "                validation_fold_id.append(self.id_list[validation_unique_id_idx])\n",
    "\n",
    "        self.train_fold_id = train_fold_id\n",
    "        self.validation_fold_id = validation_fold_id\n",
    "        \n",
    "        return\n",
    "                \n",
    "    def __iter__(self) : \n",
    "        return \n",
    "    \n",
    "    def __next__(self) : \n",
    "        if self.n_iter > self.n_split :\n",
    "            raise StopIteration\n",
    "            \n",
    "        else :\n",
    "            self.n_iter += 1\n",
    "            return self.train_fold_id[self.n_iter-1], self.validation_fold_id[self.n_iter-1]\n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c852bca-b307-4a5c-aad2-9e2867940248",
   "metadata": {},
   "source": [
    "## ipcw_fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9833bc7-dca1-45eb-919d-35604ebc0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit KaplanMeier model on each landmarking time point\n",
    "# return(predict) Inverse Probabliity of Censoring Weight(IPCW) * n(S) on any given dataset\n",
    "\n",
    "## Note : fit and predict method requires continous type of landmarking dataset. \n",
    "## Note2 : censoring될 확률이 높을수록(survival estimate from KM이 작을수록) -> (관측이 되었다면) 관측치의 weight 높아짐.\n",
    "class ipcw_fitter : \n",
    "    def __init__(self, S, window) : \n",
    "        self.S = S\n",
    "        self.window = window\n",
    "        self.censoring_model = [KaplanMeierFitter() for i in range(len(S))]\n",
    "        return\n",
    "    \n",
    "\n",
    "    # T, E, W 는 해당하는 각각 time, event indcicator, weight에 해당하는 칼럼 네임.\n",
    "    ## Note : 즉, bagging할 시 먼저 웨이트를 붙여서 들어와야 됨. \n",
    "    def fit(self, data, T, E, W = None) : \n",
    "        self.T = T\n",
    "        self.E = E\n",
    "        for i in range(len(self.S)) : \n",
    "            risk_set = data.loc[data['LM'] == self.S[i],]\n",
    "            \n",
    "            # Here, event is censoring, so indicator is reversed.\n",
    "            time = risk_set[T]; event = abs(risk_set[E]-1); \n",
    "            if W is  None : \n",
    "                self.censoring_model[i] = self.censoring_model[i].fit(durations = np.array(time), event_observed = np.array(event))\n",
    "            else :\n",
    "                weight = risk_set[W]\n",
    "                self.censoring_model[i] = self.censoring_model[i].fit(durations = time, event_observed = event, weights  = weight)\n",
    "        return \n",
    "    \n",
    "    def predict(self, data) : \n",
    "        eps = 0.000000001\n",
    "        n_S = [sum(data['LM']==s) for s in self.S]# number of risk sets on each landmark time point\n",
    "        \n",
    "        \n",
    "        ipcw_list = []\n",
    "        for i in range(data.shape[0]) : \n",
    "            lm_time = data['LM'][i]\n",
    "            lm_index= np.where(self.S==lm_time)[0][0]\n",
    "            \n",
    "            ipcw_list.append(1/(self.censoring_model[lm_index].predict(data[T_col][i]- eps) * n_S[lm_index]))\n",
    "        \n",
    "        ipcw_list = np.array(ipcw_list)\n",
    "        ipcw_list[(data[self.E]==0)&(data[self.T] < data['LM']+self.window)] = 0\n",
    "\n",
    "        return ipcw_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7072a-c86c-4002-8b9a-9b1bc01a30c4",
   "metadata": {},
   "source": [
    "## LM_cox_fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8fbf4e-828a-4cfc-ae9b-68410689de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : model and specifics\n",
    "# output : predicted v-year survival estimates\n",
    "class LM_cox_fitter :\n",
    "    def __init__(self, model, ID, T, E, S, window, degree= 2, stratified = False) : \n",
    "        self.model = deepcopy(model)\n",
    "        self.ID = ID\n",
    "        self.T = T\n",
    "        self.E = E\n",
    "        self.S = S\n",
    "        self.window = window\n",
    "        \n",
    "        self.degree = degree\n",
    "        self.stratified = stratified\n",
    "        \n",
    "    def fit(self, data, weight = None) : \n",
    "        \n",
    "        temp_data = deepcopy(data)        \n",
    "        x_cols = list(temp_data.columns)\n",
    "        x_cols.remove(self.ID);x_cols.remove(self.T);x_cols.remove(self.E);x_cols.remove('LM');x_cols.remove('diff')\n",
    "        self.x_cols = x_cols\n",
    "\n",
    "        # making interaction term between Xs and 1, ... , d degree LM terms\n",
    "        for i in range(len(x_cols)) : \n",
    "            for d in range(1,self.degree+1) : \n",
    "                col_name = x_cols[i] + '_' + str(d)\n",
    "                value = temp_data[x_cols[i]] * (temp_data['LM'])**d\n",
    "                temp_data[col_name] = value\n",
    "\n",
    "        # Add weight column\n",
    "        if weight is not None: \n",
    "            data['weight'] = weight\n",
    "            \n",
    "        if self.stratified :   \n",
    "            # default : landmarked time has 2nd degree relationship with baseline hazard\n",
    "            temp_data['LM_2'] = (temp_data['LM'])**2\n",
    "            \n",
    "            if weight is None : \n",
    "                self.model.fit(df = temp_data.drop([self.ID],axis=1), duration_col = self.T, event_col = self.E, robust =True) # no strata on LM\n",
    "            else : \n",
    "                self.model.fit(df = temp_data.drop([self.ID],axis=1), duration_col = self.T, event_col = self.E, wieghts_col = 'weight', robust =True) # no strata on LM\n",
    "        else : \n",
    "            if weight is None : \n",
    "                self.model.fit(df = temp_data.drop([self.ID],axis=1), duration_col = self.T, event_col = self.E, strata = ['LM']) # strata on LM\n",
    "            else :\n",
    "                self.model.fit(df = temp_data.drop([self.ID],axis=1), duration_col = self.T, event_col = self.E, strata = ['LM'], wieghts_col = 'weight', robust =True) # strata on LM\n",
    "                \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, data, v = None) : \n",
    "        if v == None : \n",
    "            v = self.window\n",
    "            \n",
    "        temp_data = deepcopy(data)        \n",
    "\n",
    "        # making interaction term between Xs and 1, ... , d degree LM terms\n",
    "        for i in range(len(self.x_cols)) : \n",
    "            for d in range(1,self.degree+1) : \n",
    "                col_name = self.x_cols[i] + '_' + str(d)\n",
    "                value = temp_data[self.x_cols[i]] * (temp_data['LM'])**d\n",
    "                temp_data[col_name] = value\n",
    "                \n",
    "        if self.stratified :   \n",
    "            # default : landmarked time has 2nd degree relationship with baseline hazard\n",
    "            temp_data['LM_2'] = (temp_data['LM'])**2\n",
    "            surv_est_mat = self.model.predict_survival_function(X = temp_data, times = self.S + v)\n",
    "        else : \n",
    "            surv_est_mat = self.model.predict_survival_function(X = temp_data, times = self.S + v)\n",
    "            \n",
    "        v_year = temp_data.LM + v\n",
    "\n",
    "        v_year_surv_prob = []\n",
    "        for idx in v_year.index : \n",
    "            value = surv_est_mat.loc[v_year[idx],idx]\n",
    "            v_year_surv_prob.append(value)\n",
    "            \n",
    "        return np.array(v_year_surv_prob)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76fc54-cad3-4161-9326-39f99a34c8f9",
   "metadata": {},
   "source": [
    "## LM_sklearn_fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1dbc023-a6e5-4b79-8979-b192557f28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : model and specifics\n",
    "# output : predicted v-year survival estimates\n",
    "class LM_sklearn_fitter : \n",
    "    def __init__(self, model, ID, E, k_bin) : \n",
    "        self.model = deepcopy(model)\n",
    "        self.ID = ID\n",
    "        self.E = E\n",
    "        self.k_bin = k_bin\n",
    "        \n",
    "        \n",
    "    def fit(self, data, weight = None) : \n",
    "        if weight is None : \n",
    "            self.model.fit(data.drop([self.E, self.ID], axis=1), data[self.E])\n",
    "        \n",
    "        else :\n",
    "            self.model.fit(data.drop([self.E, self.ID], axis=1), data[self.E], weight)\n",
    "                        \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, data) : \n",
    "        data = data.drop_duplicates(subset =[ID_col, 'LM'])\n",
    "\n",
    "        v_year_surv_prob=1\n",
    "        for i in range(1,self.k_bin) : \n",
    "            data['bin'] = i\n",
    "            v_year_surv_prob = v_year_surv_prob*self.model.predict_proba(data.drop([self.E, self.ID],axis=1))[:,0]\n",
    "\n",
    "        return np.array(v_year_surv_prob)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33dcf2f-09b7-4c45-a82b-6aa3e149b3e1",
   "metadata": {},
   "source": [
    "## nnls_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7069dee-dba8-4245-9607-e4af6a6463e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnls_constraint : \n",
    "    def __init__(self, tol = 10**(-5), max_iter = 10^5) : \n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def fit(self, x, y, w) : \n",
    "        n, k = x.shape\n",
    "        obj = lambda beta, y, x, w : np.dot(w.reshape(-1,), (np.array(y).reshape(-1, ) - x @ beta)**2)/n\n",
    "        \n",
    "        # bound(0-1) and constrant(beta sum to 1)\n",
    "        bnds = list(tuple(itertools.repeat((0,1),k)))\n",
    "        cons = [{\"type\": \"eq\", \"fun\": lambda beta: np.sum(beta) - 1}]\n",
    "\n",
    "        # Initial guess for betas\n",
    "        init = np.repeat(0,k)\n",
    "        \n",
    "        # minimization\n",
    "        res = minimize(obj, args=(y, x, w), x0=init, bounds=bnds, constraints=cons, tol = self.tol, options= {'maxiter':self.max_iter})\n",
    "        \n",
    "        self.coef_ = res.x\n",
    "        self.iter = res['nit']\n",
    "        self.score = res['fun']\n",
    "        self.res = res\n",
    "        \n",
    "        return \n",
    "\n",
    "    def predict(self, x) : \n",
    "        return x @ self.coef_\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459a61f-59cd-44e1-83e3-fa388470dac9",
   "metadata": {},
   "source": [
    "## hillclimb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5856827-41d5-473b-b6a8-6e7d22b89db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hillclimb : \n",
    "    def __init__(self, max_iter= 2000, early_stop_n = 50, early_stop_eps = 10**(-3)) : \n",
    "        self.max_iter = max_iter\n",
    "        self.early_stop_n = early_stop_n\n",
    "        self.early_stop_eps = early_stop_eps\n",
    "        return\n",
    "        \n",
    "    def fit(self, x, y, w) : \n",
    "        n, k = x.shape\n",
    "        coef_ = np.zeros(k)\n",
    "        \n",
    "        current_score = 10^10\n",
    "        \n",
    "        current_iter = 0; early_stop_iter = 0 \n",
    "        while (current_iter <= self.max_iter)&(early_stop_iter <= self.early_stop_n) :\n",
    "            \n",
    "            # search\n",
    "            next_scores = []\n",
    "            for i in range(k) : \n",
    "                temp_coef_ = copy.copy(coef_); temp_coef_[i] += 1\n",
    "                temp_score = brier_score_loss(y, x @ (temp_coef_ / sum(temp_coef_)),w)\n",
    "                next_scores.append(temp_score)\n",
    "            \n",
    "            \n",
    "            # update\n",
    "            next_score = min(next_scores)\n",
    "            \n",
    "            best_ind = next_scores.index(next_score)\n",
    "            coef_[best_ind] = coef_[best_ind]+1\n",
    "            \n",
    "            current_iter += 1\n",
    "            \n",
    "            if (current_score - next_score) > self.early_stop_eps :\n",
    "                early_stop_iter = 0 \n",
    "            else : \n",
    "                early_stop_iter += 1\n",
    "            \n",
    "            current_score = next_score\n",
    "        \n",
    "        self.coef_ = coef_ / sum(coef_)\n",
    "        self.iter = current_iter    \n",
    "        self.score = current_score\n",
    "            \n",
    "    def predict(self, x) : \n",
    "        return x @ self.coef_\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24b7ba-b9a1-4a34-a303-9812e12e55f4",
   "metadata": {},
   "source": [
    "## stacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5123686-f1ec-4e67-978e-4a5218a1609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacker :\n",
    "    def __init__(self, model_specifics, ID, T, E, S, window, k_bin) : \n",
    "        self.model_specifics = model_specifics\n",
    "        self.ID = ID\n",
    "        self.T = T\n",
    "        self.E = E\n",
    "        self.S = S\n",
    "        self.window = window\n",
    "        self.k_bin = k_bin \n",
    "        \n",
    "        self.model_list = [] # initializing model list\n",
    "        return\n",
    "    \n",
    "    # \n",
    "    def fit(self, data_cont, data_disc) : \n",
    "        new_model_list = []\n",
    "        for i in range(self.model_specifics.shape[0]) : \n",
    "            current_model_specifics = self.model_specifics.iloc[i:(i+1),:].reset_index(drop=True)\n",
    "            current_model_list = set_hyperparams(current_model_specifics) \n",
    "\n",
    "            current_model_name = current_model_specifics['model_name'][0]\n",
    "            current_model_type = current_model_specifics['type'][0]\n",
    "\n",
    "            # j for models in current_model_list \n",
    "            for j in range(len(current_model_list)) : \n",
    "                if current_model_type == 'cox_str' : \n",
    "                    fitter = LM_cox_fitter(model = current_model_list[j], ID = self.ID, T = self.T, E = self.E, \n",
    "                                           S = self.S, window = self.window, degree= 2, stratified = True)\n",
    "                    fitter.fit(data= data_cont)\n",
    "\n",
    "                elif current_model_type == 'cox_no_str' : \n",
    "                    fitter = LM_cox_fitter(model = current_model_list[j], ID = self.ID, T = self.T, E = self.E, \n",
    "                                           S = self.S, window = self.window, degree= 2, stratified = False)\n",
    "                    fitter.fit(data= data_cont)\n",
    "\n",
    "                else : \n",
    "                    fitter = LM_sklearn_fitter(model = current_model_list[j], ID = self.ID, E = self.E, k_bin = self.k_bin)\n",
    "                    fitter.fit(data= data_disc)\n",
    "                new_model_list.append(fitter)\n",
    "        \n",
    "        self.model_list = new_model_list\n",
    "                \n",
    "        return self.model_list\n",
    "    \n",
    "    def predict(self, data_cont, data_disc) :\n",
    "        stacked = []\n",
    "        for fitter in self.model_list : \n",
    "            module_tree = getattr(fitter.model,'__module__',None)\n",
    "            parent = module_tree.split('.')[0] if module_tree else None\n",
    "            \n",
    "            if parent == lifelines.__name__:\n",
    "                stacked.append(fitter.predict(data_cont))\n",
    "            else :\n",
    "                stacked.append(fitter.predict(data_disc))\n",
    "        \n",
    "        stacked = np.array(stacked).T\n",
    "        \n",
    "        return stacked\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874a1d5-6640-4a71-a8e0-d511d2939f42",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f028fe-68db-4608-809a-a7a8afb724b5",
   "metadata": {},
   "source": [
    "# 1. loading data & pre-prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0c5ab334-a752-40ca-8ec2-7a36fe682d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "#\n",
    "\n",
    "# settings \n",
    "dir = \"/Users/pio/Google 드라이브/data/\"\n",
    "file_name = \"pbc2.csv\"\n",
    "data = pd.read_csv(dir + file_name)\n",
    "\n",
    "# drop status1 - competing risks setting\n",
    "data = data.drop(axis=1, columns =['status'])\n",
    "\n",
    "\n",
    "# ID, Time, Event, Measure Time column names\n",
    "ID_col = 'id'; T_col ='years'; E_col ='status2'; measure_T_col = 'year'\n",
    "\n",
    "# categorical variables\n",
    "nominal_col = ['drug','sex', 'ascites', 'hepatomegaly','spiders', 'edema']\n",
    "ordinal_col = ['histologic']\n",
    "\n",
    "# continuous variables\n",
    "cont_col = list(set(data.columns) - set(nominal_col) - set(ordinal_col) - set([ID_col, T_col, E_col, measure_T_col]))\n",
    "\n",
    "# window - 5 year prediction \n",
    "window = 5\n",
    "\n",
    "# S : landmark time points - 0, 0.5, 1, ..., 10\n",
    "S = np.linspace(0,10,21)\n",
    "v_years = S+window\n",
    "\n",
    "# Number of bins when discritizing \n",
    "## !!!(Actually, k_bin - 1 bins are produced)!!!\n",
    "k_bin = 5\n",
    "\n",
    "# minimal bin_size\n",
    "minimal_bin_size = window / (k_bin-1)\n",
    "\n",
    "# \n",
    "\n",
    "# for continous variables, \n",
    "## scaling -> min-max scaling &\n",
    "## imputation -> fill na's : median for continous\n",
    "for col in cont_col : \n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "    data[col] = (data[col] - min(data[col])) / (max(data[col]) - min(data[col]))\n",
    "\n",
    "# one-hot encoding for categorical variables\n",
    "data = pd.get_dummies(data, columns = nominal_col, drop_first=True)\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "# settings2\n",
    "\n",
    "# proportion of train set\n",
    "p_train = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "04c70122-6b2c-4258-a76b-17aa551af6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>years</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>serBilir</th>\n",
       "      <th>serChol</th>\n",
       "      <th>albumin</th>\n",
       "      <th>alkaline</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>platelets</th>\n",
       "      <th>prothrombin</th>\n",
       "      <th>histologic</th>\n",
       "      <th>status2</th>\n",
       "      <th>drug_placebo</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ascites_Yes</th>\n",
       "      <th>hepatomegaly_Yes</th>\n",
       "      <th>spiders_Yes</th>\n",
       "      <th>edema_edema despite diuretics</th>\n",
       "      <th>edema_edema no diuretics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>135.392802</td>\n",
       "      <td>8.051561</td>\n",
       "      <td>0.440588</td>\n",
       "      <td>3.135860</td>\n",
       "      <td>0.087343</td>\n",
       "      <td>0.144657</td>\n",
       "      <td>0.324545</td>\n",
       "      <td>0.094231</td>\n",
       "      <td>0.097156</td>\n",
       "      <td>0.203436</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>3.265296</td>\n",
       "      <td>0.372751</td>\n",
       "      <td>0.497172</td>\n",
       "      <td>0.121851</td>\n",
       "      <td>0.086889</td>\n",
       "      <td>0.479177</td>\n",
       "      <td>0.296144</td>\n",
       "      <td>0.084833</td>\n",
       "      <td>0.194859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.571397</td>\n",
       "      <td>3.480676</td>\n",
       "      <td>0.192895</td>\n",
       "      <td>3.094865</td>\n",
       "      <td>0.131359</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>0.073543</td>\n",
       "      <td>0.085448</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>0.100755</td>\n",
       "      <td>0.054773</td>\n",
       "      <td>0.872861</td>\n",
       "      <td>0.483661</td>\n",
       "      <td>0.500121</td>\n",
       "      <td>0.327198</td>\n",
       "      <td>0.281745</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>0.456673</td>\n",
       "      <td>0.278705</td>\n",
       "      <td>0.396194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>5.626437</td>\n",
       "      <td>0.297449</td>\n",
       "      <td>0.525682</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.122674</td>\n",
       "      <td>0.283626</td>\n",
       "      <td>0.048952</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>0.133544</td>\n",
       "      <td>0.040741</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>8.112474</td>\n",
       "      <td>0.433130</td>\n",
       "      <td>2.053444</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.131395</td>\n",
       "      <td>0.331871</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>0.084084</td>\n",
       "      <td>0.197687</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>203.000000</td>\n",
       "      <td>10.456138</td>\n",
       "      <td>0.572748</td>\n",
       "      <td>5.032308</td>\n",
       "      <td>0.092910</td>\n",
       "      <td>0.140116</td>\n",
       "      <td>0.369883</td>\n",
       "      <td>0.111683</td>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.259727</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>312.000000</td>\n",
       "      <td>14.305662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.105793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id        years          age         year     serBilir  \\\n",
       "count  1945.000000  1945.000000  1945.000000  1945.000000  1945.000000   \n",
       "mean    135.392802     8.051561     0.440588     3.135860     0.087343   \n",
       "std      85.571397     3.480676     0.192895     3.094865     0.131359   \n",
       "min       1.000000     0.112255     0.000000     0.000000     0.000000   \n",
       "25%      61.000000     5.626437     0.297449     0.525682     0.017115   \n",
       "50%     126.000000     8.112474     0.433130     2.053444     0.031785   \n",
       "75%     203.000000    10.456138     0.572748     5.032308     0.092910   \n",
       "max     312.000000    14.305662     1.000000    14.105793     1.000000   \n",
       "\n",
       "           serChol      albumin     alkaline         SGOT    platelets  \\\n",
       "count  1945.000000  1945.000000  1945.000000  1945.000000  1945.000000   \n",
       "mean      0.144657     0.324545     0.094231     0.097156     0.203436   \n",
       "std       0.074538     0.073543     0.085448     0.065430     0.100755   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.122674     0.283626     0.048952     0.054888     0.133544   \n",
       "50%       0.131395     0.331871     0.072449     0.084084     0.197687   \n",
       "75%       0.140116     0.369883     0.111683     0.124124     0.259727   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       prothrombin   histologic      status2  drug_placebo     sex_male  \\\n",
       "count  1945.000000  1945.000000  1945.000000   1945.000000  1945.000000   \n",
       "mean      0.073992     3.265296     0.372751      0.497172     0.121851   \n",
       "std       0.054773     0.872861     0.483661      0.500121     0.327198   \n",
       "min       0.000000     1.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.040741     3.000000     0.000000      0.000000     0.000000   \n",
       "50%       0.066667     3.000000     0.000000      0.000000     0.000000   \n",
       "75%       0.092593     4.000000     1.000000      1.000000     0.000000   \n",
       "max       1.000000     4.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       ascites_Yes  hepatomegaly_Yes  spiders_Yes  \\\n",
       "count  1945.000000       1945.000000  1945.000000   \n",
       "mean      0.086889          0.479177     0.296144   \n",
       "std       0.281745          0.499695     0.456673   \n",
       "min       0.000000          0.000000     0.000000   \n",
       "25%       0.000000          0.000000     0.000000   \n",
       "50%       0.000000          0.000000     0.000000   \n",
       "75%       0.000000          1.000000     1.000000   \n",
       "max       1.000000          1.000000     1.000000   \n",
       "\n",
       "       edema_edema despite diuretics  edema_edema no diuretics  \n",
       "count                    1945.000000               1945.000000  \n",
       "mean                        0.084833                  0.194859  \n",
       "std                         0.278705                  0.396194  \n",
       "min                         0.000000                  0.000000  \n",
       "25%                         0.000000                  0.000000  \n",
       "50%                         0.000000                  0.000000  \n",
       "75%                         0.000000                  0.000000  \n",
       "max                         1.000000                  1.000000  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5394b4e-351b-41e0-adce-3b4ee012a79b",
   "metadata": {},
   "source": [
    "# 2. Landmarking & Train-test split\n",
    "## 2-1. Landmarking dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f33c9988-1593-48b8-bedf-f1986223a3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_lm_cont = landmarker_cont(data=data, ID_col = ID_col, T_col = T_col, E_col = E_col, \n",
    "                window = window, S= S, measure_T_col = measure_T_col)\n",
    "\n",
    "data_lm_disc = landmarker_disc(data=data_lm_cont,ID_col = ID_col, T_col = T_col, E_col = E_col, \n",
    "                window = window, S= S, measure_T_col = measure_T_col, k_bin = k_bin, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc12c1c-c292-43bf-8851-a0117bf896ea",
   "metadata": {},
   "source": [
    "## 2-2. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "635794ff-6e33-4f94-92de-ebd27dc74930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Split IDs into train set and test set\n",
    "train_id, test_id = id_train_test_split(id_list = data[ID_col], seed_number = 1, p=0.7)\n",
    "\n",
    "# Train, test set from original form\n",
    "train = data[data[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test = data[data[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "# Train, test set for continous landmarking algorithms\n",
    "train_lm_cont = data_lm_cont[data_lm_cont[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test_lm_cont = data_lm_cont[data_lm_cont[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "# Train, test set for discrete landmarking algorithms\n",
    "train_lm_disc = data_lm_disc[data_lm_disc[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test_lm_disc = data_lm_disc[data_lm_disc[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "print(np.all(np.unique(train_lm_cont.id) == np.unique(train_lm_disc.id)))\n",
    "print(np.all(np.unique(test_lm_cont.id) == np.unique(test_lm_disc.id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73dc374-cd5b-44d7-9e1d-79dd878f1d31",
   "metadata": {},
   "source": [
    "# 3. Fitting Part(Non bootstrapping models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7ecc2-b9ee-43c2-953f-953a7f45e89e",
   "metadata": {},
   "source": [
    "## 3-1. Specifying Baseline models(level 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7ad08-0878-4a7d-b9a4-ef78e41d2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model specifics of level 0 models\n",
    "cox_params = {'penalizer':np.exp(np.linspace(-5,1,5)),'l1_ratio':[0,0.25,0.5,0.75,1]}\n",
    "# 5*5 *2 = 50\n",
    "model_specifics_cont = pd.DataFrame({'model_name' : ['cox_str', 'cox_no_str'], \n",
    "                                'model_instance':[CoxPHFitter(),CoxPHFitter()], \n",
    "                                'hyperparams':[cox_params,cox_params], \n",
    "                                'type':['cox_str','cox_no_str']})\n",
    "\n",
    "LR_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['saga']\n",
    "} # 7 * 2 * 1 = 14\n",
    "RF_params = {'n_estimators':[50,100,300,500],'max_depth':[1,3,5]} # 4*3 = 12\n",
    "GB_params = {'n_estimators':[50,100,300,500],'max_depth':[1,3,5]} # 4*3 = 12\n",
    "MLP_params = {'hidden_layer_sizes':[1,2,3], 'activation' : ['identity', 'logistic', 'tanh', 'relu'], 'max_iter' : [1000], 'early_stopping' : [True], 'learning_rate' : ['adaptive']}\n",
    "# 3*4\n",
    "KNN_params = {'n_neighbors':[1,5,10], 'weights':['uniform', 'distance']} \n",
    "# 3*2\n",
    "NGB_params = {'var_smoothing':[1e-5, 1e-9, 1e-1]}\n",
    "# 3\n",
    "ADA_params = {'n_estimators':[50, 100, 300, 500], 'max_depth':[1,3,5]}\n",
    "# 4*10*3 = 36\n",
    "\n",
    "model_specifics_disc = pd.DataFrame({'model_name' : ['LR','RF','GB','MLP','KNN','NGB','ADA'], \n",
    "                                'model_instance':[LogisticRegression(max_iter=10000),RandomForestClassifier(),GradientBoostingClassifier(),MLPClassifier(),KNeighborsClassifier(),GaussianNB(), AdaBoostClassifier()], \n",
    "                                'hyperparams':[LR_params, RF_params, GB_params,MLP_params, KNN_params,NGB_params, ADA_params], \n",
    "                                'type':['lr','rf','gb','mlp','knn','ngb','ada']})\n",
    "\n",
    "\n",
    "model_specifics = pd.concat([model_specifics_cont,model_specifics_disc],axis=0).reset_index(drop=True)\n",
    "model_specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a5e03-ffff-4ca9-b95c-7c8c1099aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_list = set_hyperparams(model_specifics)\n",
    "len(baseline_model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59529e-c8f9-4f2a-a9ff-519b9af6a4b4",
   "metadata": {},
   "source": [
    "## 3-2. Fitting Baseline models(level 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f781f9-2f16-4a5c-af42-2eeab6448a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = stacker(model_specifics = model_specifics, ID = ID_col, T = T_col, E = E_col, S = S, window = window, k_bin = k_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eaae9e-d407-4f40-8a64-ed9e086f41b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stack.fit(train_lm_cont, train_lm_disc)\n",
    "\n",
    "stack_trn = stack.predict(train_lm_cont, train_lm_disc)\n",
    "stack_tst = stack.predict(test_lm_cont, test_lm_disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c799c2c3-8b4a-430a-a5d8-9df2ca2da3a5",
   "metadata": {},
   "source": [
    "## 3-3. Fitting meta model(level 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7c0ae8e8-9f20-49fc-9d60-ec818cd2e579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LM</th>\n",
       "      <th>status2</th>\n",
       "      <th>years</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.095170</td>\n",
       "      <td>1.004824e-08</td>\n",
       "      <td>8.912633e-09</td>\n",
       "      <td>7.528412e-09</td>\n",
       "      <td>1.212599e-08</td>\n",
       "      <td>2.663466e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060887</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.061634</td>\n",
       "      <td>0.061634</td>\n",
       "      <td>0.061634</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.061845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.992268e-01</td>\n",
       "      <td>7.904634e-01</td>\n",
       "      <td>7.865925e-01</td>\n",
       "      <td>7.783915e-01</td>\n",
       "      <td>7.712919e-01</td>\n",
       "      <td>0.748895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071703</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>0.065172</td>\n",
       "      <td>0.065172</td>\n",
       "      <td>0.065172</td>\n",
       "      <td>0.064251</td>\n",
       "      <td>0.064251</td>\n",
       "      <td>0.064251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.770781</td>\n",
       "      <td>5.574541e-01</td>\n",
       "      <td>5.569528e-01</td>\n",
       "      <td>5.479559e-01</td>\n",
       "      <td>5.314501e-01</td>\n",
       "      <td>5.220573e-01</td>\n",
       "      <td>0.605204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065940</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.063176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.357275e-01</td>\n",
       "      <td>3.256735e-01</td>\n",
       "      <td>3.222720e-01</td>\n",
       "      <td>3.177992e-01</td>\n",
       "      <td>3.220754e-01</td>\n",
       "      <td>0.285316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069450</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.063148</td>\n",
       "      <td>0.063148</td>\n",
       "      <td>0.063148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.120578</td>\n",
       "      <td>8.214762e-01</td>\n",
       "      <td>8.207666e-01</td>\n",
       "      <td>8.184606e-01</td>\n",
       "      <td>8.159632e-01</td>\n",
       "      <td>8.117734e-01</td>\n",
       "      <td>0.825857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069262</td>\n",
       "      <td>0.066248</td>\n",
       "      <td>0.066248</td>\n",
       "      <td>0.066248</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.063583</td>\n",
       "      <td>0.063583</td>\n",
       "      <td>0.063583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>134</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.453401</td>\n",
       "      <td>4.265935e-01</td>\n",
       "      <td>4.911498e-01</td>\n",
       "      <td>5.227962e-01</td>\n",
       "      <td>4.924416e-01</td>\n",
       "      <td>4.435441e-01</td>\n",
       "      <td>0.560019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063633</td>\n",
       "      <td>0.063533</td>\n",
       "      <td>0.063533</td>\n",
       "      <td>0.063533</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.062877</td>\n",
       "      <td>0.062877</td>\n",
       "      <td>0.062877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>136</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.313766</td>\n",
       "      <td>9.860016e-01</td>\n",
       "      <td>9.837589e-01</td>\n",
       "      <td>9.801265e-01</td>\n",
       "      <td>9.770640e-01</td>\n",
       "      <td>9.720449e-01</td>\n",
       "      <td>0.970314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074295</td>\n",
       "      <td>0.068574</td>\n",
       "      <td>0.068574</td>\n",
       "      <td>0.068574</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.063806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>137</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.018070</td>\n",
       "      <td>9.653127e-01</td>\n",
       "      <td>9.631242e-01</td>\n",
       "      <td>9.585697e-01</td>\n",
       "      <td>9.536294e-01</td>\n",
       "      <td>9.452432e-01</td>\n",
       "      <td>0.943026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073878</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.064564</td>\n",
       "      <td>0.064564</td>\n",
       "      <td>0.064564</td>\n",
       "      <td>0.063697</td>\n",
       "      <td>0.063697</td>\n",
       "      <td>0.063697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>140</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.206987</td>\n",
       "      <td>9.793305e-01</td>\n",
       "      <td>9.780822e-01</td>\n",
       "      <td>9.739427e-01</td>\n",
       "      <td>9.704172e-01</td>\n",
       "      <td>9.659371e-01</td>\n",
       "      <td>0.961090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074143</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.063343</td>\n",
       "      <td>0.063343</td>\n",
       "      <td>0.063343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>141</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.182346</td>\n",
       "      <td>9.580216e-01</td>\n",
       "      <td>9.513071e-01</td>\n",
       "      <td>9.426130e-01</td>\n",
       "      <td>9.362581e-01</td>\n",
       "      <td>9.244196e-01</td>\n",
       "      <td>0.940540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076691</td>\n",
       "      <td>0.069664</td>\n",
       "      <td>0.069664</td>\n",
       "      <td>0.069664</td>\n",
       "      <td>0.064955</td>\n",
       "      <td>0.064955</td>\n",
       "      <td>0.064955</td>\n",
       "      <td>0.064054</td>\n",
       "      <td>0.064054</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2776 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    LM  status2      years             0             1             2  \\\n",
       "0       1   0.0        1   1.095170  1.004824e-08  8.912633e-09  7.528412e-09   \n",
       "1       2   0.0        0   5.000000  7.992268e-01  7.904634e-01  7.865925e-01   \n",
       "2       3   0.0        1   2.770781  5.574541e-01  5.569528e-01  5.479559e-01   \n",
       "3       4   0.0        0   5.000000  3.357275e-01  3.256735e-01  3.222720e-01   \n",
       "4       5   0.0        0   4.120578  8.214762e-01  8.207666e-01  8.184606e-01   \n",
       "...   ...   ...      ...        ...           ...           ...           ...   \n",
       "2771  134  10.0        0  10.453401  4.265935e-01  4.911498e-01  5.227962e-01   \n",
       "2772  136  10.0        0  10.313766  9.860016e-01  9.837589e-01  9.801265e-01   \n",
       "2773  137  10.0        0  10.018070  9.653127e-01  9.631242e-01  9.585697e-01   \n",
       "2774  140  10.0        0  10.206987  9.793305e-01  9.780822e-01  9.739427e-01   \n",
       "2775  141  10.0        0  10.182346  9.580216e-01  9.513071e-01  9.426130e-01   \n",
       "\n",
       "                 3             4         5  ...       111       112       113  \\\n",
       "0     1.212599e-08  2.663466e-08  0.000002  ...  0.060887  0.060152  0.060152   \n",
       "1     7.783915e-01  7.712919e-01  0.748895  ...  0.071703  0.068172  0.068172   \n",
       "2     5.314501e-01  5.220573e-01  0.605204  ...  0.065940  0.064433  0.064433   \n",
       "3     3.177992e-01  3.220754e-01  0.285316  ...  0.069450  0.065444  0.065444   \n",
       "4     8.159632e-01  8.117734e-01  0.825857  ...  0.069262  0.066248  0.066248   \n",
       "...            ...           ...       ...  ...       ...       ...       ...   \n",
       "2771  4.924416e-01  4.435441e-01  0.560019  ...  0.063633  0.063533  0.063533   \n",
       "2772  9.770640e-01  9.720449e-01  0.970314  ...  0.074295  0.068574  0.068574   \n",
       "2773  9.536294e-01  9.452432e-01  0.943026  ...  0.073878  0.068205  0.068205   \n",
       "2774  9.704172e-01  9.659371e-01  0.961090  ...  0.074143  0.068195  0.068195   \n",
       "2775  9.362581e-01  9.244196e-01  0.940540  ...  0.076691  0.069664  0.069664   \n",
       "\n",
       "           114       115       116       117       118       119       120  \n",
       "0     0.060152  0.061634  0.061634  0.061634  0.061845  0.061845  0.061845  \n",
       "1     0.068172  0.065172  0.065172  0.065172  0.064251  0.064251  0.064251  \n",
       "2     0.064433  0.063457  0.063457  0.063457  0.063176  0.063176  0.063176  \n",
       "3     0.065444  0.063521  0.063521  0.063521  0.063148  0.063148  0.063148  \n",
       "4     0.066248  0.063866  0.063866  0.063866  0.063583  0.063583  0.063583  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2771  0.063533  0.063023  0.063023  0.063023  0.062877  0.062877  0.062877  \n",
       "2772  0.068574  0.064382  0.064382  0.064382  0.063806  0.063806  0.063806  \n",
       "2773  0.068205  0.064564  0.064564  0.064564  0.063697  0.063697  0.063697  \n",
       "2774  0.068195  0.064101  0.064101  0.064101  0.063343  0.063343  0.063343  \n",
       "2775  0.069664  0.064955  0.064955  0.064955  0.064054  0.064054  0.064054  \n",
       "\n",
       "[2776 rows x 125 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cb83b45e-cde3-4a38-8576-fb9f65dde882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LM</th>\n",
       "      <th>status2</th>\n",
       "      <th>years</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.745126</td>\n",
       "      <td>0.738533</td>\n",
       "      <td>0.729977</td>\n",
       "      <td>0.723309</td>\n",
       "      <td>0.714972</td>\n",
       "      <td>0.770869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072270</td>\n",
       "      <td>0.067484</td>\n",
       "      <td>0.067484</td>\n",
       "      <td>0.067484</td>\n",
       "      <td>0.064328</td>\n",
       "      <td>0.064328</td>\n",
       "      <td>0.064328</td>\n",
       "      <td>0.063663</td>\n",
       "      <td>0.063663</td>\n",
       "      <td>0.063663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139634</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061277</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.062254</td>\n",
       "      <td>0.062254</td>\n",
       "      <td>0.062254</td>\n",
       "      <td>0.062274</td>\n",
       "      <td>0.062274</td>\n",
       "      <td>0.062274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.755894</td>\n",
       "      <td>0.751015</td>\n",
       "      <td>0.743818</td>\n",
       "      <td>0.740266</td>\n",
       "      <td>0.737455</td>\n",
       "      <td>0.788112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071286</td>\n",
       "      <td>0.067106</td>\n",
       "      <td>0.067106</td>\n",
       "      <td>0.067106</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.063627</td>\n",
       "      <td>0.063627</td>\n",
       "      <td>0.063627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.920405</td>\n",
       "      <td>0.918273</td>\n",
       "      <td>0.915618</td>\n",
       "      <td>0.912982</td>\n",
       "      <td>0.909361</td>\n",
       "      <td>0.921802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079549</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>0.065222</td>\n",
       "      <td>0.065222</td>\n",
       "      <td>0.065222</td>\n",
       "      <td>0.064184</td>\n",
       "      <td>0.064184</td>\n",
       "      <td>0.064184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.105465</td>\n",
       "      <td>0.567759</td>\n",
       "      <td>0.571706</td>\n",
       "      <td>0.574039</td>\n",
       "      <td>0.577969</td>\n",
       "      <td>0.580124</td>\n",
       "      <td>0.613054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061849</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>0.062339</td>\n",
       "      <td>0.062339</td>\n",
       "      <td>0.062339</td>\n",
       "      <td>0.062478</td>\n",
       "      <td>0.062478</td>\n",
       "      <td>0.062478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>73</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.303581</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>0.996447</td>\n",
       "      <td>0.995307</td>\n",
       "      <td>0.994457</td>\n",
       "      <td>0.993012</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075551</td>\n",
       "      <td>0.070947</td>\n",
       "      <td>0.070947</td>\n",
       "      <td>0.070947</td>\n",
       "      <td>0.065588</td>\n",
       "      <td>0.065588</td>\n",
       "      <td>0.065588</td>\n",
       "      <td>0.064667</td>\n",
       "      <td>0.064667</td>\n",
       "      <td>0.064667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>84</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.870989</td>\n",
       "      <td>0.315324</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>0.319486</td>\n",
       "      <td>0.343707</td>\n",
       "      <td>0.402296</td>\n",
       "      <td>0.551653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069163</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062638</td>\n",
       "      <td>0.062638</td>\n",
       "      <td>0.062638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>115</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.200854</td>\n",
       "      <td>0.972478</td>\n",
       "      <td>0.969098</td>\n",
       "      <td>0.963791</td>\n",
       "      <td>0.961352</td>\n",
       "      <td>0.957731</td>\n",
       "      <td>0.959409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081262</td>\n",
       "      <td>0.071629</td>\n",
       "      <td>0.071629</td>\n",
       "      <td>0.071629</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.064602</td>\n",
       "      <td>0.064602</td>\n",
       "      <td>0.064602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>127</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.743621</td>\n",
       "      <td>0.849871</td>\n",
       "      <td>0.847990</td>\n",
       "      <td>0.842123</td>\n",
       "      <td>0.837994</td>\n",
       "      <td>0.834570</td>\n",
       "      <td>0.856223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070215</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.063315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>135</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.456138</td>\n",
       "      <td>0.998035</td>\n",
       "      <td>0.997404</td>\n",
       "      <td>0.996425</td>\n",
       "      <td>0.995529</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.990864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>0.071003</td>\n",
       "      <td>0.071003</td>\n",
       "      <td>0.071003</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.064210</td>\n",
       "      <td>0.064210</td>\n",
       "      <td>0.064210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    LM  status2      years         0         1         2         3  \\\n",
       "0       6   0.0        0   5.000000  0.745126  0.738533  0.729977  0.723309   \n",
       "1      10   0.0        1   0.139634  0.000049  0.000028  0.000017  0.000017   \n",
       "2      11   0.0        0   5.000000  0.755894  0.751015  0.743818  0.740266   \n",
       "3      13   0.0        0   5.000000  0.920405  0.918273  0.915618  0.912982   \n",
       "4      17   0.0        1   2.105465  0.567759  0.571706  0.574039  0.577969   \n",
       "...   ...   ...      ...        ...       ...       ...       ...       ...   \n",
       "1191   73  10.0        0  13.303581  0.997093  0.996447  0.995307  0.994457   \n",
       "1192   84  10.0        0  12.870989  0.315324  0.317646  0.319486  0.343707   \n",
       "1193  115  10.0        0  11.200854  0.972478  0.969098  0.963791  0.961352   \n",
       "1194  127  10.0        0  10.743621  0.849871  0.847990  0.842123  0.837994   \n",
       "1195  135  10.0        0  10.456138  0.998035  0.997404  0.996425  0.995529   \n",
       "\n",
       "             4         5  ...       111       112       113       114  \\\n",
       "0     0.714972  0.770869  ...  0.072270  0.067484  0.067484  0.067484   \n",
       "1     0.000024  0.000565  ...  0.061277  0.060960  0.060960  0.060960   \n",
       "2     0.737455  0.788112  ...  0.071286  0.067106  0.067106  0.067106   \n",
       "3     0.909361  0.921802  ...  0.079549  0.070935  0.070935  0.070935   \n",
       "4     0.580124  0.613054  ...  0.061849  0.061797  0.061797  0.061797   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "1191  0.993012  0.987952  ...  0.075551  0.070947  0.070947  0.070947   \n",
       "1192  0.402296  0.551653  ...  0.069163  0.065747  0.065747  0.065747   \n",
       "1193  0.957731  0.959409  ...  0.081262  0.071629  0.071629  0.071629   \n",
       "1194  0.834570  0.856223  ...  0.070215  0.066400  0.066400  0.066400   \n",
       "1195  0.993547  0.990864  ...  0.077462  0.071003  0.071003  0.071003   \n",
       "\n",
       "           115       116       117       118       119       120  \n",
       "0     0.064328  0.064328  0.064328  0.063663  0.063663  0.063663  \n",
       "1     0.062254  0.062254  0.062254  0.062274  0.062274  0.062274  \n",
       "2     0.064215  0.064215  0.064215  0.063627  0.063627  0.063627  \n",
       "3     0.065222  0.065222  0.065222  0.064184  0.064184  0.064184  \n",
       "4     0.062339  0.062339  0.062339  0.062478  0.062478  0.062478  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "1191  0.065588  0.065588  0.065588  0.064667  0.064667  0.064667  \n",
       "1192  0.062937  0.062937  0.062937  0.062638  0.062638  0.062638  \n",
       "1193  0.065828  0.065828  0.065828  0.064602  0.064602  0.064602  \n",
       "1194  0.063732  0.063732  0.063732  0.063315  0.063315  0.063315  \n",
       "1195  0.065201  0.065201  0.065201  0.064210  0.064210  0.064210  \n",
       "\n",
       "[1196 rows x 125 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45fbee8c-5683-4f26-878d-c04d56f14a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcw_calc = ipcw_fitter(S= S, window =window)\n",
    "ipcw_calc.fit(data= train_lm_cont, T = T_col, E = E_col)\n",
    "\n",
    "\n",
    "nnls = nnls_constraint()\n",
    "nnls.fit(x = stack_trn.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = stack_trn[E_col],\n",
    "         w = ipcw_calc.predict(train_lm_cont))\n",
    "\n",
    "res_nnls = nnls.predict(stack_tst.drop([ID_col, 'LM', E_col, T_col], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "df4d4de2-e2f1-4c13-8afd-29f8ca4009b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcw_calc = ipcw_fitter(S= S, window =window)\n",
    "ipcw_calc.fit(data= train_lm_cont, T = T_col, E = E_col)\n",
    "\n",
    "\n",
    "nnls = nnls_constraint()\n",
    "nnls.fit(x = stack_trn.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = stack_trn[E_col],\n",
    "         w = ipcw_calc.predict(train_lm_cont))\n",
    "\n",
    "\n",
    "hill = hillclimb()\n",
    "hill.fit(x = stack_trn.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = stack_trn[E_col],\n",
    "         w = ipcw_calc.predict(train_lm_cont))\n",
    "\n",
    "\n",
    "ipcw_rf = RandomForestClassifier()\n",
    "ipcw_rf.fit(X = stack_trn.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "            y = stack_trn[E_col], sample_weight = ipcw_calc.predict(train_lm_cont))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "615451a1-e524-414a-b033-695ee5db255c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.361831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.309915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.355119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.364044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.370705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.387232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1196.000000\n",
       "mean      0.361831\n",
       "std       0.012297\n",
       "min       0.309915\n",
       "25%       0.355119\n",
       "50%       0.364044\n",
       "75%       0.370705\n",
       "max       0.387232"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_nnls = nnls.predict(stack_tst.drop([ID_col, 'LM', E_col, T_col], axis=1))\n",
    "pd.DataFrame(res_nnls).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e977dbce-3fd9-418a-9bcb-f319f6b75f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.059707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.183305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.351935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.387152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.415339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.559062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1196.000000\n",
       "mean      0.383215\n",
       "std       0.059707\n",
       "min       0.183305\n",
       "25%       0.351935\n",
       "50%       0.387152\n",
       "75%       0.415339\n",
       "max       0.559062"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_hill = hill.predict(stack_tst.drop([ID_col, 'LM', E_col, T_col], axis=1))\n",
    "pd.DataFrame(res_hill).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "24672961-f8d6-4990-a412-dbf0d4c1a690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.189799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.392306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1196.000000\n",
       "mean      0.189799\n",
       "std       0.392306\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = ipcw_rf.predict(stack_tst.drop([ID_col, 'LM', E_col, T_col], axis=1))\n",
    "pd.DataFrame(res_rf).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4890a-55c4-48d0-9eb7-1f6e96186b3c",
   "metadata": {},
   "source": [
    "## 3-4. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7eca0a64-7058-4c47-aaff-78c2dff6be15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9094240837696335"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concordance_index(event_times = stack_tst[stack_tst['LM'] == 0][T_col], \n",
    "                  predicted_scores = stack_tst[stack_tst['LM']==0][0], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == 0][E_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4dcff9c3-338d-412c-ab74-941238856fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i for model, j for landmarked time\n",
    "c_index_list = []\n",
    "for i in range(121) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        c_index_value = concordance_index(event_times = stack_tst[stack_tst['LM'] == j][T_col], \n",
    "                  predicted_scores = stack_tst[stack_tst['LM']==j][i], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == j][E_col])\n",
    "        temp.append(c_index_value)\n",
    "    c_index_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d4e845c8-811d-40c1-adb9-5db89c5a2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_index_list = np.array(c_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "720cd6d6-c300-444c-a96e-601286df4900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.825583</td>\n",
       "      <td>0.823942</td>\n",
       "      <td>0.828229</td>\n",
       "      <td>0.813323</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.821620</td>\n",
       "      <td>0.794009</td>\n",
       "      <td>0.772371</td>\n",
       "      <td>0.764422</td>\n",
       "      <td>0.735798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681845</td>\n",
       "      <td>0.663190</td>\n",
       "      <td>0.670466</td>\n",
       "      <td>0.715111</td>\n",
       "      <td>0.619358</td>\n",
       "      <td>0.601559</td>\n",
       "      <td>0.741311</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0.712161</td>\n",
       "      <td>0.843727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.172503</td>\n",
       "      <td>0.176665</td>\n",
       "      <td>0.174709</td>\n",
       "      <td>0.170879</td>\n",
       "      <td>0.163171</td>\n",
       "      <td>0.162621</td>\n",
       "      <td>0.153781</td>\n",
       "      <td>0.149890</td>\n",
       "      <td>0.137038</td>\n",
       "      <td>0.136038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115813</td>\n",
       "      <td>0.119438</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>0.117966</td>\n",
       "      <td>0.113666</td>\n",
       "      <td>0.099847</td>\n",
       "      <td>0.136026</td>\n",
       "      <td>0.100633</td>\n",
       "      <td>0.123658</td>\n",
       "      <td>0.177107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.141509</td>\n",
       "      <td>0.160032</td>\n",
       "      <td>0.171275</td>\n",
       "      <td>0.186701</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.206630</td>\n",
       "      <td>0.181916</td>\n",
       "      <td>0.211491</td>\n",
       "      <td>0.241636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.301115</td>\n",
       "      <td>0.275109</td>\n",
       "      <td>0.198718</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.867539</td>\n",
       "      <td>0.873821</td>\n",
       "      <td>0.865446</td>\n",
       "      <td>0.839478</td>\n",
       "      <td>0.833760</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.811050</td>\n",
       "      <td>0.800861</td>\n",
       "      <td>0.788509</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.672489</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.887958</td>\n",
       "      <td>0.888561</td>\n",
       "      <td>0.890924</td>\n",
       "      <td>0.884793</td>\n",
       "      <td>0.872975</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.826695</td>\n",
       "      <td>0.819071</td>\n",
       "      <td>0.801115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.701587</td>\n",
       "      <td>0.702602</td>\n",
       "      <td>0.746725</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.901571</td>\n",
       "      <td>0.895637</td>\n",
       "      <td>0.901274</td>\n",
       "      <td>0.891705</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.868508</td>\n",
       "      <td>0.846071</td>\n",
       "      <td>0.830073</td>\n",
       "      <td>0.823420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.923037</td>\n",
       "      <td>0.919222</td>\n",
       "      <td>0.917994</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.895993</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.906077</td>\n",
       "      <td>0.876211</td>\n",
       "      <td>0.861858</td>\n",
       "      <td>0.868030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832787</td>\n",
       "      <td>0.831746</td>\n",
       "      <td>0.817844</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  121.000000  121.000000   \n",
       "mean     0.825583    0.823942    0.828229    0.813323    0.809572    0.821620   \n",
       "std      0.172503    0.176665    0.174709    0.170879    0.163171    0.162621   \n",
       "min      0.152356    0.141509    0.160032    0.171275    0.186701    0.189000   \n",
       "25%      0.867539    0.873821    0.865446    0.839478    0.833760    0.862000   \n",
       "50%      0.887958    0.888561    0.890924    0.884793    0.872975    0.882000   \n",
       "75%      0.901571    0.895637    0.901274    0.891705    0.884058    0.898000   \n",
       "max      0.923037    0.919222    0.917994    0.904762    0.895993    0.928000   \n",
       "\n",
       "               6           7           8           9   ...          11  \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  ...  121.000000   \n",
       "mean     0.794009    0.772371    0.764422    0.735798  ...    0.681845   \n",
       "std      0.153781    0.149890    0.137038    0.136038  ...    0.115813   \n",
       "min      0.206630    0.181916    0.211491    0.241636  ...    0.245902   \n",
       "25%      0.811050    0.800861    0.788509    0.689591  ...    0.639344   \n",
       "50%      0.854144    0.826695    0.819071    0.801115  ...    0.714754   \n",
       "75%      0.868508    0.846071    0.830073    0.823420  ...    0.750820   \n",
       "max      0.906077    0.876211    0.861858    0.868030  ...    0.832787   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  121.000000  121.000000   \n",
       "mean     0.663190    0.670466    0.715111    0.619358    0.601559    0.741311   \n",
       "std      0.119438    0.105638    0.117966    0.113666    0.099847    0.136026   \n",
       "min      0.244444    0.301115    0.275109    0.198718    0.206186    0.191781   \n",
       "25%      0.600000    0.635688    0.672489    0.589744    0.577320    0.726027   \n",
       "50%      0.701587    0.702602    0.746725    0.641026    0.618557    0.780822   \n",
       "75%      0.739683    0.743494    0.781659    0.692308    0.659794    0.808219   \n",
       "max      0.831746    0.817844    0.851528    0.788462    0.742268    0.917808   \n",
       "\n",
       "               18          19          20  \n",
       "count  121.000000  121.000000  121.000000  \n",
       "mean     0.611570    0.712161    0.843727  \n",
       "std      0.100633    0.123658    0.177107  \n",
       "min      0.200000    0.257143    0.136364  \n",
       "25%      0.542857    0.685714    0.818182  \n",
       "50%      0.628571    0.742857    0.909091  \n",
       "75%      0.657143    0.800000    0.954545  \n",
       "max      0.800000    0.857143    1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(c_index_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "45cb7825-8a43-488a-bff9-d0f386e7bed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6277486910994764,\n",
       " 0.6043632075471698,\n",
       " 0.6576433121019108,\n",
       " 0.6758832565284179,\n",
       " 0.6811594202898551,\n",
       " 0.733,\n",
       " 0.6928176795580111,\n",
       " 0.6458557588805167,\n",
       " 0.6699266503667481,\n",
       " 0.6486988847583643,\n",
       " 0.6845070422535211,\n",
       " 0.6229508196721312,\n",
       " 0.5968253968253968,\n",
       " 0.5650557620817844,\n",
       " 0.6419213973799127,\n",
       " 0.4807692307692308,\n",
       " 0.5670103092783505,\n",
       " 0.7671232876712328,\n",
       " 0.5428571428571428,\n",
       " 0.6,\n",
       " 1.0]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnls_c_index = []\n",
    "for j in S : \n",
    "    c_index_value = concordance_index(event_times = stack_tst[stack_tst['LM'] == j][T_col], \n",
    "                  predicted_scores = res_nnls[stack_tst['LM'] == j], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == j][E_col])\n",
    "    nnls_c_index.append(c_index_value)\n",
    "\n",
    "nnls_c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a2e9fddb-2aec-48ee-93a9-95ec6d51a36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17853403141361257,\n",
       " 0.16391509433962265,\n",
       " 0.17038216560509553,\n",
       " 0.17204301075268819,\n",
       " 0.19522591645353793,\n",
       " 0.223,\n",
       " 0.27624309392265195,\n",
       " 0.25618945102260493,\n",
       " 0.33985330073349634,\n",
       " 0.3141263940520446,\n",
       " 0.4112676056338028,\n",
       " 0.33114754098360655,\n",
       " 0.3047619047619048,\n",
       " 0.3420074349442379,\n",
       " 0.3406113537117904,\n",
       " 0.22435897435897437,\n",
       " 0.2268041237113402,\n",
       " 0.2876712328767123,\n",
       " 0.2857142857142857,\n",
       " 0.37142857142857144,\n",
       " 0.5909090909090909]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hill_c_index = []\n",
    "for j in S : \n",
    "    c_index_value = concordance_index(event_times = stack_tst[stack_tst['LM'] == j][T_col], \n",
    "                  predicted_scores = res_hill[stack_tst['LM'] == j], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == j][E_col])\n",
    "    hill_c_index.append(c_index_value)\n",
    "\n",
    "hill_c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8c766717-5064-4304-83f9-643a60a63aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3507853403141361,\n",
       " 0.296875,\n",
       " 0.304140127388535,\n",
       " 0.3337173579109063,\n",
       " 0.32011935208866155,\n",
       " 0.29,\n",
       " 0.312707182320442,\n",
       " 0.3638320775026911,\n",
       " 0.4119804400977995,\n",
       " 0.3671003717472119,\n",
       " 0.3929577464788732,\n",
       " 0.31311475409836065,\n",
       " 0.4,\n",
       " 0.4200743494423792,\n",
       " 0.3296943231441048,\n",
       " 0.3141025641025641,\n",
       " 0.422680412371134,\n",
       " 0.3493150684931507,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.3181818181818182]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_c_index = []\n",
    "for j in S : \n",
    "    c_index_value = concordance_index(event_times = stack_tst[stack_tst['LM'] == j][T_col], \n",
    "                  predicted_scores = res_rf[stack_tst['LM'] == j], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == j][E_col])\n",
    "    rf_c_index.append(c_index_value)\n",
    "\n",
    "rf_c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "30053e2f-c723-4dc0-98b3-64d7466d14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcw_tst = ipcw_fitter(S= S, window =window)\n",
    "ipcw_tst.fit(data= test_lm_cont, T = T_col, E = E_col)\n",
    "weight_brier = ipcw_tst.predict(test_lm_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f861f4dc-0df5-456e-b74e-47d0a01c38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i for model, j for landmarked time\n",
    "brier_score_list = []\n",
    "for i in range(121) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        value = brier_score_loss(y_true = stack_tst[stack_tst['LM'] == j][E_col], \n",
    "                         y_prob = stack_tst[stack_tst['LM'] == j][i], \n",
    "                         sample_weight= weight_brier[stack_tst['LM'] == j])        \n",
    "        temp.append(value)        \n",
    "    brier_score_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f7d0dce2-3970-4792-a3a8-627ddcb60833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.508525</td>\n",
       "      <td>0.511817</td>\n",
       "      <td>0.514417</td>\n",
       "      <td>0.504855</td>\n",
       "      <td>0.489575</td>\n",
       "      <td>0.495354</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.482041</td>\n",
       "      <td>0.475095</td>\n",
       "      <td>0.476647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417106</td>\n",
       "      <td>0.384452</td>\n",
       "      <td>0.381873</td>\n",
       "      <td>0.384244</td>\n",
       "      <td>0.385087</td>\n",
       "      <td>0.351127</td>\n",
       "      <td>0.359420</td>\n",
       "      <td>0.300543</td>\n",
       "      <td>0.343449</td>\n",
       "      <td>0.456584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.160191</td>\n",
       "      <td>0.166404</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.166666</td>\n",
       "      <td>0.160397</td>\n",
       "      <td>0.157397</td>\n",
       "      <td>0.138984</td>\n",
       "      <td>0.132496</td>\n",
       "      <td>0.122593</td>\n",
       "      <td>0.140489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106852</td>\n",
       "      <td>0.085220</td>\n",
       "      <td>0.080049</td>\n",
       "      <td>0.076207</td>\n",
       "      <td>0.081609</td>\n",
       "      <td>0.065711</td>\n",
       "      <td>0.085638</td>\n",
       "      <td>0.117991</td>\n",
       "      <td>0.248394</td>\n",
       "      <td>0.293166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.184720</td>\n",
       "      <td>0.176042</td>\n",
       "      <td>0.154738</td>\n",
       "      <td>0.163666</td>\n",
       "      <td>0.164101</td>\n",
       "      <td>0.175366</td>\n",
       "      <td>0.191442</td>\n",
       "      <td>0.206996</td>\n",
       "      <td>0.239422</td>\n",
       "      <td>0.217149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>0.247516</td>\n",
       "      <td>0.245846</td>\n",
       "      <td>0.240693</td>\n",
       "      <td>0.233719</td>\n",
       "      <td>0.219495</td>\n",
       "      <td>0.211437</td>\n",
       "      <td>0.117611</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.393985</td>\n",
       "      <td>0.399119</td>\n",
       "      <td>0.417429</td>\n",
       "      <td>0.410339</td>\n",
       "      <td>0.389506</td>\n",
       "      <td>0.404168</td>\n",
       "      <td>0.413956</td>\n",
       "      <td>0.407706</td>\n",
       "      <td>0.374430</td>\n",
       "      <td>0.340586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328808</td>\n",
       "      <td>0.331785</td>\n",
       "      <td>0.341970</td>\n",
       "      <td>0.340674</td>\n",
       "      <td>0.326201</td>\n",
       "      <td>0.313366</td>\n",
       "      <td>0.303785</td>\n",
       "      <td>0.196577</td>\n",
       "      <td>0.172383</td>\n",
       "      <td>0.242203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.571871</td>\n",
       "      <td>0.563559</td>\n",
       "      <td>0.566307</td>\n",
       "      <td>0.539356</td>\n",
       "      <td>0.519772</td>\n",
       "      <td>0.515403</td>\n",
       "      <td>0.514278</td>\n",
       "      <td>0.503366</td>\n",
       "      <td>0.490648</td>\n",
       "      <td>0.516047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401595</td>\n",
       "      <td>0.376960</td>\n",
       "      <td>0.378691</td>\n",
       "      <td>0.372790</td>\n",
       "      <td>0.379956</td>\n",
       "      <td>0.349312</td>\n",
       "      <td>0.366040</td>\n",
       "      <td>0.312589</td>\n",
       "      <td>0.275625</td>\n",
       "      <td>0.341444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.614126</td>\n",
       "      <td>0.620274</td>\n",
       "      <td>0.625369</td>\n",
       "      <td>0.624384</td>\n",
       "      <td>0.596415</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.591685</td>\n",
       "      <td>0.596135</td>\n",
       "      <td>0.576807</td>\n",
       "      <td>0.581958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465373</td>\n",
       "      <td>0.414621</td>\n",
       "      <td>0.413550</td>\n",
       "      <td>0.427569</td>\n",
       "      <td>0.422410</td>\n",
       "      <td>0.377530</td>\n",
       "      <td>0.396928</td>\n",
       "      <td>0.366114</td>\n",
       "      <td>0.445651</td>\n",
       "      <td>0.761467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.785811</td>\n",
       "      <td>0.815069</td>\n",
       "      <td>0.818294</td>\n",
       "      <td>0.809564</td>\n",
       "      <td>0.815344</td>\n",
       "      <td>0.815639</td>\n",
       "      <td>0.757141</td>\n",
       "      <td>0.778362</td>\n",
       "      <td>0.725728</td>\n",
       "      <td>0.812127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753762</td>\n",
       "      <td>0.651150</td>\n",
       "      <td>0.638429</td>\n",
       "      <td>0.603570</td>\n",
       "      <td>0.693568</td>\n",
       "      <td>0.568070</td>\n",
       "      <td>0.715409</td>\n",
       "      <td>0.685073</td>\n",
       "      <td>0.877980</td>\n",
       "      <td>0.999937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  121.000000  121.000000   \n",
       "mean     0.508525    0.511817    0.514417    0.504855    0.489575    0.495354   \n",
       "std      0.160191    0.166404    0.177900    0.166666    0.160397    0.157397   \n",
       "min      0.184720    0.176042    0.154738    0.163666    0.164101    0.175366   \n",
       "25%      0.393985    0.399119    0.417429    0.410339    0.389506    0.404168   \n",
       "50%      0.571871    0.563559    0.566307    0.539356    0.519772    0.515403   \n",
       "75%      0.614126    0.620274    0.625369    0.624384    0.596415    0.608100   \n",
       "max      0.785811    0.815069    0.818294    0.809564    0.815344    0.815639   \n",
       "\n",
       "               6           7           8           9   ...          11  \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  ...  121.000000   \n",
       "mean     0.485356    0.482041    0.475095    0.476647  ...    0.417106   \n",
       "std      0.138984    0.132496    0.122593    0.140489  ...    0.106852   \n",
       "min      0.191442    0.206996    0.239422    0.217149  ...    0.243029   \n",
       "25%      0.413956    0.407706    0.374430    0.340586  ...    0.328808   \n",
       "50%      0.514278    0.503366    0.490648    0.516047  ...    0.401595   \n",
       "75%      0.591685    0.596135    0.576807    0.581958  ...    0.465373   \n",
       "max      0.757141    0.778362    0.725728    0.812127  ...    0.753762   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  121.000000  121.000000   \n",
       "mean     0.384452    0.381873    0.384244    0.385087    0.351127    0.359420   \n",
       "std      0.085220    0.080049    0.076207    0.081609    0.065711    0.085638   \n",
       "min      0.247516    0.245846    0.240693    0.233719    0.219495    0.211437   \n",
       "25%      0.331785    0.341970    0.340674    0.326201    0.313366    0.303785   \n",
       "50%      0.376960    0.378691    0.372790    0.379956    0.349312    0.366040   \n",
       "75%      0.414621    0.413550    0.427569    0.422410    0.377530    0.396928   \n",
       "max      0.651150    0.638429    0.603570    0.693568    0.568070    0.715409   \n",
       "\n",
       "               18          19          20  \n",
       "count  121.000000  121.000000  121.000000  \n",
       "mean     0.300543    0.343449    0.456584  \n",
       "std      0.117991    0.248394    0.293166  \n",
       "min      0.117611    0.004961    0.002109  \n",
       "25%      0.196577    0.172383    0.242203  \n",
       "50%      0.312589    0.275625    0.341444  \n",
       "75%      0.366114    0.445651    0.761467  \n",
       "max      0.685073    0.877980    0.999937  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_list = np.array(brier_score_list)\n",
    "pd.DataFrame(brier_score_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "442e09c4-125b-4041-8e5a-cdfb1542cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20594549418755445,\n",
       " 0.2027877486714525,\n",
       " 0.19144237968169536,\n",
       " 0.19625441036256136,\n",
       " 0.19540744841054306,\n",
       " 0.2010494325091784,\n",
       " 0.2100516571274058,\n",
       " 0.21722514094651538,\n",
       " 0.23089838465568097,\n",
       " 0.22033259433512759,\n",
       " 0.22481060952254125,\n",
       " 0.2364160061460449,\n",
       " 0.2522548999120726,\n",
       " 0.2501613205917494,\n",
       " 0.24542853008660054,\n",
       " 0.2336142860378907,\n",
       " 0.2185448134249856,\n",
       " 0.2139356569623583,\n",
       " 0.18557082088211846,\n",
       " 0.4363822183611017,\n",
       " 0.44726272769468556]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnls_brier = []\n",
    "for j in S : \n",
    "    value = brier_score_loss(y_true = stack_tst[stack_tst['LM'] == j][E_col], \n",
    "                             y_prob = res_nnls[stack_tst['LM'] == j], \n",
    "                             sample_weight= weight_brier[stack_tst['LM'] == j])        \n",
    "    \n",
    "    nnls_brier.append(value)\n",
    "    \n",
    "nnls_brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9fff7c4d-951e-4073-b14a-d78f5e3eaab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1827812871320524,\n",
       " 0.18230672607057283,\n",
       " 0.17529878683390304,\n",
       " 0.17974516376122437,\n",
       " 0.18349408491636887,\n",
       " 0.18559152496343614,\n",
       " 0.19372447296432999,\n",
       " 0.1987711809731614,\n",
       " 0.2147114867319932,\n",
       " 0.20351943303574496,\n",
       " 0.2109794885236613,\n",
       " 0.22056631839946958,\n",
       " 0.2352457415187923,\n",
       " 0.23556496393492193,\n",
       " 0.23013492005163297,\n",
       " 0.22199903978095875,\n",
       " 0.20577546098683178,\n",
       " 0.21560842441978026,\n",
       " 0.20449148335844267,\n",
       " 0.36464514706850254,\n",
       " 0.3910870017468162]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hill_brier = []\n",
    "for j in S : \n",
    "    value = brier_score_loss(y_true = stack_tst[stack_tst['LM'] == j][E_col], \n",
    "                             y_prob = res_hill[stack_tst['LM'] == j], \n",
    "                             sample_weight= weight_brier[stack_tst['LM'] == j])        \n",
    "    \n",
    "    hill_brier.append(value)\n",
    "    \n",
    "hill_brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8cf571c9-740e-4d42-850a-b3deb10ee34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23577216524902067,\n",
       " 0.18155086834976822,\n",
       " 0.16226859697306387,\n",
       " 0.17674065571745382,\n",
       " 0.18260326139531516,\n",
       " 0.1977451777452153,\n",
       " 0.23603166777445408,\n",
       " 0.2563542735723729,\n",
       " 0.23810492283110812,\n",
       " 0.1878733542044543,\n",
       " 0.32215979410157775,\n",
       " 0.2010897204312707,\n",
       " 0.35819839234822826,\n",
       " 0.5004989083092963,\n",
       " 0.487359209862588,\n",
       " 0.20120073959511264,\n",
       " 0.21507665267063758,\n",
       " 0.5507274680207012,\n",
       " 0.538961038961039,\n",
       " 0.6764705882352942,\n",
       " 0.5217391304347826]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_brier = []\n",
    "for j in S : \n",
    "    value = brier_score_loss(y_true = stack_tst[stack_tst['LM'] == j][E_col], \n",
    "                             y_prob = res_rf[stack_tst['LM'] == j], \n",
    "                             sample_weight= weight_brier[stack_tst['LM'] == j])        \n",
    "    \n",
    "    rf_brier.append(value)\n",
    "    \n",
    "rf_brier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f861bb4-7519-479e-9f41-f1f4bea4c79c",
   "metadata": {},
   "source": [
    "# 4. Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c58fb4-0159-4d7a-ba38-091f812a800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "\n",
    "# settings \n",
    "dir = \"/Users/pio/Google 드라이브/data/\"\n",
    "file_name = \"pbc2.csv\"\n",
    "data = pd.read_csv(dir + file_name)\n",
    "\n",
    "# drop status1 - competing risks setting\n",
    "data = data.drop(axis=1, columns =['status'])\n",
    "\n",
    "\n",
    "# ID, Time, Event, Measure Time column names\n",
    "ID_col = 'id'; T_col ='years'; E_col ='status2'; measure_T_col = 'year'\n",
    "\n",
    "# categorical variables\n",
    "nominal_col = ['drug','sex', 'ascites', 'hepatomegaly','spiders', 'edema']\n",
    "ordinal_col = ['histologic']\n",
    "\n",
    "# continuous variables\n",
    "cont_col = list(set(data.columns) - set(nominal_col) - set(ordinal_col) - set([ID_col, T_col, E_col, measure_T_col]))\n",
    "\n",
    "# window - 5 year prediction \n",
    "window = 5\n",
    "\n",
    "# S : landmark time points - 0, 0.5, 1, ..., 10\n",
    "S = np.linspace(0,10,21)\n",
    "v_years = S+window\n",
    "\n",
    "# Number of bins when discritizing \n",
    "## !!!(Actually, k_bin - 1 bins are produced)!!!\n",
    "k_bin = 5\n",
    "\n",
    "# minimal bin_size\n",
    "minimal_bin_size = window / (k_bin-1)\n",
    "\n",
    "# \n",
    "\n",
    "# for continous variables, \n",
    "## scaling -> min-max scaling &\n",
    "## imputation -> fill na's : median for continous\n",
    "for col in cont_col : \n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "    data[col] = (data[col] - min(data[col])) / (max(data[col]) - min(data[col]))\n",
    "\n",
    "# one-hot encoding for categorical variables\n",
    "data = pd.get_dummies(data, columns = nominal_col, drop_first=True)\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "# settings2\n",
    "\n",
    "# proportion of train set\n",
    "p_train = 0.7\n",
    "\n",
    "k_kfold = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cf36144-e0ad-4882-a1b4-ecb2b3a509e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_lm_cont = landmarker_cont(data=data, ID_col = ID_col, T_col = T_col, E_col = E_col, \n",
    "                window = window, S= S, measure_T_col = measure_T_col)\n",
    "\n",
    "data_lm_disc = landmarker_disc(data=data_lm_cont,ID_col = ID_col, T_col = T_col, E_col = E_col, \n",
    "                window = window, S= S, measure_T_col = measure_T_col, k_bin = k_bin, train=True)\n",
    "\n",
    "# Split IDs into train set and test set\n",
    "train_id, test_id = id_train_test_split(id_list = data[ID_col], seed_number = 1, p=0.7)\n",
    "\n",
    "# Train, test set from original form\n",
    "train = data[data[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test = data[data[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "# Train, test set for continous landmarking algorithms\n",
    "train_lm_cont = data_lm_cont[data_lm_cont[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test_lm_cont = data_lm_cont[data_lm_cont[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "# Train, test set for discrete landmarking algorithms\n",
    "train_lm_disc = data_lm_disc[data_lm_disc[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test_lm_disc = data_lm_disc[data_lm_disc[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "print(np.all(np.unique(train_lm_cont.id) == np.unique(train_lm_disc.id)))\n",
    "print(np.all(np.unique(test_lm_cont.id) == np.unique(test_lm_disc.id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "833e2e32-68e7-4615-8b16-b64de1e51fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_instance</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cox_str</td>\n",
       "      <td>&lt;lifelines.CoxPHFitter&gt;</td>\n",
       "      <td>{'penalizer': [0.006737946999085467, 0.0301973...</td>\n",
       "      <td>cox_str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cox_no_str</td>\n",
       "      <td>&lt;lifelines.CoxPHFitter&gt;</td>\n",
       "      <td>{'penalizer': [0.006737946999085467, 0.0301973...</td>\n",
       "      <td>cox_no_str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(max_iter=10000)</td>\n",
       "      <td>{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'p...</td>\n",
       "      <td>lr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>{'n_estimators': [50, 100, 300, 500], 'max_dep...</td>\n",
       "      <td>rf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GB</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>{'n_estimators': [50, 100, 300, 500], 'max_dep...</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>MLPClassifier()</td>\n",
       "      <td>{'hidden_layer_sizes': [1, 2, 3], 'activation'...</td>\n",
       "      <td>mlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>{'n_neighbors': [1, 5, 10], 'weights': ['unifo...</td>\n",
       "      <td>knn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NGB</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>{'var_smoothing': [1e-05, 1e-09, 0.1]}</td>\n",
       "      <td>ngb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADA</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>{'n_estimators': [50, 100, 300, 500], 'max_dep...</td>\n",
       "      <td>ada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name                      model_instance  \\\n",
       "0     cox_str             <lifelines.CoxPHFitter>   \n",
       "1  cox_no_str             <lifelines.CoxPHFitter>   \n",
       "2          LR  LogisticRegression(max_iter=10000)   \n",
       "3          RF            RandomForestClassifier()   \n",
       "4          GB        GradientBoostingClassifier()   \n",
       "5         MLP                     MLPClassifier()   \n",
       "6         KNN              KNeighborsClassifier()   \n",
       "7         NGB                        GaussianNB()   \n",
       "8         ADA                AdaBoostClassifier()   \n",
       "\n",
       "                                         hyperparams        type  \n",
       "0  {'penalizer': [0.006737946999085467, 0.0301973...     cox_str  \n",
       "1  {'penalizer': [0.006737946999085467, 0.0301973...  cox_no_str  \n",
       "2  {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'p...          lr  \n",
       "3  {'n_estimators': [50, 100, 300, 500], 'max_dep...          rf  \n",
       "4  {'n_estimators': [50, 100, 300, 500], 'max_dep...          gb  \n",
       "5  {'hidden_layer_sizes': [1, 2, 3], 'activation'...         mlp  \n",
       "6  {'n_neighbors': [1, 5, 10], 'weights': ['unifo...         knn  \n",
       "7             {'var_smoothing': [1e-05, 1e-09, 0.1]}         ngb  \n",
       "8  {'n_estimators': [50, 100, 300, 500], 'max_dep...         ada  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## model specifics of level 0 models\n",
    "cox_params = {'penalizer':np.exp(np.linspace(-5,1,5)),'l1_ratio':[0,0.25,0.5,0.75,1]}\n",
    "# 5*5 *2 = 50\n",
    "model_specifics_cont = pd.DataFrame({'model_name' : ['cox_str', 'cox_no_str'], \n",
    "                                'model_instance':[CoxPHFitter(),CoxPHFitter()], \n",
    "                                'hyperparams':[cox_params,cox_params], \n",
    "                                'type':['cox_str','cox_no_str']})\n",
    "\n",
    "LR_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['saga']\n",
    "} # 7 * 2 * 1 = 14\n",
    "RF_params = {'n_estimators':[50,100,300,500],'max_depth':[1,3,5]} # 4*3 = 12\n",
    "GB_params = {'n_estimators':[50,100,300,500],'max_depth':[1,3,5]} # 4*3 = 12\n",
    "MLP_params = {'hidden_layer_sizes':[1,2,3], 'activation' : ['identity', 'logistic', 'tanh', 'relu'], 'max_iter' : [1000], 'early_stopping' : [True], 'learning_rate' : ['adaptive']}\n",
    "# 3*4\n",
    "KNN_params = {'n_neighbors':[1,5,10], 'weights':['uniform', 'distance']} \n",
    "# 3*2\n",
    "NGB_params = {'var_smoothing':[1e-5, 1e-9, 1e-1]}\n",
    "# 3\n",
    "ADA_params = {'n_estimators':[50, 100, 300, 500], 'max_depth':[1,3,5]}\n",
    "# 4*10*3 = 36\n",
    "\n",
    "model_specifics_disc = pd.DataFrame({'model_name' : ['LR','RF','GB','MLP','KNN','NGB','ADA'], \n",
    "                                'model_instance':[LogisticRegression(max_iter=10000),RandomForestClassifier(),GradientBoostingClassifier(),MLPClassifier(),KNeighborsClassifier(),GaussianNB(), AdaBoostClassifier()], \n",
    "                                'hyperparams':[LR_params, RF_params, GB_params,MLP_params, KNN_params,NGB_params, ADA_params], \n",
    "                                'type':['lr','rf','gb','mlp','knn','ngb','ada']})\n",
    "\n",
    "\n",
    "model_specifics = pd.concat([model_specifics_cont,model_specifics_disc],axis=0).reset_index(drop=True)\n",
    "model_specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab408731-ece8-47ff-81d2-68ddd6c50e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f1edf25-50d4-4292-9a7a-034f3c81110c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset for training meta model\n",
      "fold : 0\n",
      "fold : 1\n",
      "fold : 2\n",
      "Re-train baseline models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.LM_cox_fitter at 0x7febde9669b0>,\n",
       " <__main__.LM_cox_fitter at 0x7febf8cd6080>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa571470>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa580780>,\n",
       " <__main__.LM_cox_fitter at 0x7febde966828>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa620898>,\n",
       " <__main__.LM_cox_fitter at 0x7febf793fd68>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa554a58>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9f6f98>,\n",
       " <__main__.LM_cox_fitter at 0x7febe37b0a90>,\n",
       " <__main__.LM_cox_fitter at 0x7febe1878be0>,\n",
       " <__main__.LM_cox_fitter at 0x7febdedacb38>,\n",
       " <__main__.LM_cox_fitter at 0x7febf7a38cc0>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9d25f8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe1568198>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9631d0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe379fe80>,\n",
       " <__main__.LM_cox_fitter at 0x7febe37a55f8>,\n",
       " <__main__.LM_cox_fitter at 0x7febdeda12e8>,\n",
       " <__main__.LM_cox_fitter at 0x7febdeda1550>,\n",
       " <__main__.LM_cox_fitter at 0x7febe160ecc0>,\n",
       " <__main__.LM_cox_fitter at 0x7febdef8f6a0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a4ba20>,\n",
       " <__main__.LM_cox_fitter at 0x7febe37b9860>,\n",
       " <__main__.LM_cox_fitter at 0x7febe00e6908>,\n",
       " <__main__.LM_cox_fitter at 0x7febf7267470>,\n",
       " <__main__.LM_cox_fitter at 0x7febf6be9550>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9f1710>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa5713c8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a760f0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe15a4940>,\n",
       " <__main__.LM_cox_fitter at 0x7febe15a4c50>,\n",
       " <__main__.LM_cox_fitter at 0x7febdefa4cf8>,\n",
       " <__main__.LM_cox_fitter at 0x7febdea69be0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a91400>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a93550>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a6bc88>,\n",
       " <__main__.LM_cox_fitter at 0x7febdea4a518>,\n",
       " <__main__.LM_cox_fitter at 0x7febdea3ce80>,\n",
       " <__main__.LM_cox_fitter at 0x7febdea3c978>,\n",
       " <__main__.LM_cox_fitter at 0x7febdefb0978>,\n",
       " <__main__.LM_cox_fitter at 0x7febdefb07b8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a7bcc0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe34aaeb8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe34aaa90>,\n",
       " <__main__.LM_cox_fitter at 0x7febe1576dd8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe34aa080>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9ead30>,\n",
       " <__main__.LM_cox_fitter at 0x7febe15760f0>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9cf240>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf8cbf668>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe0a76ba8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf14e470>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf8cbf518>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febfa63fba8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf1d59198>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf14e5f8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf14e438>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4e978>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4ec88>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4ef98>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4e5c0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d7d68>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d77b8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37b97b8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febde9c0278>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe0a93e48>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d7438>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf128908>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37922b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe3792b38>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d7208>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe3792cf8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf7a2de80>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe0a76128>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d71d0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf7972a20>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37927b8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded986a0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdea456a0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdea422b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdea4f9b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe01070f0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe01037f0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00ecb70>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf1d2ef0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15942b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded5d2b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4e2e8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe3792240>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe0a615f8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf128c88>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf11c1d0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded98dd8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded98160>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febfa59fc50>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4978>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37c2fd0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4ba8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37929e8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febde956fd0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded98fd0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4390>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4400>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4e358>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdea46908>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf7a2ddd8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4518>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4f98>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe155a2b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4320>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe1602cf8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15f38d0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15ef4a8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe1606b70>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdefb7278>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdefb17f0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdef8eb38>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf10ae80>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf12e208>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe188d1d0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######\n",
    "# 1. Generating dataset faor training meta model part \n",
    "\n",
    "\n",
    "kfold = id_kfold(id_list=train_id, n_split=k_kfold,seed_number=1)\n",
    "stacked_trn = []\n",
    "print('Generating dataset for training meta model')\n",
    "for i in range(k_kfold) : \n",
    "    print('fold : ' + str(i))\n",
    "    k_fold_trn_id, k_fold_val_id = next(kfold)\n",
    "    \n",
    "    k_fold_trn_lm_cont = train_lm_cont[train_lm_cont[ID_col].isin(k_fold_trn_id)].copy()\n",
    "    k_fold_trn_lm_disc = train_lm_disc[train_lm_disc[ID_col].isin(k_fold_trn_id)].copy()\n",
    "    \n",
    "    k_fold_val_lm_cont = train_lm_cont[train_lm_cont[ID_col].isin(k_fold_val_id)].copy()\n",
    "    k_fold_val_lm_disc = train_lm_disc[train_lm_disc[ID_col].isin(k_fold_val_id)].copy()\n",
    "    \n",
    "    # fit all baseline models        \n",
    "    stack_fit = stacker(model_specifics = model_specifics, \n",
    "                        ID = ID_col, T = T_col, E = E_col, S = S, window = window, k_bin = k_bin)\n",
    "    stack_fit.fit(data_cont= k_fold_trn_lm_cont , data_disc = k_fold_trn_lm_disc) \n",
    "    \n",
    "    # stack them for training meta model\n",
    "    stacked_trn.append(stack_fit.predict(k_fold_val_lm_cont, k_fold_val_lm_disc))\n",
    "    \n",
    "# ID_col, LM, T_col, E_col validation 순서에 맞게 모으기\n",
    "info = pd.concat([train_lm_cont[train_lm_cont[ID_col].isin(kfold.validation_fold_id[i])][[ID_col, 'LM', T_col, E_col]].reset_index(drop=True) for i in range(len(stacked_trn))], ignore_index=True)\n",
    "# kfold validation 예측 결과 모으기\n",
    "pred = b = pd.concat([pd.DataFrame(stacked_trn[i]) for i in range(len(stacked_trn))], ignore_index=True)\n",
    "new_data = pd.concat([info,pred], axis=1)\n",
    "# new_data['surv_status'] = abs(new_data[E_col]-1)\n",
    "######\n",
    "# 2. Training Part : \n",
    "# 2-1. (Re-)train baseline models on whole dataset  \n",
    "print('Re-train baseline models')\n",
    "stack_fit = stacker(model_specifics = model_specifics, \n",
    "                        ID = ID_col, T = T_col, E = E_col, S = S, window = window, k_bin = k_bin)\n",
    "\n",
    "stack_fit.fit(data_cont=train_lm_cont.copy() , data_disc = train_lm_disc.copy()) \n",
    "\n",
    "##### \n",
    "# 2-2-1. calculating ipcw weights\n",
    "ipcw_calc = ipcw_fitter(S= S, window =window)\n",
    "ipcw_calc.fit(data= new_data, T = T_col, E = E_col)\n",
    "\n",
    "#####\n",
    "# 2-2-2. Train meta model \n",
    "## NOTE : 생존확률의 결합이므로 라벨을 뒤집어줘야 함.\n",
    "nnls = nnls_constraintnnls = nnls_constraint()\n",
    "nnls.fit(x = new_data.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = abs(new_data[E_col]-1), # 생존확률의 결합이므로 라벨을 뒤집어줘야 함.\n",
    "         w = ipcw_calc.predict(new_data))\n",
    "\n",
    "\n",
    "hill = hillclimb()\n",
    "hill.fit(x = new_data.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = abs(new_data[E_col]-1), # 생존확률의 결합이므로 라벨을 뒤집어줘야 함.\n",
    "         w = ipcw_calc.predict(new_data))\n",
    "\n",
    "\n",
    "ipcw_rf = RandomForestClassifier()\n",
    "ipcw_rf.fit(X = new_data.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "            y = abs(new_data[E_col]-1), sample_weight = ipcw_calc.predict(new_data)) # 생존확률의 결합이므로 라벨을 뒤집어줘야 함.\n",
    "\n",
    "#####\n",
    "# 3. Prediction Part : \n",
    "# 3-1. predict(stack) on test set(baseline models)\n",
    "baseline_pred = stack_fit.predict(data_cont=test_lm_cont , data_disc = test_lm_disc) \n",
    "# 3-2. predict from baseline models -> meta model \n",
    "nnls_pred = nnls.predict(baseline_pred)\n",
    "hill_pred = hill.predict(baseline_pred)\n",
    "rf_pred = ipcw_rf.predict_proba(baseline_pred)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "62670b33-859f-47b0-95a4-0cb44025c052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.stacker at 0x7febe160e828>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "edcaac89-71fc-48e5-b573-612ecfc3f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c747413d-db80-4e1e-9a72-e1d72d205443",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save = '/Users/pio/Google 드라이브/github/survival ensemble/experiment/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a116e211-6767-41da-bda8-7a774cbeb7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_save + 'test.pkl', 'wb') as f :\n",
    "    dill.dump(stack_fit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5fe54-5117-44bc-9df7-85c56deb5701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49592cc7-762f-4067-b049-20a843fc061a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bac4b0-f304-4a98-a254-8cc639f451ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2afeb-c33d-410d-8799-b89b54fff703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed57c503-d81c-4c20-bc1a-1ad2372ad101",
   "metadata": {},
   "source": [
    "## Brier Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e602232d-c73f-44bc-b86a-4b96982452c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ipcw_calc = ipcw_fitter(S= S, window =window)\n",
    "test_ipcw_calc.fit(data= test_lm_cont, T = T_col, E = E_col)\n",
    "test_ipcw_pred = test_ipcw_calc.predict(data= test_lm_cont)\n",
    "\n",
    "# i for model, j for landmarked time\n",
    "brier_score_list = []\n",
    "for i in range(baseline_pred.shape[1]) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        value = brier_score_loss(y_true = abs(test_lm_cont[E_col]-1)[test_lm_cont['LM'] == j], \n",
    "                         y_prob = pd.DataFrame(baseline_pred)[test_lm_cont['LM'] == j][i], \n",
    "                         sample_weight= test_ipcw_pred[test_lm_cont['LM'] == j])\n",
    "        temp.append(value)        \n",
    "    brier_score_list.append(temp)\n",
    "    \n",
    "res = pd.DataFrame(brier_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "82bb7352-2bf2-4b1d-8d3b-0ba955901e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_brier = res.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8906c3d2-2635-42ab-9871-ea70ca033f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37]),)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(mean_brier[0:50] == min(mean_brier[0:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8141643d-6daa-4aec-94f1-5c968ae40bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "brier_cox = []; brier_nnls = [];brier_hill = []; brier_rf = [] \n",
    "for j in S : \n",
    "    brier_cox.append(brier_score_loss(y_true = abs(test_lm_cont[E_col]-1)[test_lm_cont['LM'] == j], \n",
    "                         y_prob = pd.DataFrame(baseline_pred)[test_lm_cont['LM'] == j][37], \n",
    "                         sample_weight= test_ipcw_pred[test_lm_cont['LM'] == j]))\n",
    "    brier_nnls.append(brier_score_loss(y_true = abs(test_lm_cont[E_col]-1)[test_lm_cont['LM'] == j], \n",
    "                     y_prob = nnls_pred[test_lm_cont['LM'] == j], \n",
    "                     sample_weight= test_ipcw_pred[test_lm_cont['LM'] == j]))        \n",
    "    brier_hill.append(brier_score_loss(y_true = abs(test_lm_cont[E_col]-1)[test_lm_cont['LM'] == j], \n",
    "                     y_prob = hill_pred[test_lm_cont['LM'] == j], \n",
    "                     sample_weight= test_ipcw_pred[test_lm_cont['LM'] == j]))\n",
    "    brier_rf.append(brier_score_loss(y_true = abs(test_lm_cont[E_col]-1)[test_lm_cont['LM'] == j], \n",
    "                     y_prob = rf_pred[test_lm_cont['LM'] == j], \n",
    "                     sample_weight= test_ipcw_pred[test_lm_cont['LM'] == j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bb3de2ba-d3fa-426d-822f-71b568b53c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cox</th>\n",
       "      <th>nnls</th>\n",
       "      <th>hill</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118384</td>\n",
       "      <td>0.123691</td>\n",
       "      <td>0.102437</td>\n",
       "      <td>0.087333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.120781</td>\n",
       "      <td>0.121054</td>\n",
       "      <td>0.099670</td>\n",
       "      <td>0.098289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107974</td>\n",
       "      <td>0.111176</td>\n",
       "      <td>0.096424</td>\n",
       "      <td>0.102428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114432</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.106345</td>\n",
       "      <td>0.117033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123589</td>\n",
       "      <td>0.123544</td>\n",
       "      <td>0.113396</td>\n",
       "      <td>0.137969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.128292</td>\n",
       "      <td>0.124807</td>\n",
       "      <td>0.108267</td>\n",
       "      <td>0.124241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.144555</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.115631</td>\n",
       "      <td>0.126728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.151342</td>\n",
       "      <td>0.149734</td>\n",
       "      <td>0.139779</td>\n",
       "      <td>0.134943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.170002</td>\n",
       "      <td>0.164642</td>\n",
       "      <td>0.150203</td>\n",
       "      <td>0.144462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.138115</td>\n",
       "      <td>0.142257</td>\n",
       "      <td>0.129478</td>\n",
       "      <td>0.129396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.161951</td>\n",
       "      <td>0.175720</td>\n",
       "      <td>0.160722</td>\n",
       "      <td>0.199838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.186205</td>\n",
       "      <td>0.187064</td>\n",
       "      <td>0.168506</td>\n",
       "      <td>0.198031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.242473</td>\n",
       "      <td>0.226977</td>\n",
       "      <td>0.223888</td>\n",
       "      <td>0.251740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.228283</td>\n",
       "      <td>0.228176</td>\n",
       "      <td>0.220377</td>\n",
       "      <td>0.275598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.212404</td>\n",
       "      <td>0.216857</td>\n",
       "      <td>0.195245</td>\n",
       "      <td>0.268616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.210946</td>\n",
       "      <td>0.214052</td>\n",
       "      <td>0.200963</td>\n",
       "      <td>0.288268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.220046</td>\n",
       "      <td>0.240214</td>\n",
       "      <td>0.263947</td>\n",
       "      <td>0.402133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.175453</td>\n",
       "      <td>0.220091</td>\n",
       "      <td>0.277166</td>\n",
       "      <td>0.409356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.210592</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>0.331233</td>\n",
       "      <td>0.496483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.425859</td>\n",
       "      <td>0.303167</td>\n",
       "      <td>0.199911</td>\n",
       "      <td>0.144562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.218044</td>\n",
       "      <td>0.163445</td>\n",
       "      <td>0.047785</td>\n",
       "      <td>0.020778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cox      nnls      hill        rf\n",
       "0   0.118384  0.123691  0.102437  0.087333\n",
       "1   0.120781  0.121054  0.099670  0.098289\n",
       "2   0.107974  0.111176  0.096424  0.102428\n",
       "3   0.114432  0.117647  0.106345  0.117033\n",
       "4   0.123589  0.123544  0.113396  0.137969\n",
       "5   0.128292  0.124807  0.108267  0.124241\n",
       "6   0.144555  0.139030  0.115631  0.126728\n",
       "7   0.151342  0.149734  0.139779  0.134943\n",
       "8   0.170002  0.164642  0.150203  0.144462\n",
       "9   0.138115  0.142257  0.129478  0.129396\n",
       "10  0.161951  0.175720  0.160722  0.199838\n",
       "11  0.186205  0.187064  0.168506  0.198031\n",
       "12  0.242473  0.226977  0.223888  0.251740\n",
       "13  0.228283  0.228176  0.220377  0.275598\n",
       "14  0.212404  0.216857  0.195245  0.268616\n",
       "15  0.210946  0.214052  0.200963  0.288268\n",
       "16  0.220046  0.240214  0.263947  0.402133\n",
       "17  0.175453  0.220091  0.277166  0.409356\n",
       "18  0.210592  0.270736  0.331233  0.496483\n",
       "19  0.425859  0.303167  0.199911  0.144562\n",
       "20  0.218044  0.163445  0.047785  0.020778"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_brier = pd.DataFrame({'cox':brier_cox,'nnls': brier_nnls, 'hill':brier_hill, 'rf':brier_rf})\n",
    "res_brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "283cece7-479a-4f13-8887-0bd531dbd929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cox     0.181415\n",
       "nnls    0.179242\n",
       "hill    0.164351\n",
       "rf      0.198011\n",
       "dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_brier.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ea09c-2e45-496e-a64f-3680d3f83335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31ab4236-99fa-48e0-81e8-f470a61d82d1",
   "metadata": {},
   "source": [
    "## C-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5be06-a668-4d29-bfd8-3ad9b2a830f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909424</td>\n",
       "      <td>0.899175</td>\n",
       "      <td>0.896497</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.846071</td>\n",
       "      <td>0.822738</td>\n",
       "      <td>0.834572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603279</td>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.672862</td>\n",
       "      <td>0.729258</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.905759</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.898885</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.883205</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.844995</td>\n",
       "      <td>0.825183</td>\n",
       "      <td>0.834572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603279</td>\n",
       "      <td>0.596825</td>\n",
       "      <td>0.676580</td>\n",
       "      <td>0.737991</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.905236</td>\n",
       "      <td>0.895047</td>\n",
       "      <td>0.899682</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.884910</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.855249</td>\n",
       "      <td>0.844995</td>\n",
       "      <td>0.825183</td>\n",
       "      <td>0.830855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609836</td>\n",
       "      <td>0.596825</td>\n",
       "      <td>0.676580</td>\n",
       "      <td>0.737991</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.904712</td>\n",
       "      <td>0.895637</td>\n",
       "      <td>0.902070</td>\n",
       "      <td>0.888633</td>\n",
       "      <td>0.883205</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.855249</td>\n",
       "      <td>0.846071</td>\n",
       "      <td>0.823961</td>\n",
       "      <td>0.828996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613115</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.680297</td>\n",
       "      <td>0.737991</td>\n",
       "      <td>0.621795</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.904712</td>\n",
       "      <td>0.895637</td>\n",
       "      <td>0.906847</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.853039</td>\n",
       "      <td>0.846071</td>\n",
       "      <td>0.826406</td>\n",
       "      <td>0.825279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616393</td>\n",
       "      <td>0.612698</td>\n",
       "      <td>0.698885</td>\n",
       "      <td>0.746725</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.879581</td>\n",
       "      <td>0.879717</td>\n",
       "      <td>0.890127</td>\n",
       "      <td>0.817972</td>\n",
       "      <td>0.799659</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.837569</td>\n",
       "      <td>0.822390</td>\n",
       "      <td>0.801956</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724590</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.747212</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.879581</td>\n",
       "      <td>0.879717</td>\n",
       "      <td>0.890127</td>\n",
       "      <td>0.817972</td>\n",
       "      <td>0.799659</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.837569</td>\n",
       "      <td>0.822390</td>\n",
       "      <td>0.801956</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724590</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.747212</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.882723</td>\n",
       "      <td>0.879127</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.802217</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.830939</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>0.801956</td>\n",
       "      <td>0.661710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.747212</td>\n",
       "      <td>0.751092</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.882723</td>\n",
       "      <td>0.879127</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.802217</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.830939</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>0.801956</td>\n",
       "      <td>0.661710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.747212</td>\n",
       "      <td>0.751092</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.882723</td>\n",
       "      <td>0.879127</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.802217</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.830939</td>\n",
       "      <td>0.814855</td>\n",
       "      <td>0.801956</td>\n",
       "      <td>0.661710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.747212</td>\n",
       "      <td>0.751092</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4      5         6   \\\n",
       "0    0.909424  0.899175  0.896497  0.892473  0.882353  0.886  0.854144   \n",
       "1    0.905759  0.896226  0.898885  0.892473  0.883205  0.887  0.856354   \n",
       "2    0.905236  0.895047  0.899682  0.890937  0.884910  0.887  0.855249   \n",
       "3    0.904712  0.895637  0.902070  0.888633  0.883205  0.885  0.855249   \n",
       "4    0.904712  0.895637  0.906847  0.890937  0.884058  0.886  0.853039   \n",
       "..        ...       ...       ...       ...       ...    ...       ...   \n",
       "116  0.879581  0.879717  0.890127  0.817972  0.799659  0.863  0.837569   \n",
       "117  0.879581  0.879717  0.890127  0.817972  0.799659  0.863  0.837569   \n",
       "118  0.882723  0.879127  0.875000  0.811828  0.802217  0.862  0.830939   \n",
       "119  0.882723  0.879127  0.875000  0.811828  0.802217  0.862  0.830939   \n",
       "120  0.882723  0.879127  0.875000  0.811828  0.802217  0.862  0.830939   \n",
       "\n",
       "           7         8         9   ...        11        12        13  \\\n",
       "0    0.846071  0.822738  0.834572  ...  0.603279  0.590476  0.672862   \n",
       "1    0.844995  0.825183  0.834572  ...  0.603279  0.596825  0.676580   \n",
       "2    0.844995  0.825183  0.830855  ...  0.609836  0.596825  0.676580   \n",
       "3    0.846071  0.823961  0.828996  ...  0.613115  0.609524  0.680297   \n",
       "4    0.846071  0.826406  0.825279  ...  0.616393  0.612698  0.698885   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "116  0.822390  0.801956  0.689591  ...  0.724590  0.707937  0.747212   \n",
       "117  0.822390  0.801956  0.689591  ...  0.724590  0.707937  0.747212   \n",
       "118  0.814855  0.801956  0.661710  ...  0.691803  0.695238  0.747212   \n",
       "119  0.814855  0.801956  0.661710  ...  0.691803  0.695238  0.747212   \n",
       "120  0.814855  0.801956  0.661710  ...  0.691803  0.695238  0.747212   \n",
       "\n",
       "           14        15        16        17        18        19        20  \n",
       "0    0.729258  0.615385  0.577320  0.726027  0.514286  0.771429  0.772727  \n",
       "1    0.737991  0.615385  0.577320  0.712329  0.485714  0.771429  0.772727  \n",
       "2    0.737991  0.615385  0.587629  0.726027  0.514286  0.742857  0.772727  \n",
       "3    0.737991  0.621795  0.587629  0.767123  0.542857  0.742857  0.772727  \n",
       "4    0.746725  0.641026  0.608247  0.780822  0.542857  0.742857  0.772727  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "116  0.781659  0.692308  0.649485  0.534247  0.514286  0.657143  0.818182  \n",
       "117  0.781659  0.692308  0.649485  0.534247  0.514286  0.657143  0.818182  \n",
       "118  0.751092  0.660256  0.649485  0.520548  0.514286  0.657143  0.818182  \n",
       "119  0.751092  0.660256  0.649485  0.520548  0.514286  0.657143  0.818182  \n",
       "120  0.751092  0.660256  0.649485  0.520548  0.514286  0.657143  0.818182  \n",
       "\n",
       "[121 rows x 21 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i for model, j for landmarked time\n",
    "c_index_list = []\n",
    "for i in range(baseline_pred.shape[1]) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        c_index_value = concordance_index(event_times = test_lm_cont[test_lm_cont['LM'] == j][T_col], \n",
    "                                          predicted_scores = pd.DataFrame(baseline_pred)[test_lm_cont['LM'] == j][i],\n",
    "                                          event_observed = test_lm_cont[test_lm_cont['LM'] == j][E_col])\n",
    "        temp.append(c_index_value)        \n",
    "    c_index_list.append(temp)\n",
    "    \n",
    "pd.DataFrame(c_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5d6b5c01-13b5-48b8-a6df-c7ca6517b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_index_nnls = []; c_index_hill = []; c_index_rf = [] \n",
    "for j in S : \n",
    "    c_index_nnls.append(concordance_index(event_times = test_lm_cont[test_lm_cont['LM'] == j][T_col], \n",
    "                  predicted_scores = nnls_pred[test_lm_cont['LM'] == j],\n",
    "                  event_observed = test_lm_cont[test_lm_cont['LM'] == j][E_col])\n",
    "\n",
    ")        \n",
    "    c_index_hill.append(concordance_index(event_times = test_lm_cont[test_lm_cont['LM'] == j][T_col], \n",
    "                  predicted_scores = hill_pred[test_lm_cont['LM'] == j],\n",
    "                  event_observed = test_lm_cont[test_lm_cont['LM'] == j][E_col])\n",
    "\n",
    ")\n",
    "    c_index_rf.append(concordance_index(event_times = test_lm_cont[test_lm_cont['LM'] == j][T_col], \n",
    "                  predicted_scores = rf_pred[test_lm_cont['LM'] == j],\n",
    "                  event_observed = test_lm_cont[test_lm_cont['LM'] == j][E_col])\n",
    "\n",
    ")\n",
    "\n",
    "result_c_meta = pd.DataFrame({'nnls': c_index_nnls, 'hill':c_index_hill, 'rf':c_index_rf})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e99cad9e-4e4c-4557-bfb3-ed04443ca11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cox</th>\n",
       "      <th>nnls</th>\n",
       "      <th>hill</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.901571</td>\n",
       "      <td>0.904188</td>\n",
       "      <td>0.901047</td>\n",
       "      <td>0.893194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.902123</td>\n",
       "      <td>0.896816</td>\n",
       "      <td>0.868809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.891720</td>\n",
       "      <td>0.919586</td>\n",
       "      <td>0.894108</td>\n",
       "      <td>0.887341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884793</td>\n",
       "      <td>0.909370</td>\n",
       "      <td>0.898618</td>\n",
       "      <td>0.865975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.880648</td>\n",
       "      <td>0.906223</td>\n",
       "      <td>0.890878</td>\n",
       "      <td>0.862745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>0.874500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.853039</td>\n",
       "      <td>0.900552</td>\n",
       "      <td>0.900552</td>\n",
       "      <td>0.844199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.833154</td>\n",
       "      <td>0.857912</td>\n",
       "      <td>0.863294</td>\n",
       "      <td>0.856835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.823961</td>\n",
       "      <td>0.842298</td>\n",
       "      <td>0.858191</td>\n",
       "      <td>0.864303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.782528</td>\n",
       "      <td>0.825279</td>\n",
       "      <td>0.819703</td>\n",
       "      <td>0.798327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>0.825352</td>\n",
       "      <td>0.763380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.740984</td>\n",
       "      <td>0.747541</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.737705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.715873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.698885</td>\n",
       "      <td>0.739777</td>\n",
       "      <td>0.754647</td>\n",
       "      <td>0.684015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.751092</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.829694</td>\n",
       "      <td>0.762009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.711538</td>\n",
       "      <td>0.701923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.701031</td>\n",
       "      <td>0.680412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.726027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cox      nnls      hill        rf\n",
       "0   0.901571  0.904188  0.901047  0.893194\n",
       "1   0.886792  0.902123  0.896816  0.868809\n",
       "2   0.891720  0.919586  0.894108  0.887341\n",
       "3   0.884793  0.909370  0.898618  0.865975\n",
       "4   0.880648  0.906223  0.890878  0.862745\n",
       "5   0.883000  0.931000  0.918000  0.874500\n",
       "6   0.853039  0.900552  0.900552  0.844199\n",
       "7   0.833154  0.857912  0.863294  0.856835\n",
       "8   0.823961  0.842298  0.858191  0.864303\n",
       "9   0.782528  0.825279  0.819703  0.798327\n",
       "10  0.802817  0.797183  0.825352  0.763380\n",
       "11  0.740984  0.747541  0.770492  0.737705\n",
       "12  0.707937  0.739683  0.746032  0.715873\n",
       "13  0.698885  0.739777  0.754647  0.684015\n",
       "14  0.751092  0.777293  0.829694  0.762009\n",
       "15  0.602564  0.660256  0.711538  0.701923\n",
       "16  0.618557  0.649485  0.701031  0.680412\n",
       "17  0.767123  0.780822  0.821918  0.726027\n",
       "18  0.600000  0.657143  0.714286  0.628571\n",
       "19  0.771429  0.771429  0.800000  0.828571\n",
       "20  1.000000  0.954545  1.000000  0.909091"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "da292a52-d851-4285-ba71-f277cb7a1b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cox     0.794409\n",
       "nnls    0.817795\n",
       "hill    0.834105\n",
       "rf      0.797800\n",
       "dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_c_index.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ccffe8-c179-4fa9-9f56-d6e760856d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48492f45-2519-4c9b-be45-6b2a5c8ac835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63accd27-aa4f-4a25-9045-a8cb4b2a6fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4c6dd-2f2d-459c-a4a7-ee6e02138eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
