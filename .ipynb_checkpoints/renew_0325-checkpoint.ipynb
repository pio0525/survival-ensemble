{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d629e794-1413-4cc0-ac83-5b13ff0382fb",
   "metadata": {},
   "source": [
    "# TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e7686b-cf3a-43ca-9e70-f4ef524801ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from sksurv.util import Surv\n",
    "# from sksurv.metrics import concordance_index_ipcw, concordance_index_censored\n",
    "\n",
    "# models \n",
    "import lifelines\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# others\n",
    "from numpy import inf\n",
    "from random import sample, seed\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "import itertools\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "from lifelines.utils import concordance_index\n",
    "import sys \n",
    "import os\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('mode.chained_assignment',  None)\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54f2daea-e10f-4d92-b9b1-dde6a565fcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import copy\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_error,brier_score_loss\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926db770-3f52-4918-8dbb-e75d2029320c",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1bb9fd-9016-4179-8ca5-be70c4612f27",
   "metadata": {},
   "source": [
    "## id_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afcbfbe-06cd-4766-9c5a-505fa061a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given list of IDs, split ids into train with p proportion\n",
    "# return list of train id and test id\n",
    "def id_train_test_split(id_list, seed_number = 1, p=0.7) :\n",
    "    id_list = np.unique(id_list)\n",
    "    \n",
    "    n_train = round(len(id_list)*0.7)\n",
    "    n_test = len(id_list) - n_train\n",
    "    \n",
    "    # IDs within train set and test set\n",
    "    seed(seed_number)\n",
    "    train_id = list(sample(set(id_list), n_train))\n",
    "    test_id = list(set(id_list).difference(set(train_id)))\n",
    "    return train_id, test_id\n",
    "    \n",
    "# Train_test split of rows example) \n",
    "## train = data[data[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "## test = data[data[ID_col].isin(test_id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df5b02-1f17-4398-9c78-8b13989510a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a18fce7-cb7d-48e4-90c5-63d868652f72",
   "metadata": {},
   "source": [
    "## id_bootstrapping_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c9da63-10de-47e9-8c74-3a7dd152d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_bootstrapping_split(id_list, seed_number) :\n",
    "    return inbag_id_count, outbag_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5230f66-93e2-40a1-a523-893391d4c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given list of IDs, split ids into k-fold train/validation set \n",
    "class id_kfold :\n",
    "    def __init__(self,id_list, n_split,seed_number=1) : \n",
    "        self.id_list = np.unique(id_list)\n",
    "        self.n_split = n_split\n",
    "        self.seed_number=  seed_number\n",
    "\n",
    "        self.kf = KFold(n_splits = n_split, shuffle =True, random_state = seed_number)\n",
    "        \n",
    "        self.n_iter = 0 # initializing iteration\n",
    "        \n",
    "        train_fold_id = [] ; validation_fold_id = []\n",
    "        for train_unique_id_idx, validation_unique_id_idx in self.kf.split(self.id_list) :\n",
    "                train_fold_id.append(self.id_list[train_unique_id_idx])\n",
    "                validation_fold_id.append(self.id_list[validation_unique_id_idx])\n",
    "\n",
    "        self.train_fold_id = train_fold_id\n",
    "        self.validation_fold_id = validation_fold_id\n",
    "        \n",
    "        return\n",
    "                \n",
    "    def __iter__(self) : \n",
    "        return \n",
    "    \n",
    "    def __next__(self) : \n",
    "        if self.n_iter > self.n_split :\n",
    "            raise StopIteration\n",
    "            \n",
    "        else :\n",
    "            self.n_iter += 1\n",
    "            return self.train_fold_id[self.n_iter-1], self.validation_fold_id[self.n_iter-1]\n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0354ee8-f304-4611-9859-e9dfb0a1c184",
   "metadata": {},
   "source": [
    "## landmarker_cont & landmarker_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d03254-8e67-4c66-8507-bf06b0c9f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given original form of data,\n",
    "# Return landmarked dataset in continuous form\n",
    "def landmarker_cont(data,ID_col, T_col,E_col,window,S,measure_T_col) :\n",
    "    super_set = pd.DataFrame()\n",
    "    \n",
    "    for t in S :\n",
    "        # LM point 이후 생존자\n",
    "        # R_t_idx = np.where(data[T_col] > t )\n",
    "        R_t_idx = np.where( (data[T_col] > t ) & (data[measure_T_col] <= t ) )\n",
    "        R_t = data.loc[R_t_idx].reset_index(drop=True)\n",
    "        \n",
    "        # LM point - 변수로 지정. strata로 나중에 지정하려고\n",
    "        R_t['LM'] = t\n",
    "        \n",
    "        # time & event 수정 필요한 그룹. -> t+w 시점에서 censoring된 것으로 처리\n",
    "        occurance_out_index = np.where(R_t[T_col] > t+window)\n",
    "        for idx in occurance_out_index :\n",
    "            R_t.loc[idx,T_col] = t+window\n",
    "            R_t.loc[idx,E_col] = 0\n",
    "            \n",
    "        super_set = pd.concat([super_set,R_t],axis=0)\n",
    "        \n",
    "        # Leave only last measurements per each id & lm points\n",
    "        super_set = super_set.drop_duplicates([ID_col,'LM'],keep='last')\n",
    "        \n",
    "        # Time elapsed from measurement & LM time\n",
    "        super_set['diff'] = super_set['LM'] - super_set[measure_T_col]\n",
    "                \n",
    "    return  super_set.drop(columns = [measure_T_col], axis=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Given landmarked dataset in continuous form(output from Landmarker_cont),\n",
    "# Return discretized landmarked dataset.\n",
    "## Note that, if arg train == True, then \n",
    "def landmarker_disc(data,ID_col, T_col,E_col,window,S,measure_T_col, k_bin, train=True) :\n",
    "    super_set = data\n",
    "    discretized_set = pd.DataFrame()\n",
    "\n",
    "    for s in S :\n",
    "        temp = super_set[super_set['LM'] == s].reset_index(drop=True)\n",
    "        temp_bin = np.linspace(s, s+window, k_bin)\n",
    "\n",
    "        temp_digitize = np.digitize(temp[T_col],temp_bin, right =True)\n",
    "        temp['bin'] = temp_digitize    \n",
    "\n",
    "        \n",
    "        for i in range(temp.shape[0]) :\n",
    "            temp2 = temp.copy().iloc[i,:]\n",
    "            if train :\n",
    "                for j in range(1,temp_digitize[i]) :\n",
    "                    temp2['bin'] = j\n",
    "                    temp2[E_col] = 0\n",
    "                    discretized_set = pd.concat([discretized_set,temp2],axis=1)\n",
    "                    \n",
    "                temp2['bin'] = temp_digitize[i]\n",
    "                temp2[E_col] = temp.loc[i,E_col]\n",
    "                discretized_set = pd.concat([discretized_set,temp2],axis=1)\n",
    "                \n",
    "            else :\n",
    "                for j in range(1,k_bin) :\n",
    "                    temp2['bin'] = j\n",
    "                    temp2[E_col] = 0\n",
    "                    discretized_set = pd.concat([discretized_set,temp2],axis=1)\n",
    "                \n",
    "        \n",
    "    discretized_set = discretized_set.T\n",
    "    \n",
    "    return discretized_set.drop(columns = [T_col], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0d5253-6d1d-402e-bce6-c5224cefc938",
   "metadata": {},
   "source": [
    "## set_hyperparams(model_specifics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40772cc-7cfc-48e6-9b8f-102293b5573f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d484d577-0abd-4eaa-a0af-b26c356a2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given model_specifics(dictionary)\n",
    "# Create list of model instances with hyperparameters from model_specifics(baseline)\n",
    "def set_hyperparams(model_specifics) :\n",
    "    model_list = []\n",
    "    for g_1 in range(model_specifics.shape[0]) : \n",
    "        model_name = model_specifics.loc[g_1,'model_name'] \n",
    "        model_hyperparams = model_specifics.loc[g_1,'hyperparams']\n",
    "        model_type = model_specifics.loc[g_1,'type']\n",
    "\n",
    "        param_combinations = list(itertools.product(*list(model_hyperparams.values())))\n",
    "        param_names = list(model_hyperparams.keys())\n",
    "\n",
    "        # change hyperparameters according to model_hyperparameter grid\n",
    "        for g_2 in range(len(param_combinations)) :\n",
    "            model_instance = deepcopy(model_specifics.loc[g_1,'model_instance'])\n",
    "            for param_idx in range(len(param_names)) :\n",
    "                setattr(model_instance, param_names[param_idx], param_combinations[g_2][param_idx])\n",
    "            model_list.append(model_instance)    \n",
    "    return model_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4496c-81a2-446c-896b-831da357c079",
   "metadata": {},
   "source": [
    "# CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0740a3e4-15f3-47e7-8f6d-9fe133bfcfa8",
   "metadata": {},
   "source": [
    "## id_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02f972f-6ebc-487e-a965-3ad781ea3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given list of IDs, split ids into k-fold train/validation set \n",
    "class id_kfold :\n",
    "    def __init__(self,id_list, n_split,seed_number=1) : \n",
    "        self.id_list = np.unique(id_list)\n",
    "        self.n_split = n_split\n",
    "        self.seed_number=  seed_number\n",
    "\n",
    "        self.kf = KFold(n_splits = n_split, shuffle =True, random_state = seed_number)\n",
    "        \n",
    "        self.n_iter = 0 # initializing iteration\n",
    "        \n",
    "        train_fold_id = [] ; validation_fold_id = []\n",
    "        for train_unique_id_idx, validation_unique_id_idx in self.kf.split(self.id_list) :\n",
    "                train_fold_id.append(self.id_list[train_unique_id_idx])\n",
    "                validation_fold_id.append(self.id_list[validation_unique_id_idx])\n",
    "\n",
    "        self.train_fold_id = train_fold_id\n",
    "        self.validation_fold_id = validation_fold_id\n",
    "        \n",
    "        return\n",
    "                \n",
    "    def __iter__(self) : \n",
    "        return \n",
    "    \n",
    "    def __next__(self) : \n",
    "        if self.n_iter > self.n_split :\n",
    "            raise StopIteration\n",
    "            \n",
    "        else :\n",
    "            self.n_iter += 1\n",
    "            return self.train_fold_id[self.n_iter-1], self.validation_fold_id[self.n_iter-1]\n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c852bca-b307-4a5c-aad2-9e2867940248",
   "metadata": {},
   "source": [
    "## ipcw_fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9833bc7-dca1-45eb-919d-35604ebc0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit KaplanMeier model on each landmarking time point\n",
    "# return(predict) Inverse Probabliity of Censoring Weight(IPCW) * n(S) on any given dataset\n",
    "\n",
    "## Note : fit and predict method requires continous type of landmarking dataset. \n",
    "## Note2 : censoring될 확률이 높을수록(survival estimate from KM이 작을수록) -> (관측이 되었다면) 관측치의 weight 높아짐.\n",
    "class ipcw_fitter : \n",
    "    def __init__(self, S, window) : \n",
    "        self.S = S\n",
    "        self.window = window\n",
    "        self.censoring_model = [KaplanMeierFitter() for i in range(len(S))]\n",
    "        return\n",
    "    \n",
    "\n",
    "    # T, E, W 는 해당하는 각각 time, event indcicator, weight에 해당하는 칼럼 네임.\n",
    "    ## Note : 즉, bagging할 시 먼저 웨이트를 붙여서 들어와야 됨. \n",
    "    def fit(self, data, T, E, W = None) : \n",
    "        self.T = T\n",
    "        self.E = E\n",
    "        for i in range(len(self.S)) : \n",
    "            risk_set = data.loc[data['LM'] == self.S[i],]\n",
    "            \n",
    "            # Here, event is censoring, so indicator is reversed.\n",
    "            time = risk_set[T]; event = abs(risk_set[E]-1); \n",
    "            if W is  None : \n",
    "                self.censoring_model[i] = self.censoring_model[i].fit(durations = np.array(time), event_observed = np.array(event))\n",
    "            else :\n",
    "                weight = risk_set[W]\n",
    "                self.censoring_model[i] = self.censoring_model[i].fit(durations = time, event_observed = event, weights  = weight)\n",
    "        return \n",
    "    \n",
    "    def predict(self, data) : \n",
    "        eps = 0.000000001\n",
    "        n_S = [sum(data['LM']==s) for s in self.S]# number of risk sets on each landmark time point\n",
    "        \n",
    "        \n",
    "        ipcw_list = []\n",
    "        for i in range(data.shape[0]) : \n",
    "            lm_time = data['LM'][i]\n",
    "            lm_index= np.where(self.S==lm_time)[0][0]\n",
    "            \n",
    "            ipcw_list.append(1/(self.censoring_model[lm_index].predict(data[T_col][i]- eps) * n_S[lm_index]))\n",
    "        \n",
    "        ipcw_list = np.array(ipcw_list)\n",
    "        ipcw_list[(data[self.E]==0)&(data[self.T] < data['LM']+self.window)] = 0\n",
    "\n",
    "        return ipcw_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7072a-c86c-4002-8b9a-9b1bc01a30c4",
   "metadata": {},
   "source": [
    "## LM_cox_fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8fbf4e-828a-4cfc-ae9b-68410689de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : model and specifics\n",
    "# output : predicted v-year survival estimates\n",
    "class LM_cox_fitter :\n",
    "    def __init__(self, model, ID, T, E, S, window, degree= 2, stratified = False) : \n",
    "        self.model = deepcopy(model)\n",
    "        self.ID = ID\n",
    "        self.T = T\n",
    "        self.E = E\n",
    "        self.S = S\n",
    "        self.window = window\n",
    "        \n",
    "        self.degree = degree\n",
    "        self.stratified = stratified\n",
    "        \n",
    "    def fit(self, data, weight = None) : \n",
    "        \n",
    "        temp_data = deepcopy(data)        \n",
    "        x_cols = list(temp_data.columns)\n",
    "        x_cols.remove(self.ID);x_cols.remove(self.T);x_cols.remove(self.E);x_cols.remove('LM');x_cols.remove('diff')\n",
    "        self.x_cols = x_cols\n",
    "\n",
    "        # making interaction term between Xs and 1, ... , d degree LM terms\n",
    "        for i in range(len(x_cols)) : \n",
    "            for d in range(1,self.degree+1) : \n",
    "                col_name = x_cols[i] + '_' + str(d)\n",
    "                value = temp_data[x_cols[i]] * (temp_data['LM'])**d\n",
    "                temp_data[col_name] = value\n",
    "\n",
    "        # Add weight column\n",
    "        if weight is not None: \n",
    "            data['weight'] = weight\n",
    "            \n",
    "        if self.stratified :   \n",
    "            # default : landmarked time has 2nd degree relationship with baseline hazard\n",
    "            temp_data['LM_2'] = (temp_data['LM'])**2\n",
    "            \n",
    "            if weight is None : \n",
    "                self.model.fit(df = temp_data.drop([self.ID],axis=1), duration_col = self.T, event_col = self.E, robust =True) # no strata on LM\n",
    "            else : \n",
    "                self.model.fit(df = temp_data.drop([self.ID],axis=1), duration_col = self.T, event_col = self.E, wieghts_col = 'weight', robust =True) # no strata on LM\n",
    "        else : \n",
    "            if weight is None : \n",
    "                self.model.fit(df = temp_data.drop([self.ID],axis=1), duration_col = self.T, event_col = self.E, strata = ['LM']) # strata on LM\n",
    "            else :\n",
    "                self.model.fit(df = temp_data.drop([self.ID],axis=1), duration_col = self.T, event_col = self.E, strata = ['LM'], wieghts_col = 'weight', robust =True) # strata on LM\n",
    "                \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, data, v = None) : \n",
    "        if v == None : \n",
    "            v = self.window\n",
    "            \n",
    "        temp_data = deepcopy(data)        \n",
    "\n",
    "        # making interaction term between Xs and 1, ... , d degree LM terms\n",
    "        for i in range(len(self.x_cols)) : \n",
    "            for d in range(1,self.degree+1) : \n",
    "                col_name = self.x_cols[i] + '_' + str(d)\n",
    "                value = temp_data[self.x_cols[i]] * (temp_data['LM'])**d\n",
    "                temp_data[col_name] = value\n",
    "                \n",
    "        if self.stratified :   \n",
    "            # default : landmarked time has 2nd degree relationship with baseline hazard\n",
    "            temp_data['LM_2'] = (temp_data['LM'])**2\n",
    "            surv_est_mat = self.model.predict_survival_function(X = temp_data, times = self.S + v)\n",
    "        else : \n",
    "            surv_est_mat = self.model.predict_survival_function(X = temp_data, times = self.S + v)\n",
    "            \n",
    "        v_year = temp_data.LM + v\n",
    "\n",
    "        v_year_surv_prob = []\n",
    "        for idx in v_year.index : \n",
    "            value = surv_est_mat.loc[v_year[idx],idx]\n",
    "            v_year_surv_prob.append(value)\n",
    "            \n",
    "        return np.array(v_year_surv_prob)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76fc54-cad3-4161-9326-39f99a34c8f9",
   "metadata": {},
   "source": [
    "## LM_sklearn_fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1dbc023-a6e5-4b79-8979-b192557f28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : model and specifics\n",
    "# output : predicted v-year survival estimates\n",
    "class LM_sklearn_fitter : \n",
    "    def __init__(self, model, ID, E, k_bin) : \n",
    "        self.model = deepcopy(model)\n",
    "        self.ID = ID\n",
    "        self.E = E\n",
    "        self.k_bin = k_bin\n",
    "        \n",
    "        \n",
    "    def fit(self, data, weight = None) : \n",
    "        if weight is None : \n",
    "            self.model.fit(data.drop([self.E, self.ID], axis=1), data[self.E])\n",
    "        \n",
    "        else :\n",
    "            self.model.fit(data.drop([self.E, self.ID], axis=1), data[self.E], weight)\n",
    "                        \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, data) : \n",
    "        data = data.drop_duplicates(subset =[ID_col, 'LM'])\n",
    "\n",
    "        v_year_surv_prob=1\n",
    "        for i in range(1,self.k_bin) : \n",
    "            data['bin'] = i\n",
    "            v_year_surv_prob = v_year_surv_prob*self.model.predict_proba(data.drop([self.E, self.ID],axis=1))[:,0]\n",
    "\n",
    "        return np.array(v_year_surv_prob)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33dcf2f-09b7-4c45-a82b-6aa3e149b3e1",
   "metadata": {},
   "source": [
    "## nnls_constraint - not yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7069dee-dba8-4245-9607-e4af6a6463e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnls_constraint : \n",
    "    def __init__(self, tol = 10**(-5), max_iter = 10^5) : \n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def fit(self, x, y, w) : \n",
    "        n, k = x.shape\n",
    "        obj = lambda beta, y, x, w : np.dot(w.reshape(-1,), (np.array(y).reshape(-1, ) - x @ beta)**2)/n\n",
    "        \n",
    "        # bound(0-1) and constrant(beta sum to 1)\n",
    "        bnds = list(tuple(itertools.repeat((0,1),k)))\n",
    "        cons = [{\"type\": \"eq\", \"fun\": lambda beta: np.sum(beta) - 1}]\n",
    "\n",
    "        # Initial guess for betas\n",
    "        init = np.repeat(0,k)\n",
    "        \n",
    "        # minimization\n",
    "        res = minimize(obj, args=(y, x, w), x0=init, bounds=bnds, constraints=cons, tol = self.tol, options= {'maxiter':self.max_iter})\n",
    "        \n",
    "        self.coef_ = res.x\n",
    "        self.iter = res['nit']\n",
    "        self.score = res['fun']\n",
    "        self.res = res\n",
    "        \n",
    "        return \n",
    "\n",
    "    def predict(self, x) : \n",
    "        return x @ self.coef_\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459a61f-59cd-44e1-83e3-fa388470dac9",
   "metadata": {},
   "source": [
    "## hillclimb() - not yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5856827-41d5-473b-b6a8-6e7d22b89db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hillclimb : \n",
    "    def __init__(self, max_iter= 2000, early_stop_n = 50, early_stop_eps = 10**(-3)) : \n",
    "        self.max_iter = max_iter\n",
    "        self.early_stop_n = early_stop_n\n",
    "        self.early_stop_eps = early_stop_eps\n",
    "        return\n",
    "        \n",
    "    def fit(self, x, y, w) : \n",
    "        n, k = x.shape\n",
    "        coef_ = np.zeros(k)\n",
    "        \n",
    "        current_score = 10^10\n",
    "        \n",
    "        current_iter = 0; early_stop_iter = 0 \n",
    "        while (current_iter <= self.max_iter)&(early_stop_iter <= self.early_stop_n) :\n",
    "            \n",
    "            # search\n",
    "            next_scores = []\n",
    "            for i in range(k) : \n",
    "                temp_coef_ = copy.copy(coef_); temp_coef_[i] += 1\n",
    "                temp_score = brier_score_loss(y, x @ (temp_coef_ / sum(temp_coef_)),w)\n",
    "                next_scores.append(temp_score)\n",
    "            \n",
    "            \n",
    "            # update\n",
    "            next_score = min(next_scores)\n",
    "            \n",
    "            best_ind = next_scores.index(next_score)\n",
    "            coef_[best_ind] = coef_[best_ind]+1\n",
    "            \n",
    "            current_iter += 1\n",
    "            \n",
    "            if (current_score - next_score) > self.early_stop_eps :\n",
    "                early_stop_iter = 0 \n",
    "            else : \n",
    "                early_stop_iter += 1\n",
    "            \n",
    "            current_score = next_score\n",
    "        \n",
    "        self.coef_ = coef_ / sum(coef_)\n",
    "        self.iter = current_iter    \n",
    "        self.score = current_score\n",
    "            \n",
    "    def predict(self, x) : \n",
    "        return x @ self.coef_\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af24b7ba-b9a1-4a34-a303-9812e12e55f4",
   "metadata": {},
   "source": [
    "## stacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5123686-f1ec-4e67-978e-4a5218a1609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacker :\n",
    "    def __init__(self, model_specifics, ID, T, E, S, window, k_bin) : \n",
    "        self.model_specifics = model_specifics\n",
    "        self.ID = ID\n",
    "        self.T = T\n",
    "        self.E = E\n",
    "        self.S = S\n",
    "        self.window = window\n",
    "        self.k_bin = k_bin \n",
    "        \n",
    "        self.model_list = [] # initializing model list\n",
    "        return\n",
    "    \n",
    "    # \n",
    "    def fit(self, data_cont, data_disc) : \n",
    "        new_model_list = []\n",
    "        for i in range(self.model_specifics.shape[0]) : \n",
    "            current_model_specifics = self.model_specifics.iloc[i:(i+1),:].reset_index(drop=True)\n",
    "            current_model_list = set_hyperparams(current_model_specifics) \n",
    "\n",
    "            current_model_name = current_model_specifics['model_name'][0]\n",
    "            current_model_type = current_model_specifics['type'][0]\n",
    "\n",
    "            # j for models in current_model_list \n",
    "            for j in range(len(current_model_list)) : \n",
    "                if current_model_type == 'cox_str' : \n",
    "                    fitter = LM_cox_fitter(model = current_model_list[j], ID = self.ID, T = self.T, E = self.E, \n",
    "                                           S = self.S, window = self.window, degree= 2, stratified = True)\n",
    "                    fitter.fit(data= data_cont)\n",
    "\n",
    "                elif current_model_type == 'cox_no_str' : \n",
    "                    fitter = LM_cox_fitter(model = current_model_list[j], ID = self.ID, T = self.T, E = self.E, \n",
    "                                           S = self.S, window = self.window, degree= 2, stratified = False)\n",
    "                    fitter.fit(data= data_cont)\n",
    "\n",
    "                else : \n",
    "                    fitter = LM_sklearn_fitter(model = current_model_list[j], ID = self.ID, E = self.E, k_bin = self.k_bin)\n",
    "                    fitter.fit(data= data_disc)\n",
    "                new_model_list.append(fitter)\n",
    "        \n",
    "        self.model_list = new_model_list\n",
    "                \n",
    "        return self.model_list\n",
    "    \n",
    "    def predict(self, data_cont, data_disc) :\n",
    "        stacked = []\n",
    "        for fitter in self.model_list : \n",
    "            module_tree = getattr(fitter.model,'__module__',None)\n",
    "            parent = module_tree.split('.')[0] if module_tree else None\n",
    "            \n",
    "            if parent == lifelines.__name__:\n",
    "                stacked.append(fitter.predict(data_cont))\n",
    "            else :\n",
    "                stacked.append(fitter.predict(data_disc))\n",
    "        \n",
    "        stacked = np.array(stacked).T\n",
    "        \n",
    "        return stacked\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874a1d5-6640-4a71-a8e0-d511d2939f42",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f028fe-68db-4608-809a-a7a8afb724b5",
   "metadata": {},
   "source": [
    "# 1. loading data & pre-prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0c5ab334-a752-40ca-8ec2-7a36fe682d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "#\n",
    "\n",
    "# settings \n",
    "dir = \"/Users/pio/Google 드라이브/data/\"\n",
    "file_name = \"pbc2.csv\"\n",
    "data = pd.read_csv(dir + file_name)\n",
    "\n",
    "# drop status1 - competing risks setting\n",
    "data = data.drop(axis=1, columns =['status'])\n",
    "\n",
    "\n",
    "# ID, Time, Event, Measure Time column names\n",
    "ID_col = 'id'; T_col ='years'; E_col ='status2'; measure_T_col = 'year'\n",
    "\n",
    "# categorical variables\n",
    "nominal_col = ['drug','sex', 'ascites', 'hepatomegaly','spiders', 'edema']\n",
    "ordinal_col = ['histologic']\n",
    "\n",
    "# continuous variables\n",
    "cont_col = list(set(data.columns) - set(nominal_col) - set(ordinal_col) - set([ID_col, T_col, E_col, measure_T_col]))\n",
    "\n",
    "# window - 5 year prediction \n",
    "window = 5\n",
    "\n",
    "# S : landmark time points - 0, 0.5, 1, ..., 10\n",
    "S = np.linspace(0,10,21)\n",
    "v_years = S+window\n",
    "\n",
    "# Number of bins when discritizing \n",
    "## !!!(Actually, k_bin - 1 bins are produced)!!!\n",
    "k_bin = 5\n",
    "\n",
    "# minimal bin_size\n",
    "minimal_bin_size = window / (k_bin-1)\n",
    "\n",
    "# \n",
    "\n",
    "# for continous variables, \n",
    "## scaling -> min-max scaling &\n",
    "## imputation -> fill na's : median for continous\n",
    "for col in cont_col : \n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "    data[col] = (data[col] - min(data[col])) / (max(data[col]) - min(data[col]))\n",
    "\n",
    "# one-hot encoding for categorical variables\n",
    "data = pd.get_dummies(data, columns = nominal_col, drop_first=True)\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "# settings2\n",
    "\n",
    "# proportion of train set\n",
    "p_train = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "04c70122-6b2c-4258-a76b-17aa551af6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>years</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>serBilir</th>\n",
       "      <th>serChol</th>\n",
       "      <th>albumin</th>\n",
       "      <th>alkaline</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>platelets</th>\n",
       "      <th>prothrombin</th>\n",
       "      <th>histologic</th>\n",
       "      <th>status2</th>\n",
       "      <th>drug_placebo</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>ascites_Yes</th>\n",
       "      <th>hepatomegaly_Yes</th>\n",
       "      <th>spiders_Yes</th>\n",
       "      <th>edema_edema despite diuretics</th>\n",
       "      <th>edema_edema no diuretics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "      <td>1945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>135.392802</td>\n",
       "      <td>8.051561</td>\n",
       "      <td>0.440588</td>\n",
       "      <td>3.135860</td>\n",
       "      <td>0.087343</td>\n",
       "      <td>0.144657</td>\n",
       "      <td>0.324545</td>\n",
       "      <td>0.094231</td>\n",
       "      <td>0.097156</td>\n",
       "      <td>0.203436</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>3.265296</td>\n",
       "      <td>0.372751</td>\n",
       "      <td>0.497172</td>\n",
       "      <td>0.121851</td>\n",
       "      <td>0.086889</td>\n",
       "      <td>0.479177</td>\n",
       "      <td>0.296144</td>\n",
       "      <td>0.084833</td>\n",
       "      <td>0.194859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.571397</td>\n",
       "      <td>3.480676</td>\n",
       "      <td>0.192895</td>\n",
       "      <td>3.094865</td>\n",
       "      <td>0.131359</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>0.073543</td>\n",
       "      <td>0.085448</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>0.100755</td>\n",
       "      <td>0.054773</td>\n",
       "      <td>0.872861</td>\n",
       "      <td>0.483661</td>\n",
       "      <td>0.500121</td>\n",
       "      <td>0.327198</td>\n",
       "      <td>0.281745</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>0.456673</td>\n",
       "      <td>0.278705</td>\n",
       "      <td>0.396194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>5.626437</td>\n",
       "      <td>0.297449</td>\n",
       "      <td>0.525682</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.122674</td>\n",
       "      <td>0.283626</td>\n",
       "      <td>0.048952</td>\n",
       "      <td>0.054888</td>\n",
       "      <td>0.133544</td>\n",
       "      <td>0.040741</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>8.112474</td>\n",
       "      <td>0.433130</td>\n",
       "      <td>2.053444</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.131395</td>\n",
       "      <td>0.331871</td>\n",
       "      <td>0.072449</td>\n",
       "      <td>0.084084</td>\n",
       "      <td>0.197687</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>203.000000</td>\n",
       "      <td>10.456138</td>\n",
       "      <td>0.572748</td>\n",
       "      <td>5.032308</td>\n",
       "      <td>0.092910</td>\n",
       "      <td>0.140116</td>\n",
       "      <td>0.369883</td>\n",
       "      <td>0.111683</td>\n",
       "      <td>0.124124</td>\n",
       "      <td>0.259727</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>312.000000</td>\n",
       "      <td>14.305662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.105793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id        years          age         year     serBilir  \\\n",
       "count  1945.000000  1945.000000  1945.000000  1945.000000  1945.000000   \n",
       "mean    135.392802     8.051561     0.440588     3.135860     0.087343   \n",
       "std      85.571397     3.480676     0.192895     3.094865     0.131359   \n",
       "min       1.000000     0.112255     0.000000     0.000000     0.000000   \n",
       "25%      61.000000     5.626437     0.297449     0.525682     0.017115   \n",
       "50%     126.000000     8.112474     0.433130     2.053444     0.031785   \n",
       "75%     203.000000    10.456138     0.572748     5.032308     0.092910   \n",
       "max     312.000000    14.305662     1.000000    14.105793     1.000000   \n",
       "\n",
       "           serChol      albumin     alkaline         SGOT    platelets  \\\n",
       "count  1945.000000  1945.000000  1945.000000  1945.000000  1945.000000   \n",
       "mean      0.144657     0.324545     0.094231     0.097156     0.203436   \n",
       "std       0.074538     0.073543     0.085448     0.065430     0.100755   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.122674     0.283626     0.048952     0.054888     0.133544   \n",
       "50%       0.131395     0.331871     0.072449     0.084084     0.197687   \n",
       "75%       0.140116     0.369883     0.111683     0.124124     0.259727   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       prothrombin   histologic      status2  drug_placebo     sex_male  \\\n",
       "count  1945.000000  1945.000000  1945.000000   1945.000000  1945.000000   \n",
       "mean      0.073992     3.265296     0.372751      0.497172     0.121851   \n",
       "std       0.054773     0.872861     0.483661      0.500121     0.327198   \n",
       "min       0.000000     1.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.040741     3.000000     0.000000      0.000000     0.000000   \n",
       "50%       0.066667     3.000000     0.000000      0.000000     0.000000   \n",
       "75%       0.092593     4.000000     1.000000      1.000000     0.000000   \n",
       "max       1.000000     4.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       ascites_Yes  hepatomegaly_Yes  spiders_Yes  \\\n",
       "count  1945.000000       1945.000000  1945.000000   \n",
       "mean      0.086889          0.479177     0.296144   \n",
       "std       0.281745          0.499695     0.456673   \n",
       "min       0.000000          0.000000     0.000000   \n",
       "25%       0.000000          0.000000     0.000000   \n",
       "50%       0.000000          0.000000     0.000000   \n",
       "75%       0.000000          1.000000     1.000000   \n",
       "max       1.000000          1.000000     1.000000   \n",
       "\n",
       "       edema_edema despite diuretics  edema_edema no diuretics  \n",
       "count                    1945.000000               1945.000000  \n",
       "mean                        0.084833                  0.194859  \n",
       "std                         0.278705                  0.396194  \n",
       "min                         0.000000                  0.000000  \n",
       "25%                         0.000000                  0.000000  \n",
       "50%                         0.000000                  0.000000  \n",
       "75%                         0.000000                  0.000000  \n",
       "max                         1.000000                  1.000000  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5394b4e-351b-41e0-adce-3b4ee012a79b",
   "metadata": {},
   "source": [
    "# 2. Landmarking & Train-test split\n",
    "## 2-1. Landmarking dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f33c9988-1593-48b8-bedf-f1986223a3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_lm_cont = landmarker_cont(data=data, ID_col = ID_col, T_col = T_col, E_col = E_col, \n",
    "                window = window, S= S, measure_T_col = measure_T_col)\n",
    "\n",
    "data_lm_disc = landmarker_disc(data=data_lm_cont,ID_col = ID_col, T_col = T_col, E_col = E_col, \n",
    "                window = window, S= S, measure_T_col = measure_T_col, k_bin = k_bin, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc12c1c-c292-43bf-8851-a0117bf896ea",
   "metadata": {},
   "source": [
    "## 2-2. Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "635794ff-6e33-4f94-92de-ebd27dc74930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Split IDs into train set and test set\n",
    "train_id, test_id = id_train_test_split(id_list = data[ID_col], seed_number = 1, p=0.7)\n",
    "\n",
    "# Train, test set from original form\n",
    "train = data[data[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test = data[data[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "# Train, test set for continous landmarking algorithms\n",
    "train_lm_cont = data_lm_cont[data_lm_cont[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test_lm_cont = data_lm_cont[data_lm_cont[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "# Train, test set for discrete landmarking algorithms\n",
    "train_lm_disc = data_lm_disc[data_lm_disc[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test_lm_disc = data_lm_disc[data_lm_disc[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "print(np.all(np.unique(train_lm_cont.id) == np.unique(train_lm_disc.id)))\n",
    "print(np.all(np.unique(test_lm_cont.id) == np.unique(test_lm_disc.id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73dc374-cd5b-44d7-9e1d-79dd878f1d31",
   "metadata": {},
   "source": [
    "# 3. Fitting Part(Non bootstrapping models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7ecc2-b9ee-43c2-953f-953a7f45e89e",
   "metadata": {},
   "source": [
    "## 3-1. Specifying Baseline models(level 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7ad08-0878-4a7d-b9a4-ef78e41d2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model specifics of level 0 models\n",
    "cox_params = {'penalizer':np.exp(np.linspace(-5,1,5)),'l1_ratio':[0,0.25,0.5,0.75,1]}\n",
    "# 5*5 *2 = 50\n",
    "model_specifics_cont = pd.DataFrame({'model_name' : ['cox_str', 'cox_no_str'], \n",
    "                                'model_instance':[CoxPHFitter(),CoxPHFitter()], \n",
    "                                'hyperparams':[cox_params,cox_params], \n",
    "                                'type':['cox_str','cox_no_str']})\n",
    "\n",
    "LR_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['saga']\n",
    "} # 7 * 2 * 1 = 14\n",
    "RF_params = {'n_estimators':[50,100,300,500],'max_depth':[1,3,5]} # 4*3 = 12\n",
    "GB_params = {'n_estimators':[50,100,300,500],'max_depth':[1,3,5]} # 4*3 = 12\n",
    "MLP_params = {'hidden_layer_sizes':[1,2,3], 'activation' : ['identity', 'logistic', 'tanh', 'relu'], 'max_iter' : [1000], 'early_stopping' : [True], 'learning_rate' : ['adaptive']}\n",
    "# 3*4\n",
    "KNN_params = {'n_neighbors':[1,5,10], 'weights':['uniform', 'distance']} \n",
    "# 3*2\n",
    "NGB_params = {'var_smoothing':[1e-5, 1e-9, 1e-1]}\n",
    "# 3\n",
    "ADA_params = {'n_estimators':[50, 100, 300, 500], 'max_depth':[1,3,5]}\n",
    "# 4*10*3 = 36\n",
    "\n",
    "model_specifics_disc = pd.DataFrame({'model_name' : ['LR','RF','GB','MLP','KNN','NGB','ADA'], \n",
    "                                'model_instance':[LogisticRegression(max_iter=10000),RandomForestClassifier(),GradientBoostingClassifier(),MLPClassifier(),KNeighborsClassifier(),GaussianNB(), AdaBoostClassifier()], \n",
    "                                'hyperparams':[LR_params, RF_params, GB_params,MLP_params, KNN_params,NGB_params, ADA_params], \n",
    "                                'type':['lr','rf','gb','mlp','knn','ngb','ada']})\n",
    "\n",
    "\n",
    "model_specifics = pd.concat([model_specifics_cont,model_specifics_disc],axis=0).reset_index(drop=True)\n",
    "model_specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a5e03-ffff-4ca9-b95c-7c8c1099aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_list = set_hyperparams(model_specifics)\n",
    "len(baseline_model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59529e-c8f9-4f2a-a9ff-519b9af6a4b4",
   "metadata": {},
   "source": [
    "## 3-2. Fitting Baseline models(level 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f781f9-2f16-4a5c-af42-2eeab6448a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = stacker(model_specifics = model_specifics, ID = ID_col, T = T_col, E = E_col, S = S, window = window, k_bin = k_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eaae9e-d407-4f40-8a64-ed9e086f41b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stack.fit(train_lm_cont, train_lm_disc)\n",
    "\n",
    "stack_trn = stack.predict(train_lm_cont, train_lm_disc)\n",
    "stack_tst = stack.predict(test_lm_cont, test_lm_disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c799c2c3-8b4a-430a-a5d8-9df2ca2da3a5",
   "metadata": {},
   "source": [
    "## 3-3. Fitting meta model(level 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7c0ae8e8-9f20-49fc-9d60-ec818cd2e579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LM</th>\n",
       "      <th>status2</th>\n",
       "      <th>years</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.095170</td>\n",
       "      <td>1.004824e-08</td>\n",
       "      <td>8.912633e-09</td>\n",
       "      <td>7.528412e-09</td>\n",
       "      <td>1.212599e-08</td>\n",
       "      <td>2.663466e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060887</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.061634</td>\n",
       "      <td>0.061634</td>\n",
       "      <td>0.061634</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.061845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.992268e-01</td>\n",
       "      <td>7.904634e-01</td>\n",
       "      <td>7.865925e-01</td>\n",
       "      <td>7.783915e-01</td>\n",
       "      <td>7.712919e-01</td>\n",
       "      <td>0.748895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071703</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>0.068172</td>\n",
       "      <td>0.065172</td>\n",
       "      <td>0.065172</td>\n",
       "      <td>0.065172</td>\n",
       "      <td>0.064251</td>\n",
       "      <td>0.064251</td>\n",
       "      <td>0.064251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.770781</td>\n",
       "      <td>5.574541e-01</td>\n",
       "      <td>5.569528e-01</td>\n",
       "      <td>5.479559e-01</td>\n",
       "      <td>5.314501e-01</td>\n",
       "      <td>5.220573e-01</td>\n",
       "      <td>0.605204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065940</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.064433</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>0.063457</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.063176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.357275e-01</td>\n",
       "      <td>3.256735e-01</td>\n",
       "      <td>3.222720e-01</td>\n",
       "      <td>3.177992e-01</td>\n",
       "      <td>3.220754e-01</td>\n",
       "      <td>0.285316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069450</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>0.065444</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.063148</td>\n",
       "      <td>0.063148</td>\n",
       "      <td>0.063148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.120578</td>\n",
       "      <td>8.214762e-01</td>\n",
       "      <td>8.207666e-01</td>\n",
       "      <td>8.184606e-01</td>\n",
       "      <td>8.159632e-01</td>\n",
       "      <td>8.117734e-01</td>\n",
       "      <td>0.825857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069262</td>\n",
       "      <td>0.066248</td>\n",
       "      <td>0.066248</td>\n",
       "      <td>0.066248</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.063866</td>\n",
       "      <td>0.063583</td>\n",
       "      <td>0.063583</td>\n",
       "      <td>0.063583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>134</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.453401</td>\n",
       "      <td>4.265935e-01</td>\n",
       "      <td>4.911498e-01</td>\n",
       "      <td>5.227962e-01</td>\n",
       "      <td>4.924416e-01</td>\n",
       "      <td>4.435441e-01</td>\n",
       "      <td>0.560019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063633</td>\n",
       "      <td>0.063533</td>\n",
       "      <td>0.063533</td>\n",
       "      <td>0.063533</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.062877</td>\n",
       "      <td>0.062877</td>\n",
       "      <td>0.062877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>136</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.313766</td>\n",
       "      <td>9.860016e-01</td>\n",
       "      <td>9.837589e-01</td>\n",
       "      <td>9.801265e-01</td>\n",
       "      <td>9.770640e-01</td>\n",
       "      <td>9.720449e-01</td>\n",
       "      <td>0.970314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074295</td>\n",
       "      <td>0.068574</td>\n",
       "      <td>0.068574</td>\n",
       "      <td>0.068574</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>0.064382</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.063806</td>\n",
       "      <td>0.063806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>137</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.018070</td>\n",
       "      <td>9.653127e-01</td>\n",
       "      <td>9.631242e-01</td>\n",
       "      <td>9.585697e-01</td>\n",
       "      <td>9.536294e-01</td>\n",
       "      <td>9.452432e-01</td>\n",
       "      <td>0.943026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073878</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.068205</td>\n",
       "      <td>0.064564</td>\n",
       "      <td>0.064564</td>\n",
       "      <td>0.064564</td>\n",
       "      <td>0.063697</td>\n",
       "      <td>0.063697</td>\n",
       "      <td>0.063697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>140</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.206987</td>\n",
       "      <td>9.793305e-01</td>\n",
       "      <td>9.780822e-01</td>\n",
       "      <td>9.739427e-01</td>\n",
       "      <td>9.704172e-01</td>\n",
       "      <td>9.659371e-01</td>\n",
       "      <td>0.961090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074143</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.064101</td>\n",
       "      <td>0.063343</td>\n",
       "      <td>0.063343</td>\n",
       "      <td>0.063343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>141</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.182346</td>\n",
       "      <td>9.580216e-01</td>\n",
       "      <td>9.513071e-01</td>\n",
       "      <td>9.426130e-01</td>\n",
       "      <td>9.362581e-01</td>\n",
       "      <td>9.244196e-01</td>\n",
       "      <td>0.940540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076691</td>\n",
       "      <td>0.069664</td>\n",
       "      <td>0.069664</td>\n",
       "      <td>0.069664</td>\n",
       "      <td>0.064955</td>\n",
       "      <td>0.064955</td>\n",
       "      <td>0.064955</td>\n",
       "      <td>0.064054</td>\n",
       "      <td>0.064054</td>\n",
       "      <td>0.064054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2776 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    LM  status2      years             0             1             2  \\\n",
       "0       1   0.0        1   1.095170  1.004824e-08  8.912633e-09  7.528412e-09   \n",
       "1       2   0.0        0   5.000000  7.992268e-01  7.904634e-01  7.865925e-01   \n",
       "2       3   0.0        1   2.770781  5.574541e-01  5.569528e-01  5.479559e-01   \n",
       "3       4   0.0        0   5.000000  3.357275e-01  3.256735e-01  3.222720e-01   \n",
       "4       5   0.0        0   4.120578  8.214762e-01  8.207666e-01  8.184606e-01   \n",
       "...   ...   ...      ...        ...           ...           ...           ...   \n",
       "2771  134  10.0        0  10.453401  4.265935e-01  4.911498e-01  5.227962e-01   \n",
       "2772  136  10.0        0  10.313766  9.860016e-01  9.837589e-01  9.801265e-01   \n",
       "2773  137  10.0        0  10.018070  9.653127e-01  9.631242e-01  9.585697e-01   \n",
       "2774  140  10.0        0  10.206987  9.793305e-01  9.780822e-01  9.739427e-01   \n",
       "2775  141  10.0        0  10.182346  9.580216e-01  9.513071e-01  9.426130e-01   \n",
       "\n",
       "                 3             4         5  ...       111       112       113  \\\n",
       "0     1.212599e-08  2.663466e-08  0.000002  ...  0.060887  0.060152  0.060152   \n",
       "1     7.783915e-01  7.712919e-01  0.748895  ...  0.071703  0.068172  0.068172   \n",
       "2     5.314501e-01  5.220573e-01  0.605204  ...  0.065940  0.064433  0.064433   \n",
       "3     3.177992e-01  3.220754e-01  0.285316  ...  0.069450  0.065444  0.065444   \n",
       "4     8.159632e-01  8.117734e-01  0.825857  ...  0.069262  0.066248  0.066248   \n",
       "...            ...           ...       ...  ...       ...       ...       ...   \n",
       "2771  4.924416e-01  4.435441e-01  0.560019  ...  0.063633  0.063533  0.063533   \n",
       "2772  9.770640e-01  9.720449e-01  0.970314  ...  0.074295  0.068574  0.068574   \n",
       "2773  9.536294e-01  9.452432e-01  0.943026  ...  0.073878  0.068205  0.068205   \n",
       "2774  9.704172e-01  9.659371e-01  0.961090  ...  0.074143  0.068195  0.068195   \n",
       "2775  9.362581e-01  9.244196e-01  0.940540  ...  0.076691  0.069664  0.069664   \n",
       "\n",
       "           114       115       116       117       118       119       120  \n",
       "0     0.060152  0.061634  0.061634  0.061634  0.061845  0.061845  0.061845  \n",
       "1     0.068172  0.065172  0.065172  0.065172  0.064251  0.064251  0.064251  \n",
       "2     0.064433  0.063457  0.063457  0.063457  0.063176  0.063176  0.063176  \n",
       "3     0.065444  0.063521  0.063521  0.063521  0.063148  0.063148  0.063148  \n",
       "4     0.066248  0.063866  0.063866  0.063866  0.063583  0.063583  0.063583  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2771  0.063533  0.063023  0.063023  0.063023  0.062877  0.062877  0.062877  \n",
       "2772  0.068574  0.064382  0.064382  0.064382  0.063806  0.063806  0.063806  \n",
       "2773  0.068205  0.064564  0.064564  0.064564  0.063697  0.063697  0.063697  \n",
       "2774  0.068195  0.064101  0.064101  0.064101  0.063343  0.063343  0.063343  \n",
       "2775  0.069664  0.064955  0.064955  0.064955  0.064054  0.064054  0.064054  \n",
       "\n",
       "[2776 rows x 125 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cb83b45e-cde3-4a38-8576-fb9f65dde882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LM</th>\n",
       "      <th>status2</th>\n",
       "      <th>years</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.745126</td>\n",
       "      <td>0.738533</td>\n",
       "      <td>0.729977</td>\n",
       "      <td>0.723309</td>\n",
       "      <td>0.714972</td>\n",
       "      <td>0.770869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072270</td>\n",
       "      <td>0.067484</td>\n",
       "      <td>0.067484</td>\n",
       "      <td>0.067484</td>\n",
       "      <td>0.064328</td>\n",
       "      <td>0.064328</td>\n",
       "      <td>0.064328</td>\n",
       "      <td>0.063663</td>\n",
       "      <td>0.063663</td>\n",
       "      <td>0.063663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139634</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061277</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.062254</td>\n",
       "      <td>0.062254</td>\n",
       "      <td>0.062254</td>\n",
       "      <td>0.062274</td>\n",
       "      <td>0.062274</td>\n",
       "      <td>0.062274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.755894</td>\n",
       "      <td>0.751015</td>\n",
       "      <td>0.743818</td>\n",
       "      <td>0.740266</td>\n",
       "      <td>0.737455</td>\n",
       "      <td>0.788112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071286</td>\n",
       "      <td>0.067106</td>\n",
       "      <td>0.067106</td>\n",
       "      <td>0.067106</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.063627</td>\n",
       "      <td>0.063627</td>\n",
       "      <td>0.063627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.920405</td>\n",
       "      <td>0.918273</td>\n",
       "      <td>0.915618</td>\n",
       "      <td>0.912982</td>\n",
       "      <td>0.909361</td>\n",
       "      <td>0.921802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079549</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>0.065222</td>\n",
       "      <td>0.065222</td>\n",
       "      <td>0.065222</td>\n",
       "      <td>0.064184</td>\n",
       "      <td>0.064184</td>\n",
       "      <td>0.064184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.105465</td>\n",
       "      <td>0.567759</td>\n",
       "      <td>0.571706</td>\n",
       "      <td>0.574039</td>\n",
       "      <td>0.577969</td>\n",
       "      <td>0.580124</td>\n",
       "      <td>0.613054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061849</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>0.062339</td>\n",
       "      <td>0.062339</td>\n",
       "      <td>0.062339</td>\n",
       "      <td>0.062478</td>\n",
       "      <td>0.062478</td>\n",
       "      <td>0.062478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>73</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.303581</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>0.996447</td>\n",
       "      <td>0.995307</td>\n",
       "      <td>0.994457</td>\n",
       "      <td>0.993012</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075551</td>\n",
       "      <td>0.070947</td>\n",
       "      <td>0.070947</td>\n",
       "      <td>0.070947</td>\n",
       "      <td>0.065588</td>\n",
       "      <td>0.065588</td>\n",
       "      <td>0.065588</td>\n",
       "      <td>0.064667</td>\n",
       "      <td>0.064667</td>\n",
       "      <td>0.064667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>84</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.870989</td>\n",
       "      <td>0.315324</td>\n",
       "      <td>0.317646</td>\n",
       "      <td>0.319486</td>\n",
       "      <td>0.343707</td>\n",
       "      <td>0.402296</td>\n",
       "      <td>0.551653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069163</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>0.065747</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.062638</td>\n",
       "      <td>0.062638</td>\n",
       "      <td>0.062638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>115</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.200854</td>\n",
       "      <td>0.972478</td>\n",
       "      <td>0.969098</td>\n",
       "      <td>0.963791</td>\n",
       "      <td>0.961352</td>\n",
       "      <td>0.957731</td>\n",
       "      <td>0.959409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081262</td>\n",
       "      <td>0.071629</td>\n",
       "      <td>0.071629</td>\n",
       "      <td>0.071629</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.065828</td>\n",
       "      <td>0.064602</td>\n",
       "      <td>0.064602</td>\n",
       "      <td>0.064602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>127</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.743621</td>\n",
       "      <td>0.849871</td>\n",
       "      <td>0.847990</td>\n",
       "      <td>0.842123</td>\n",
       "      <td>0.837994</td>\n",
       "      <td>0.834570</td>\n",
       "      <td>0.856223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070215</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.063315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>135</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.456138</td>\n",
       "      <td>0.998035</td>\n",
       "      <td>0.997404</td>\n",
       "      <td>0.996425</td>\n",
       "      <td>0.995529</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.990864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>0.071003</td>\n",
       "      <td>0.071003</td>\n",
       "      <td>0.071003</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.064210</td>\n",
       "      <td>0.064210</td>\n",
       "      <td>0.064210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    LM  status2      years         0         1         2         3  \\\n",
       "0       6   0.0        0   5.000000  0.745126  0.738533  0.729977  0.723309   \n",
       "1      10   0.0        1   0.139634  0.000049  0.000028  0.000017  0.000017   \n",
       "2      11   0.0        0   5.000000  0.755894  0.751015  0.743818  0.740266   \n",
       "3      13   0.0        0   5.000000  0.920405  0.918273  0.915618  0.912982   \n",
       "4      17   0.0        1   2.105465  0.567759  0.571706  0.574039  0.577969   \n",
       "...   ...   ...      ...        ...       ...       ...       ...       ...   \n",
       "1191   73  10.0        0  13.303581  0.997093  0.996447  0.995307  0.994457   \n",
       "1192   84  10.0        0  12.870989  0.315324  0.317646  0.319486  0.343707   \n",
       "1193  115  10.0        0  11.200854  0.972478  0.969098  0.963791  0.961352   \n",
       "1194  127  10.0        0  10.743621  0.849871  0.847990  0.842123  0.837994   \n",
       "1195  135  10.0        0  10.456138  0.998035  0.997404  0.996425  0.995529   \n",
       "\n",
       "             4         5  ...       111       112       113       114  \\\n",
       "0     0.714972  0.770869  ...  0.072270  0.067484  0.067484  0.067484   \n",
       "1     0.000024  0.000565  ...  0.061277  0.060960  0.060960  0.060960   \n",
       "2     0.737455  0.788112  ...  0.071286  0.067106  0.067106  0.067106   \n",
       "3     0.909361  0.921802  ...  0.079549  0.070935  0.070935  0.070935   \n",
       "4     0.580124  0.613054  ...  0.061849  0.061797  0.061797  0.061797   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "1191  0.993012  0.987952  ...  0.075551  0.070947  0.070947  0.070947   \n",
       "1192  0.402296  0.551653  ...  0.069163  0.065747  0.065747  0.065747   \n",
       "1193  0.957731  0.959409  ...  0.081262  0.071629  0.071629  0.071629   \n",
       "1194  0.834570  0.856223  ...  0.070215  0.066400  0.066400  0.066400   \n",
       "1195  0.993547  0.990864  ...  0.077462  0.071003  0.071003  0.071003   \n",
       "\n",
       "           115       116       117       118       119       120  \n",
       "0     0.064328  0.064328  0.064328  0.063663  0.063663  0.063663  \n",
       "1     0.062254  0.062254  0.062254  0.062274  0.062274  0.062274  \n",
       "2     0.064215  0.064215  0.064215  0.063627  0.063627  0.063627  \n",
       "3     0.065222  0.065222  0.065222  0.064184  0.064184  0.064184  \n",
       "4     0.062339  0.062339  0.062339  0.062478  0.062478  0.062478  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "1191  0.065588  0.065588  0.065588  0.064667  0.064667  0.064667  \n",
       "1192  0.062937  0.062937  0.062937  0.062638  0.062638  0.062638  \n",
       "1193  0.065828  0.065828  0.065828  0.064602  0.064602  0.064602  \n",
       "1194  0.063732  0.063732  0.063732  0.063315  0.063315  0.063315  \n",
       "1195  0.065201  0.065201  0.065201  0.064210  0.064210  0.064210  \n",
       "\n",
       "[1196 rows x 125 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45fbee8c-5683-4f26-878d-c04d56f14a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcw_calc = ipcw_fitter(S= S, window =window)\n",
    "ipcw_calc.fit(data= train_lm_cont, T = T_col, E = E_col)\n",
    "\n",
    "\n",
    "nnls = nnls_constraint()\n",
    "nnls.fit(x = stack_trn.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = stack_trn[E_col],\n",
    "         w = ipcw_calc.predict(train_lm_cont))\n",
    "\n",
    "res_nnls = nnls.predict(stack_tst.drop([ID_col, 'LM', E_col, T_col], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "df4d4de2-e2f1-4c13-8afd-29f8ca4009b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcw_calc = ipcw_fitter(S= S, window =window)\n",
    "ipcw_calc.fit(data= train_lm_cont, T = T_col, E = E_col)\n",
    "\n",
    "\n",
    "nnls = nnls_constraint()\n",
    "nnls.fit(x = stack_trn.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = stack_trn[E_col],\n",
    "         w = ipcw_calc.predict(train_lm_cont))\n",
    "\n",
    "\n",
    "hill = hillclimb()\n",
    "hill.fit(x = stack_trn.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = stack_trn[E_col],\n",
    "         w = ipcw_calc.predict(train_lm_cont))\n",
    "\n",
    "\n",
    "ipcw_rf = RandomForestClassifier()\n",
    "ipcw_rf.fit(X = stack_trn.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "            y = stack_trn[E_col], sample_weight = ipcw_calc.predict(train_lm_cont))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "615451a1-e524-414a-b033-695ee5db255c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.361831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.309915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.355119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.364044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.370705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.387232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1196.000000\n",
       "mean      0.361831\n",
       "std       0.012297\n",
       "min       0.309915\n",
       "25%       0.355119\n",
       "50%       0.364044\n",
       "75%       0.370705\n",
       "max       0.387232"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_nnls = nnls.predict(stack_tst.drop([ID_col, 'LM', E_col, T_col], axis=1))\n",
    "pd.DataFrame(res_nnls).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e977dbce-3fd9-418a-9bcb-f319f6b75f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.059707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.183305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.351935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.387152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.415339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.559062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1196.000000\n",
       "mean      0.383215\n",
       "std       0.059707\n",
       "min       0.183305\n",
       "25%       0.351935\n",
       "50%       0.387152\n",
       "75%       0.415339\n",
       "max       0.559062"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_hill = hill.predict(stack_tst.drop([ID_col, 'LM', E_col, T_col], axis=1))\n",
    "pd.DataFrame(res_hill).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "24672961-f8d6-4990-a412-dbf0d4c1a690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.189799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.392306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1196.000000\n",
       "mean      0.189799\n",
       "std       0.392306\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = ipcw_rf.predict(stack_tst.drop([ID_col, 'LM', E_col, T_col], axis=1))\n",
    "pd.DataFrame(res_rf).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba4890a-55c4-48d0-9eb7-1f6e96186b3c",
   "metadata": {},
   "source": [
    "## 3-4. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7eca0a64-7058-4c47-aaff-78c2dff6be15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9094240837696335"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concordance_index(event_times = stack_tst[stack_tst['LM'] == 0][T_col], \n",
    "                  predicted_scores = stack_tst[stack_tst['LM']==0][0], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == 0][E_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4dcff9c3-338d-412c-ab74-941238856fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i for model, j for landmarked time\n",
    "c_index_list = []\n",
    "for i in range(121) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        c_index_value = concordance_index(event_times = stack_tst[stack_tst['LM'] == j][T_col], \n",
    "                  predicted_scores = stack_tst[stack_tst['LM']==j][i], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == j][E_col])\n",
    "        temp.append(c_index_value)\n",
    "    c_index_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d4e845c8-811d-40c1-adb9-5db89c5a2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_index_list = np.array(c_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "720cd6d6-c300-444c-a96e-601286df4900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.825583</td>\n",
       "      <td>0.823942</td>\n",
       "      <td>0.828229</td>\n",
       "      <td>0.813323</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.821620</td>\n",
       "      <td>0.794009</td>\n",
       "      <td>0.772371</td>\n",
       "      <td>0.764422</td>\n",
       "      <td>0.735798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681845</td>\n",
       "      <td>0.663190</td>\n",
       "      <td>0.670466</td>\n",
       "      <td>0.715111</td>\n",
       "      <td>0.619358</td>\n",
       "      <td>0.601559</td>\n",
       "      <td>0.741311</td>\n",
       "      <td>0.611570</td>\n",
       "      <td>0.712161</td>\n",
       "      <td>0.843727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.172503</td>\n",
       "      <td>0.176665</td>\n",
       "      <td>0.174709</td>\n",
       "      <td>0.170879</td>\n",
       "      <td>0.163171</td>\n",
       "      <td>0.162621</td>\n",
       "      <td>0.153781</td>\n",
       "      <td>0.149890</td>\n",
       "      <td>0.137038</td>\n",
       "      <td>0.136038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115813</td>\n",
       "      <td>0.119438</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>0.117966</td>\n",
       "      <td>0.113666</td>\n",
       "      <td>0.099847</td>\n",
       "      <td>0.136026</td>\n",
       "      <td>0.100633</td>\n",
       "      <td>0.123658</td>\n",
       "      <td>0.177107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.141509</td>\n",
       "      <td>0.160032</td>\n",
       "      <td>0.171275</td>\n",
       "      <td>0.186701</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.206630</td>\n",
       "      <td>0.181916</td>\n",
       "      <td>0.211491</td>\n",
       "      <td>0.241636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.301115</td>\n",
       "      <td>0.275109</td>\n",
       "      <td>0.198718</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.867539</td>\n",
       "      <td>0.873821</td>\n",
       "      <td>0.865446</td>\n",
       "      <td>0.839478</td>\n",
       "      <td>0.833760</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.811050</td>\n",
       "      <td>0.800861</td>\n",
       "      <td>0.788509</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.672489</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.887958</td>\n",
       "      <td>0.888561</td>\n",
       "      <td>0.890924</td>\n",
       "      <td>0.884793</td>\n",
       "      <td>0.872975</td>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.826695</td>\n",
       "      <td>0.819071</td>\n",
       "      <td>0.801115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.701587</td>\n",
       "      <td>0.702602</td>\n",
       "      <td>0.746725</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.901571</td>\n",
       "      <td>0.895637</td>\n",
       "      <td>0.901274</td>\n",
       "      <td>0.891705</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.868508</td>\n",
       "      <td>0.846071</td>\n",
       "      <td>0.830073</td>\n",
       "      <td>0.823420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.923037</td>\n",
       "      <td>0.919222</td>\n",
       "      <td>0.917994</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.895993</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.906077</td>\n",
       "      <td>0.876211</td>\n",
       "      <td>0.861858</td>\n",
       "      <td>0.868030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832787</td>\n",
       "      <td>0.831746</td>\n",
       "      <td>0.817844</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.742268</td>\n",
       "      <td>0.917808</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  121.000000  121.000000   \n",
       "mean     0.825583    0.823942    0.828229    0.813323    0.809572    0.821620   \n",
       "std      0.172503    0.176665    0.174709    0.170879    0.163171    0.162621   \n",
       "min      0.152356    0.141509    0.160032    0.171275    0.186701    0.189000   \n",
       "25%      0.867539    0.873821    0.865446    0.839478    0.833760    0.862000   \n",
       "50%      0.887958    0.888561    0.890924    0.884793    0.872975    0.882000   \n",
       "75%      0.901571    0.895637    0.901274    0.891705    0.884058    0.898000   \n",
       "max      0.923037    0.919222    0.917994    0.904762    0.895993    0.928000   \n",
       "\n",
       "               6           7           8           9   ...          11  \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  ...  121.000000   \n",
       "mean     0.794009    0.772371    0.764422    0.735798  ...    0.681845   \n",
       "std      0.153781    0.149890    0.137038    0.136038  ...    0.115813   \n",
       "min      0.206630    0.181916    0.211491    0.241636  ...    0.245902   \n",
       "25%      0.811050    0.800861    0.788509    0.689591  ...    0.639344   \n",
       "50%      0.854144    0.826695    0.819071    0.801115  ...    0.714754   \n",
       "75%      0.868508    0.846071    0.830073    0.823420  ...    0.750820   \n",
       "max      0.906077    0.876211    0.861858    0.868030  ...    0.832787   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  121.000000  121.000000   \n",
       "mean     0.663190    0.670466    0.715111    0.619358    0.601559    0.741311   \n",
       "std      0.119438    0.105638    0.117966    0.113666    0.099847    0.136026   \n",
       "min      0.244444    0.301115    0.275109    0.198718    0.206186    0.191781   \n",
       "25%      0.600000    0.635688    0.672489    0.589744    0.577320    0.726027   \n",
       "50%      0.701587    0.702602    0.746725    0.641026    0.618557    0.780822   \n",
       "75%      0.739683    0.743494    0.781659    0.692308    0.659794    0.808219   \n",
       "max      0.831746    0.817844    0.851528    0.788462    0.742268    0.917808   \n",
       "\n",
       "               18          19          20  \n",
       "count  121.000000  121.000000  121.000000  \n",
       "mean     0.611570    0.712161    0.843727  \n",
       "std      0.100633    0.123658    0.177107  \n",
       "min      0.200000    0.257143    0.136364  \n",
       "25%      0.542857    0.685714    0.818182  \n",
       "50%      0.628571    0.742857    0.909091  \n",
       "75%      0.657143    0.800000    0.954545  \n",
       "max      0.800000    0.857143    1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(c_index_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "45cb7825-8a43-488a-bff9-d0f386e7bed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6277486910994764,\n",
       " 0.6043632075471698,\n",
       " 0.6576433121019108,\n",
       " 0.6758832565284179,\n",
       " 0.6811594202898551,\n",
       " 0.733,\n",
       " 0.6928176795580111,\n",
       " 0.6458557588805167,\n",
       " 0.6699266503667481,\n",
       " 0.6486988847583643,\n",
       " 0.6845070422535211,\n",
       " 0.6229508196721312,\n",
       " 0.5968253968253968,\n",
       " 0.5650557620817844,\n",
       " 0.6419213973799127,\n",
       " 0.4807692307692308,\n",
       " 0.5670103092783505,\n",
       " 0.7671232876712328,\n",
       " 0.5428571428571428,\n",
       " 0.6,\n",
       " 1.0]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnls_c_index = []\n",
    "for j in S : \n",
    "    c_index_value = concordance_index(event_times = stack_tst[stack_tst['LM'] == j][T_col], \n",
    "                  predicted_scores = res_nnls[stack_tst['LM'] == j], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == j][E_col])\n",
    "    nnls_c_index.append(c_index_value)\n",
    "\n",
    "nnls_c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a2e9fddb-2aec-48ee-93a9-95ec6d51a36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17853403141361257,\n",
       " 0.16391509433962265,\n",
       " 0.17038216560509553,\n",
       " 0.17204301075268819,\n",
       " 0.19522591645353793,\n",
       " 0.223,\n",
       " 0.27624309392265195,\n",
       " 0.25618945102260493,\n",
       " 0.33985330073349634,\n",
       " 0.3141263940520446,\n",
       " 0.4112676056338028,\n",
       " 0.33114754098360655,\n",
       " 0.3047619047619048,\n",
       " 0.3420074349442379,\n",
       " 0.3406113537117904,\n",
       " 0.22435897435897437,\n",
       " 0.2268041237113402,\n",
       " 0.2876712328767123,\n",
       " 0.2857142857142857,\n",
       " 0.37142857142857144,\n",
       " 0.5909090909090909]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hill_c_index = []\n",
    "for j in S : \n",
    "    c_index_value = concordance_index(event_times = stack_tst[stack_tst['LM'] == j][T_col], \n",
    "                  predicted_scores = res_hill[stack_tst['LM'] == j], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == j][E_col])\n",
    "    hill_c_index.append(c_index_value)\n",
    "\n",
    "hill_c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8c766717-5064-4304-83f9-643a60a63aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3507853403141361,\n",
       " 0.296875,\n",
       " 0.304140127388535,\n",
       " 0.3337173579109063,\n",
       " 0.32011935208866155,\n",
       " 0.29,\n",
       " 0.312707182320442,\n",
       " 0.3638320775026911,\n",
       " 0.4119804400977995,\n",
       " 0.3671003717472119,\n",
       " 0.3929577464788732,\n",
       " 0.31311475409836065,\n",
       " 0.4,\n",
       " 0.4200743494423792,\n",
       " 0.3296943231441048,\n",
       " 0.3141025641025641,\n",
       " 0.422680412371134,\n",
       " 0.3493150684931507,\n",
       " 0.42857142857142855,\n",
       " 0.42857142857142855,\n",
       " 0.3181818181818182]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_c_index = []\n",
    "for j in S : \n",
    "    c_index_value = concordance_index(event_times = stack_tst[stack_tst['LM'] == j][T_col], \n",
    "                  predicted_scores = res_rf[stack_tst['LM'] == j], \n",
    "                  event_observed=stack_tst[stack_tst['LM'] == j][E_col])\n",
    "    rf_c_index.append(c_index_value)\n",
    "\n",
    "rf_c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "30053e2f-c723-4dc0-98b3-64d7466d14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipcw_tst = ipcw_fitter(S= S, window =window)\n",
    "ipcw_tst.fit(data= test_lm_cont, T = T_col, E = E_col)\n",
    "weight_brier = ipcw_tst.predict(test_lm_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f861f4dc-0df5-456e-b74e-47d0a01c38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i for model, j for landmarked time\n",
    "brier_score_list = []\n",
    "for i in range(121) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        value = brier_score_loss(y_true = stack_tst[stack_tst['LM'] == j][E_col], \n",
    "                         y_prob = stack_tst[stack_tst['LM'] == j][i], \n",
    "                         sample_weight= weight_brier[stack_tst['LM'] == j])        \n",
    "        temp.append(value)        \n",
    "    brier_score_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f7d0dce2-3970-4792-a3a8-627ddcb60833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.508525</td>\n",
       "      <td>0.511817</td>\n",
       "      <td>0.514417</td>\n",
       "      <td>0.504855</td>\n",
       "      <td>0.489575</td>\n",
       "      <td>0.495354</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.482041</td>\n",
       "      <td>0.475095</td>\n",
       "      <td>0.476647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417106</td>\n",
       "      <td>0.384452</td>\n",
       "      <td>0.381873</td>\n",
       "      <td>0.384244</td>\n",
       "      <td>0.385087</td>\n",
       "      <td>0.351127</td>\n",
       "      <td>0.359420</td>\n",
       "      <td>0.300543</td>\n",
       "      <td>0.343449</td>\n",
       "      <td>0.456584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.160191</td>\n",
       "      <td>0.166404</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.166666</td>\n",
       "      <td>0.160397</td>\n",
       "      <td>0.157397</td>\n",
       "      <td>0.138984</td>\n",
       "      <td>0.132496</td>\n",
       "      <td>0.122593</td>\n",
       "      <td>0.140489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106852</td>\n",
       "      <td>0.085220</td>\n",
       "      <td>0.080049</td>\n",
       "      <td>0.076207</td>\n",
       "      <td>0.081609</td>\n",
       "      <td>0.065711</td>\n",
       "      <td>0.085638</td>\n",
       "      <td>0.117991</td>\n",
       "      <td>0.248394</td>\n",
       "      <td>0.293166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.184720</td>\n",
       "      <td>0.176042</td>\n",
       "      <td>0.154738</td>\n",
       "      <td>0.163666</td>\n",
       "      <td>0.164101</td>\n",
       "      <td>0.175366</td>\n",
       "      <td>0.191442</td>\n",
       "      <td>0.206996</td>\n",
       "      <td>0.239422</td>\n",
       "      <td>0.217149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>0.247516</td>\n",
       "      <td>0.245846</td>\n",
       "      <td>0.240693</td>\n",
       "      <td>0.233719</td>\n",
       "      <td>0.219495</td>\n",
       "      <td>0.211437</td>\n",
       "      <td>0.117611</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.393985</td>\n",
       "      <td>0.399119</td>\n",
       "      <td>0.417429</td>\n",
       "      <td>0.410339</td>\n",
       "      <td>0.389506</td>\n",
       "      <td>0.404168</td>\n",
       "      <td>0.413956</td>\n",
       "      <td>0.407706</td>\n",
       "      <td>0.374430</td>\n",
       "      <td>0.340586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328808</td>\n",
       "      <td>0.331785</td>\n",
       "      <td>0.341970</td>\n",
       "      <td>0.340674</td>\n",
       "      <td>0.326201</td>\n",
       "      <td>0.313366</td>\n",
       "      <td>0.303785</td>\n",
       "      <td>0.196577</td>\n",
       "      <td>0.172383</td>\n",
       "      <td>0.242203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.571871</td>\n",
       "      <td>0.563559</td>\n",
       "      <td>0.566307</td>\n",
       "      <td>0.539356</td>\n",
       "      <td>0.519772</td>\n",
       "      <td>0.515403</td>\n",
       "      <td>0.514278</td>\n",
       "      <td>0.503366</td>\n",
       "      <td>0.490648</td>\n",
       "      <td>0.516047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401595</td>\n",
       "      <td>0.376960</td>\n",
       "      <td>0.378691</td>\n",
       "      <td>0.372790</td>\n",
       "      <td>0.379956</td>\n",
       "      <td>0.349312</td>\n",
       "      <td>0.366040</td>\n",
       "      <td>0.312589</td>\n",
       "      <td>0.275625</td>\n",
       "      <td>0.341444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.614126</td>\n",
       "      <td>0.620274</td>\n",
       "      <td>0.625369</td>\n",
       "      <td>0.624384</td>\n",
       "      <td>0.596415</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.591685</td>\n",
       "      <td>0.596135</td>\n",
       "      <td>0.576807</td>\n",
       "      <td>0.581958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465373</td>\n",
       "      <td>0.414621</td>\n",
       "      <td>0.413550</td>\n",
       "      <td>0.427569</td>\n",
       "      <td>0.422410</td>\n",
       "      <td>0.377530</td>\n",
       "      <td>0.396928</td>\n",
       "      <td>0.366114</td>\n",
       "      <td>0.445651</td>\n",
       "      <td>0.761467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.785811</td>\n",
       "      <td>0.815069</td>\n",
       "      <td>0.818294</td>\n",
       "      <td>0.809564</td>\n",
       "      <td>0.815344</td>\n",
       "      <td>0.815639</td>\n",
       "      <td>0.757141</td>\n",
       "      <td>0.778362</td>\n",
       "      <td>0.725728</td>\n",
       "      <td>0.812127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753762</td>\n",
       "      <td>0.651150</td>\n",
       "      <td>0.638429</td>\n",
       "      <td>0.603570</td>\n",
       "      <td>0.693568</td>\n",
       "      <td>0.568070</td>\n",
       "      <td>0.715409</td>\n",
       "      <td>0.685073</td>\n",
       "      <td>0.877980</td>\n",
       "      <td>0.999937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  121.000000  121.000000   \n",
       "mean     0.508525    0.511817    0.514417    0.504855    0.489575    0.495354   \n",
       "std      0.160191    0.166404    0.177900    0.166666    0.160397    0.157397   \n",
       "min      0.184720    0.176042    0.154738    0.163666    0.164101    0.175366   \n",
       "25%      0.393985    0.399119    0.417429    0.410339    0.389506    0.404168   \n",
       "50%      0.571871    0.563559    0.566307    0.539356    0.519772    0.515403   \n",
       "75%      0.614126    0.620274    0.625369    0.624384    0.596415    0.608100   \n",
       "max      0.785811    0.815069    0.818294    0.809564    0.815344    0.815639   \n",
       "\n",
       "               6           7           8           9   ...          11  \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  ...  121.000000   \n",
       "mean     0.485356    0.482041    0.475095    0.476647  ...    0.417106   \n",
       "std      0.138984    0.132496    0.122593    0.140489  ...    0.106852   \n",
       "min      0.191442    0.206996    0.239422    0.217149  ...    0.243029   \n",
       "25%      0.413956    0.407706    0.374430    0.340586  ...    0.328808   \n",
       "50%      0.514278    0.503366    0.490648    0.516047  ...    0.401595   \n",
       "75%      0.591685    0.596135    0.576807    0.581958  ...    0.465373   \n",
       "max      0.757141    0.778362    0.725728    0.812127  ...    0.753762   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  121.000000  121.000000  121.000000  121.000000  121.000000  121.000000   \n",
       "mean     0.384452    0.381873    0.384244    0.385087    0.351127    0.359420   \n",
       "std      0.085220    0.080049    0.076207    0.081609    0.065711    0.085638   \n",
       "min      0.247516    0.245846    0.240693    0.233719    0.219495    0.211437   \n",
       "25%      0.331785    0.341970    0.340674    0.326201    0.313366    0.303785   \n",
       "50%      0.376960    0.378691    0.372790    0.379956    0.349312    0.366040   \n",
       "75%      0.414621    0.413550    0.427569    0.422410    0.377530    0.396928   \n",
       "max      0.651150    0.638429    0.603570    0.693568    0.568070    0.715409   \n",
       "\n",
       "               18          19          20  \n",
       "count  121.000000  121.000000  121.000000  \n",
       "mean     0.300543    0.343449    0.456584  \n",
       "std      0.117991    0.248394    0.293166  \n",
       "min      0.117611    0.004961    0.002109  \n",
       "25%      0.196577    0.172383    0.242203  \n",
       "50%      0.312589    0.275625    0.341444  \n",
       "75%      0.366114    0.445651    0.761467  \n",
       "max      0.685073    0.877980    0.999937  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_list = np.array(brier_score_list)\n",
    "pd.DataFrame(brier_score_list).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "442e09c4-125b-4041-8e5a-cdfb1542cc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20594549418755445,\n",
       " 0.2027877486714525,\n",
       " 0.19144237968169536,\n",
       " 0.19625441036256136,\n",
       " 0.19540744841054306,\n",
       " 0.2010494325091784,\n",
       " 0.2100516571274058,\n",
       " 0.21722514094651538,\n",
       " 0.23089838465568097,\n",
       " 0.22033259433512759,\n",
       " 0.22481060952254125,\n",
       " 0.2364160061460449,\n",
       " 0.2522548999120726,\n",
       " 0.2501613205917494,\n",
       " 0.24542853008660054,\n",
       " 0.2336142860378907,\n",
       " 0.2185448134249856,\n",
       " 0.2139356569623583,\n",
       " 0.18557082088211846,\n",
       " 0.4363822183611017,\n",
       " 0.44726272769468556]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnls_brier = []\n",
    "for j in S : \n",
    "    value = brier_score_loss(y_true = stack_tst[stack_tst['LM'] == j][E_col], \n",
    "                             y_prob = res_nnls[stack_tst['LM'] == j], \n",
    "                             sample_weight= weight_brier[stack_tst['LM'] == j])        \n",
    "    \n",
    "    nnls_brier.append(value)\n",
    "    \n",
    "nnls_brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9fff7c4d-951e-4073-b14a-d78f5e3eaab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1827812871320524,\n",
       " 0.18230672607057283,\n",
       " 0.17529878683390304,\n",
       " 0.17974516376122437,\n",
       " 0.18349408491636887,\n",
       " 0.18559152496343614,\n",
       " 0.19372447296432999,\n",
       " 0.1987711809731614,\n",
       " 0.2147114867319932,\n",
       " 0.20351943303574496,\n",
       " 0.2109794885236613,\n",
       " 0.22056631839946958,\n",
       " 0.2352457415187923,\n",
       " 0.23556496393492193,\n",
       " 0.23013492005163297,\n",
       " 0.22199903978095875,\n",
       " 0.20577546098683178,\n",
       " 0.21560842441978026,\n",
       " 0.20449148335844267,\n",
       " 0.36464514706850254,\n",
       " 0.3910870017468162]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hill_brier = []\n",
    "for j in S : \n",
    "    value = brier_score_loss(y_true = stack_tst[stack_tst['LM'] == j][E_col], \n",
    "                             y_prob = res_hill[stack_tst['LM'] == j], \n",
    "                             sample_weight= weight_brier[stack_tst['LM'] == j])        \n",
    "    \n",
    "    hill_brier.append(value)\n",
    "    \n",
    "hill_brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8cf571c9-740e-4d42-850a-b3deb10ee34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.23577216524902067,\n",
       " 0.18155086834976822,\n",
       " 0.16226859697306387,\n",
       " 0.17674065571745382,\n",
       " 0.18260326139531516,\n",
       " 0.1977451777452153,\n",
       " 0.23603166777445408,\n",
       " 0.2563542735723729,\n",
       " 0.23810492283110812,\n",
       " 0.1878733542044543,\n",
       " 0.32215979410157775,\n",
       " 0.2010897204312707,\n",
       " 0.35819839234822826,\n",
       " 0.5004989083092963,\n",
       " 0.487359209862588,\n",
       " 0.20120073959511264,\n",
       " 0.21507665267063758,\n",
       " 0.5507274680207012,\n",
       " 0.538961038961039,\n",
       " 0.6764705882352942,\n",
       " 0.5217391304347826]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_brier = []\n",
    "for j in S : \n",
    "    value = brier_score_loss(y_true = stack_tst[stack_tst['LM'] == j][E_col], \n",
    "                             y_prob = res_rf[stack_tst['LM'] == j], \n",
    "                             sample_weight= weight_brier[stack_tst['LM'] == j])        \n",
    "    \n",
    "    rf_brier.append(value)\n",
    "    \n",
    "rf_brier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f861bb4-7519-479e-9f41-f1f4bea4c79c",
   "metadata": {},
   "source": [
    "# 4. Full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6c58fb4-0159-4d7a-ba38-091f812a800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################\n",
    "\n",
    "# settings \n",
    "dir = \"/Users/pio/Google 드라이브/data/\"\n",
    "file_name = \"pbc2.csv\"\n",
    "data = pd.read_csv(dir + file_name)\n",
    "\n",
    "# drop status1 - competing risks setting\n",
    "data = data.drop(axis=1, columns =['status'])\n",
    "\n",
    "\n",
    "# ID, Time, Event, Measure Time column names\n",
    "ID_col = 'id'; T_col ='years'; E_col ='status2'; measure_T_col = 'year'\n",
    "\n",
    "# categorical variables\n",
    "nominal_col = ['drug','sex', 'ascites', 'hepatomegaly','spiders', 'edema']\n",
    "ordinal_col = ['histologic']\n",
    "\n",
    "# continuous variables\n",
    "cont_col = list(set(data.columns) - set(nominal_col) - set(ordinal_col) - set([ID_col, T_col, E_col, measure_T_col]))\n",
    "\n",
    "# window - 5 year prediction \n",
    "window = 5\n",
    "\n",
    "# S : landmark time points - 0, 0.5, 1, ..., 10\n",
    "S = np.linspace(0,10,21)\n",
    "v_years = S+window\n",
    "\n",
    "# Number of bins when discritizing \n",
    "## !!!(Actually, k_bin - 1 bins are produced)!!!\n",
    "k_bin = 5\n",
    "\n",
    "# minimal bin_size\n",
    "minimal_bin_size = window / (k_bin-1)\n",
    "\n",
    "# \n",
    "\n",
    "# for continous variables, \n",
    "## scaling -> min-max scaling &\n",
    "## imputation -> fill na's : median for continous\n",
    "for col in cont_col : \n",
    "    data[col] = data[col].fillna(data[col].median())\n",
    "    data[col] = (data[col] - min(data[col])) / (max(data[col]) - min(data[col]))\n",
    "\n",
    "# one-hot encoding for categorical variables\n",
    "data = pd.get_dummies(data, columns = nominal_col, drop_first=True)\n",
    "\n",
    "\n",
    "####################################################################################################################################\n",
    "# settings2\n",
    "\n",
    "# proportion of train set\n",
    "p_train = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cf36144-e0ad-4882-a1b4-ecb2b3a509e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data_lm_cont = landmarker_cont(data=data, ID_col = ID_col, T_col = T_col, E_col = E_col, \n",
    "                window = window, S= S, measure_T_col = measure_T_col)\n",
    "\n",
    "data_lm_disc = landmarker_disc(data=data_lm_cont,ID_col = ID_col, T_col = T_col, E_col = E_col, \n",
    "                window = window, S= S, measure_T_col = measure_T_col, k_bin = k_bin, train=True)\n",
    "\n",
    "# Split IDs into train set and test set\n",
    "train_id, test_id = id_train_test_split(id_list = data[ID_col], seed_number = 1, p=0.7)\n",
    "\n",
    "# Train, test set from original form\n",
    "train = data[data[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test = data[data[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "# Train, test set for continous landmarking algorithms\n",
    "train_lm_cont = data_lm_cont[data_lm_cont[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test_lm_cont = data_lm_cont[data_lm_cont[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "# Train, test set for discrete landmarking algorithms\n",
    "train_lm_disc = data_lm_disc[data_lm_disc[ID_col].isin(train_id)].reset_index(drop=True)\n",
    "test_lm_disc = data_lm_disc[data_lm_disc[ID_col].isin(test_id)].reset_index(drop=True)\n",
    "\n",
    "print(np.all(np.unique(train_lm_cont.id) == np.unique(train_lm_disc.id)))\n",
    "print(np.all(np.unique(test_lm_cont.id) == np.unique(test_lm_disc.id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "833e2e32-68e7-4615-8b16-b64de1e51fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_instance</th>\n",
       "      <th>hyperparams</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cox_str</td>\n",
       "      <td>&lt;lifelines.CoxPHFitter&gt;</td>\n",
       "      <td>{'penalizer': [0.006737946999085467, 0.0301973...</td>\n",
       "      <td>cox_str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cox_no_str</td>\n",
       "      <td>&lt;lifelines.CoxPHFitter&gt;</td>\n",
       "      <td>{'penalizer': [0.006737946999085467, 0.0301973...</td>\n",
       "      <td>cox_no_str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(max_iter=10000)</td>\n",
       "      <td>{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'p...</td>\n",
       "      <td>lr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>{'n_estimators': [50, 100, 300, 500], 'max_dep...</td>\n",
       "      <td>rf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GB</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>{'n_estimators': [50, 100, 300, 500], 'max_dep...</td>\n",
       "      <td>gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>MLPClassifier()</td>\n",
       "      <td>{'hidden_layer_sizes': [1, 2, 3], 'activation'...</td>\n",
       "      <td>mlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>{'n_neighbors': [1, 5, 10], 'weights': ['unifo...</td>\n",
       "      <td>knn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NGB</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>{'var_smoothing': [1e-05, 1e-09, 0.1]}</td>\n",
       "      <td>ngb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADA</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>{'n_estimators': [50, 100, 300, 500], 'max_dep...</td>\n",
       "      <td>ada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name                      model_instance  \\\n",
       "0     cox_str             <lifelines.CoxPHFitter>   \n",
       "1  cox_no_str             <lifelines.CoxPHFitter>   \n",
       "2          LR  LogisticRegression(max_iter=10000)   \n",
       "3          RF            RandomForestClassifier()   \n",
       "4          GB        GradientBoostingClassifier()   \n",
       "5         MLP                     MLPClassifier()   \n",
       "6         KNN              KNeighborsClassifier()   \n",
       "7         NGB                        GaussianNB()   \n",
       "8         ADA                AdaBoostClassifier()   \n",
       "\n",
       "                                         hyperparams        type  \n",
       "0  {'penalizer': [0.006737946999085467, 0.0301973...     cox_str  \n",
       "1  {'penalizer': [0.006737946999085467, 0.0301973...  cox_no_str  \n",
       "2  {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'p...          lr  \n",
       "3  {'n_estimators': [50, 100, 300, 500], 'max_dep...          rf  \n",
       "4  {'n_estimators': [50, 100, 300, 500], 'max_dep...          gb  \n",
       "5  {'hidden_layer_sizes': [1, 2, 3], 'activation'...         mlp  \n",
       "6  {'n_neighbors': [1, 5, 10], 'weights': ['unifo...         knn  \n",
       "7             {'var_smoothing': [1e-05, 1e-09, 0.1]}         ngb  \n",
       "8  {'n_estimators': [50, 100, 300, 500], 'max_dep...         ada  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## model specifics of level 0 models\n",
    "cox_params = {'penalizer':np.exp(np.linspace(-5,1,5)),'l1_ratio':[0,0.25,0.5,0.75,1]}\n",
    "# 5*5 *2 = 50\n",
    "model_specifics_cont = pd.DataFrame({'model_name' : ['cox_str', 'cox_no_str'], \n",
    "                                'model_instance':[CoxPHFitter(),CoxPHFitter()], \n",
    "                                'hyperparams':[cox_params,cox_params], \n",
    "                                'type':['cox_str','cox_no_str']})\n",
    "\n",
    "LR_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['saga']\n",
    "} # 7 * 2 * 1 = 14\n",
    "RF_params = {'n_estimators':[50,100,300,500],'max_depth':[1,3,5]} # 4*3 = 12\n",
    "GB_params = {'n_estimators':[50,100,300,500],'max_depth':[1,3,5]} # 4*3 = 12\n",
    "MLP_params = {'hidden_layer_sizes':[1,2,3], 'activation' : ['identity', 'logistic', 'tanh', 'relu'], 'max_iter' : [1000], 'early_stopping' : [True], 'learning_rate' : ['adaptive']}\n",
    "# 3*4\n",
    "KNN_params = {'n_neighbors':[1,5,10], 'weights':['uniform', 'distance']} \n",
    "# 3*2\n",
    "NGB_params = {'var_smoothing':[1e-5, 1e-9, 1e-1]}\n",
    "# 3\n",
    "ADA_params = {'n_estimators':[50, 100, 300, 500], 'max_depth':[1,3,5]}\n",
    "# 4*10*3 = 36\n",
    "\n",
    "model_specifics_disc = pd.DataFrame({'model_name' : ['LR','RF','GB','MLP','KNN','NGB','ADA'], \n",
    "                                'model_instance':[LogisticRegression(max_iter=10000),RandomForestClassifier(),GradientBoostingClassifier(),MLPClassifier(),KNeighborsClassifier(),GaussianNB(), AdaBoostClassifier()], \n",
    "                                'hyperparams':[LR_params, RF_params, GB_params,MLP_params, KNN_params,NGB_params, ADA_params], \n",
    "                                'type':['lr','rf','gb','mlp','knn','ngb','ada']})\n",
    "\n",
    "\n",
    "model_specifics = pd.concat([model_specifics_cont,model_specifics_disc],axis=0).reset_index(drop=True)\n",
    "model_specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babdfcd4-af61-40f8-8b39-53b14608eae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f1edf25-50d4-4292-9a7a-034f3c81110c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset for training meta model\n",
      "fold : 0\n",
      "fold : 1\n",
      "fold : 2\n",
      "Re-train baseline models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.LM_cox_fitter at 0x7febde9669b0>,\n",
       " <__main__.LM_cox_fitter at 0x7febf8cd6080>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa571470>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa580780>,\n",
       " <__main__.LM_cox_fitter at 0x7febde966828>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa620898>,\n",
       " <__main__.LM_cox_fitter at 0x7febf793fd68>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa554a58>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9f6f98>,\n",
       " <__main__.LM_cox_fitter at 0x7febe37b0a90>,\n",
       " <__main__.LM_cox_fitter at 0x7febe1878be0>,\n",
       " <__main__.LM_cox_fitter at 0x7febdedacb38>,\n",
       " <__main__.LM_cox_fitter at 0x7febf7a38cc0>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9d25f8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe1568198>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9631d0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe379fe80>,\n",
       " <__main__.LM_cox_fitter at 0x7febe37a55f8>,\n",
       " <__main__.LM_cox_fitter at 0x7febdeda12e8>,\n",
       " <__main__.LM_cox_fitter at 0x7febdeda1550>,\n",
       " <__main__.LM_cox_fitter at 0x7febe160ecc0>,\n",
       " <__main__.LM_cox_fitter at 0x7febdef8f6a0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a4ba20>,\n",
       " <__main__.LM_cox_fitter at 0x7febe37b9860>,\n",
       " <__main__.LM_cox_fitter at 0x7febe00e6908>,\n",
       " <__main__.LM_cox_fitter at 0x7febf7267470>,\n",
       " <__main__.LM_cox_fitter at 0x7febf6be9550>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9f1710>,\n",
       " <__main__.LM_cox_fitter at 0x7febfa5713c8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a760f0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe15a4940>,\n",
       " <__main__.LM_cox_fitter at 0x7febe15a4c50>,\n",
       " <__main__.LM_cox_fitter at 0x7febdefa4cf8>,\n",
       " <__main__.LM_cox_fitter at 0x7febdea69be0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a91400>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a93550>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a6bc88>,\n",
       " <__main__.LM_cox_fitter at 0x7febdea4a518>,\n",
       " <__main__.LM_cox_fitter at 0x7febdea3ce80>,\n",
       " <__main__.LM_cox_fitter at 0x7febdea3c978>,\n",
       " <__main__.LM_cox_fitter at 0x7febdefb0978>,\n",
       " <__main__.LM_cox_fitter at 0x7febdefb07b8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe0a7bcc0>,\n",
       " <__main__.LM_cox_fitter at 0x7febe34aaeb8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe34aaa90>,\n",
       " <__main__.LM_cox_fitter at 0x7febe1576dd8>,\n",
       " <__main__.LM_cox_fitter at 0x7febe34aa080>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9ead30>,\n",
       " <__main__.LM_cox_fitter at 0x7febe15760f0>,\n",
       " <__main__.LM_cox_fitter at 0x7febde9cf240>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf8cbf668>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe0a76ba8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf14e470>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf8cbf518>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febfa63fba8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf1d59198>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf14e5f8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf14e438>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4e978>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4ec88>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4ef98>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4e5c0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d7d68>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d77b8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37b97b8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febde9c0278>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe0a93e48>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d7438>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf128908>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37922b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe3792b38>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d7208>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe3792cf8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf7a2de80>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe0a76128>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00d71d0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf7972a20>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37927b8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded986a0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdea456a0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdea422b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdea4f9b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe01070f0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe01037f0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe00ecb70>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf1d2ef0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15942b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded5d2b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4e2e8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe3792240>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe0a615f8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf128c88>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf11c1d0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded98dd8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded98160>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febfa59fc50>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4978>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37c2fd0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4ba8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe37929e8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febde956fd0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded98fd0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4390>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4400>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febded4e358>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdea46908>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febf7a2ddd8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4518>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4f98>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe155a2b0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15e4320>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe1602cf8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15f38d0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe15ef4a8>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe1606b70>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdefb7278>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdefb17f0>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdef8eb38>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf10ae80>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febdf12e208>,\n",
       " <__main__.LM_sklearn_fitter at 0x7febe188d1d0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "total_n = 0\n",
    "for g_1 in range(model_specifics.shape[0]) : \n",
    "    model_hyperparams = model_specifics.loc[g_1,'hyperparams']\n",
    "    n_param_combinations = len(list(itertools.product(*list(model_hyperparams.values()))))\n",
    "    total_n = total_n + n_param_combinations\n",
    "'''\n",
    "\n",
    "#######\n",
    "# 1. Generating dataset faor training meta model part \n",
    "k_kfold = 3\n",
    "\n",
    "kfold = id_kfold(id_list=train_id, n_split=k_kfold,seed_number=1)\n",
    "stacked_trn = []\n",
    "print('Generating dataset for training meta model')\n",
    "for i in range(k_kfold) : \n",
    "    print('fold : ' + str(i))\n",
    "    k_fold_trn_id, k_fold_val_id = next(kfold)\n",
    "    \n",
    "    k_fold_trn_lm_cont = train_lm_cont[train_lm_cont[ID_col].isin(k_fold_trn_id)].copy()\n",
    "    k_fold_trn_lm_disc = train_lm_disc[train_lm_disc[ID_col].isin(k_fold_trn_id)].copy()\n",
    "    \n",
    "    k_fold_val_lm_cont = train_lm_cont[train_lm_cont[ID_col].isin(k_fold_val_id)].copy()\n",
    "    k_fold_val_lm_disc = train_lm_disc[train_lm_disc[ID_col].isin(k_fold_val_id)].copy()\n",
    "    \n",
    "    # fit all baseline models        \n",
    "    stack_fit = stacker(model_specifics = model_specifics, \n",
    "                        ID = ID_col, T = T_col, E = E_col, S = S, window = window, k_bin = k_bin)\n",
    "    stack_fit.fit(data_cont= k_fold_trn_lm_cont , data_disc = k_fold_trn_lm_disc) \n",
    "    \n",
    "    # stack them for training meta model\n",
    "    stacked_trn.append(stack_fit.predict(k_fold_val_lm_cont, k_fold_val_lm_disc))\n",
    "    \n",
    "# ID_col, LM, T_col, E_col validation 순서에 맞게 모으기\n",
    "info = pd.concat([train_lm_cont[train_lm_cont[ID_col].isin(kfold.validation_fold_id[i])][[ID_col, 'LM', T_col, E_col]].reset_index(drop=True) for i in range(len(stacked_trn))], ignore_index=True)\n",
    "# kfold validation 예측 결과 모으기\n",
    "pred = b = pd.concat([pd.DataFrame(stacked_trn[i]) for i in range(len(stacked_trn))], ignore_index=True)\n",
    "new_data = pd.concat([info,pred], axis=1)\n",
    "# new_data['surv_status'] = abs(new_data[E_col]-1)\n",
    "######\n",
    "# 2. Training Part : \n",
    "# 2-1. (Re-)train baseline models on whole dataset  \n",
    "print('Re-train baseline models')\n",
    "stack_fit = stacker(model_specifics = model_specifics, \n",
    "                        ID = ID_col, T = T_col, E = E_col, S = S, window = window, k_bin = k_bin)\n",
    "\n",
    "stack_fit.fit(data_cont=train_lm_cont.copy() , data_disc = train_lm_disc.copy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "20dd41fe-e8df-4107-9ca0-2fa3208db8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### \n",
    "# 2-2-1. calculating ipcw weights\n",
    "ipcw_calc = ipcw_fitter(S= S, window =window)\n",
    "ipcw_calc.fit(data= new_data, T = T_col, E = E_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7829c352-352f-48c1-99a5-5261b0999f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####\n",
    "# 2-2-2. Train meta model \n",
    "## NOTE : 생존확률의 결합이므로 라벨을 뒤집어줘야 함.\n",
    "nnls = nnls_constraintnnls = nnls_constraint()\n",
    "nnls.fit(x = new_data.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = abs(new_data[E_col]-1), # 생존확률의 결합이므로 라벨을 뒤집어줘야 함.\n",
    "         w = ipcw_calc.predict(new_data))\n",
    "\n",
    "\n",
    "hill = hillclimb()\n",
    "hill.fit(x = new_data.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "         y = abs(new_data[E_col]-1), # 생존확률의 결합이므로 라벨을 뒤집어줘야 함.\n",
    "         w = ipcw_calc.predict(new_data))\n",
    "\n",
    "\n",
    "ipcw_rf = RandomForestClassifier()\n",
    "ipcw_rf.fit(X = new_data.drop([ID_col, 'LM', E_col, T_col], axis=1), \n",
    "            y = abs(new_data[E_col]-1), sample_weight = ipcw_calc.predict(new_data)) # 생존확률의 결합이므로 라벨을 뒤집어줘야 함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77e0d300-320d-467c-aeec-20a094bdd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 3. Prediction Part : \n",
    "# 3-1. predict(stack) on test set(baseline models)\n",
    "baseline_pred = stack_fit.predict(data_cont=test_lm_cont , data_disc = test_lm_disc) \n",
    "# 3-2. predict from baseline models -> meta model \n",
    "nnls_pred = nnls.predict(baseline_pred)\n",
    "hill_pred = hill.predict(baseline_pred)\n",
    "rf_pred = ipcw_rf.predict_proba(baseline_pred)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed57c503-d81c-4c20-bc1a-1ad2372ad101",
   "metadata": {},
   "source": [
    "## Brier Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e602232d-c73f-44bc-b86a-4b96982452c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.128830</td>\n",
       "      <td>0.127992</td>\n",
       "      <td>0.118726</td>\n",
       "      <td>0.121073</td>\n",
       "      <td>0.129872</td>\n",
       "      <td>0.125825</td>\n",
       "      <td>0.143405</td>\n",
       "      <td>0.148971</td>\n",
       "      <td>0.170613</td>\n",
       "      <td>0.138813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198101</td>\n",
       "      <td>0.236531</td>\n",
       "      <td>0.235390</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.217294</td>\n",
       "      <td>0.252656</td>\n",
       "      <td>0.165098</td>\n",
       "      <td>0.207704</td>\n",
       "      <td>0.413091</td>\n",
       "      <td>0.204060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.150793</td>\n",
       "      <td>0.148571</td>\n",
       "      <td>0.138203</td>\n",
       "      <td>0.144119</td>\n",
       "      <td>0.150309</td>\n",
       "      <td>0.153155</td>\n",
       "      <td>0.166712</td>\n",
       "      <td>0.177205</td>\n",
       "      <td>0.196732</td>\n",
       "      <td>0.170339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203971</td>\n",
       "      <td>0.236841</td>\n",
       "      <td>0.229373</td>\n",
       "      <td>0.218389</td>\n",
       "      <td>0.216171</td>\n",
       "      <td>0.219378</td>\n",
       "      <td>0.186594</td>\n",
       "      <td>0.209407</td>\n",
       "      <td>0.401551</td>\n",
       "      <td>0.293040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.178749</td>\n",
       "      <td>0.171786</td>\n",
       "      <td>0.156821</td>\n",
       "      <td>0.163722</td>\n",
       "      <td>0.169222</td>\n",
       "      <td>0.171404</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.195081</td>\n",
       "      <td>0.217322</td>\n",
       "      <td>0.196213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221653</td>\n",
       "      <td>0.241622</td>\n",
       "      <td>0.231471</td>\n",
       "      <td>0.230134</td>\n",
       "      <td>0.225353</td>\n",
       "      <td>0.214348</td>\n",
       "      <td>0.208362</td>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.433413</td>\n",
       "      <td>0.398673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.194662</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.172645</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>0.185264</td>\n",
       "      <td>0.184918</td>\n",
       "      <td>0.196313</td>\n",
       "      <td>0.209626</td>\n",
       "      <td>0.233869</td>\n",
       "      <td>0.214779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234414</td>\n",
       "      <td>0.249615</td>\n",
       "      <td>0.243414</td>\n",
       "      <td>0.242306</td>\n",
       "      <td>0.233050</td>\n",
       "      <td>0.219496</td>\n",
       "      <td>0.208842</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>0.451029</td>\n",
       "      <td>0.473576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.194662</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.172645</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>0.185264</td>\n",
       "      <td>0.184918</td>\n",
       "      <td>0.196313</td>\n",
       "      <td>0.209626</td>\n",
       "      <td>0.233869</td>\n",
       "      <td>0.214779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234414</td>\n",
       "      <td>0.249615</td>\n",
       "      <td>0.243414</td>\n",
       "      <td>0.242306</td>\n",
       "      <td>0.233050</td>\n",
       "      <td>0.219496</td>\n",
       "      <td>0.208842</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>0.451029</td>\n",
       "      <td>0.473575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.163155</td>\n",
       "      <td>0.158840</td>\n",
       "      <td>0.146996</td>\n",
       "      <td>0.151665</td>\n",
       "      <td>0.157261</td>\n",
       "      <td>0.154408</td>\n",
       "      <td>0.169332</td>\n",
       "      <td>0.179154</td>\n",
       "      <td>0.200961</td>\n",
       "      <td>0.174173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208623</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.229504</td>\n",
       "      <td>0.220924</td>\n",
       "      <td>0.219289</td>\n",
       "      <td>0.227049</td>\n",
       "      <td>0.173709</td>\n",
       "      <td>0.193486</td>\n",
       "      <td>0.400236</td>\n",
       "      <td>0.266321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.194662</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.172645</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>0.185264</td>\n",
       "      <td>0.184918</td>\n",
       "      <td>0.196313</td>\n",
       "      <td>0.209626</td>\n",
       "      <td>0.233869</td>\n",
       "      <td>0.214779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234414</td>\n",
       "      <td>0.249615</td>\n",
       "      <td>0.243414</td>\n",
       "      <td>0.242306</td>\n",
       "      <td>0.233050</td>\n",
       "      <td>0.219496</td>\n",
       "      <td>0.208842</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>0.451029</td>\n",
       "      <td>0.473575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.194662</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.172645</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>0.185264</td>\n",
       "      <td>0.184918</td>\n",
       "      <td>0.196313</td>\n",
       "      <td>0.209626</td>\n",
       "      <td>0.233869</td>\n",
       "      <td>0.214779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234414</td>\n",
       "      <td>0.249615</td>\n",
       "      <td>0.243414</td>\n",
       "      <td>0.242306</td>\n",
       "      <td>0.233050</td>\n",
       "      <td>0.219496</td>\n",
       "      <td>0.208842</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>0.451029</td>\n",
       "      <td>0.473575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.194662</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.172645</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>0.185264</td>\n",
       "      <td>0.184918</td>\n",
       "      <td>0.196313</td>\n",
       "      <td>0.209626</td>\n",
       "      <td>0.233869</td>\n",
       "      <td>0.214779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234414</td>\n",
       "      <td>0.249615</td>\n",
       "      <td>0.243414</td>\n",
       "      <td>0.242306</td>\n",
       "      <td>0.233050</td>\n",
       "      <td>0.219496</td>\n",
       "      <td>0.208842</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>0.451029</td>\n",
       "      <td>0.473575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.194662</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.172645</td>\n",
       "      <td>0.180108</td>\n",
       "      <td>0.185264</td>\n",
       "      <td>0.184918</td>\n",
       "      <td>0.196313</td>\n",
       "      <td>0.209626</td>\n",
       "      <td>0.233869</td>\n",
       "      <td>0.214779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234414</td>\n",
       "      <td>0.249615</td>\n",
       "      <td>0.243414</td>\n",
       "      <td>0.242306</td>\n",
       "      <td>0.233050</td>\n",
       "      <td>0.219496</td>\n",
       "      <td>0.208842</td>\n",
       "      <td>0.201767</td>\n",
       "      <td>0.451029</td>\n",
       "      <td>0.473575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.194355</td>\n",
       "      <td>0.189322</td>\n",
       "      <td>0.171370</td>\n",
       "      <td>0.178322</td>\n",
       "      <td>0.178693</td>\n",
       "      <td>0.184371</td>\n",
       "      <td>0.196938</td>\n",
       "      <td>0.208984</td>\n",
       "      <td>0.230193</td>\n",
       "      <td>0.214545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239613</td>\n",
       "      <td>0.263111</td>\n",
       "      <td>0.258003</td>\n",
       "      <td>0.252001</td>\n",
       "      <td>0.238267</td>\n",
       "      <td>0.220348</td>\n",
       "      <td>0.208775</td>\n",
       "      <td>0.177433</td>\n",
       "      <td>0.498094</td>\n",
       "      <td>0.498094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.170215</td>\n",
       "      <td>0.164194</td>\n",
       "      <td>0.153358</td>\n",
       "      <td>0.159825</td>\n",
       "      <td>0.162326</td>\n",
       "      <td>0.167673</td>\n",
       "      <td>0.178210</td>\n",
       "      <td>0.190755</td>\n",
       "      <td>0.210498</td>\n",
       "      <td>0.195156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219120</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.234280</td>\n",
       "      <td>0.221801</td>\n",
       "      <td>0.209147</td>\n",
       "      <td>0.212068</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>0.423436</td>\n",
       "      <td>0.404619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.165747</td>\n",
       "      <td>0.156142</td>\n",
       "      <td>0.149591</td>\n",
       "      <td>0.155305</td>\n",
       "      <td>0.158747</td>\n",
       "      <td>0.164318</td>\n",
       "      <td>0.168215</td>\n",
       "      <td>0.183642</td>\n",
       "      <td>0.200599</td>\n",
       "      <td>0.180733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205818</td>\n",
       "      <td>0.241110</td>\n",
       "      <td>0.242226</td>\n",
       "      <td>0.224031</td>\n",
       "      <td>0.212559</td>\n",
       "      <td>0.202540</td>\n",
       "      <td>0.229328</td>\n",
       "      <td>0.202455</td>\n",
       "      <td>0.416717</td>\n",
       "      <td>0.397779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.129004</td>\n",
       "      <td>0.124238</td>\n",
       "      <td>0.124487</td>\n",
       "      <td>0.129580</td>\n",
       "      <td>0.134219</td>\n",
       "      <td>0.137023</td>\n",
       "      <td>0.147482</td>\n",
       "      <td>0.152659</td>\n",
       "      <td>0.173346</td>\n",
       "      <td>0.156367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182124</td>\n",
       "      <td>0.227181</td>\n",
       "      <td>0.236529</td>\n",
       "      <td>0.218558</td>\n",
       "      <td>0.204655</td>\n",
       "      <td>0.207860</td>\n",
       "      <td>0.210443</td>\n",
       "      <td>0.191292</td>\n",
       "      <td>0.363283</td>\n",
       "      <td>0.308275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.101948</td>\n",
       "      <td>0.104714</td>\n",
       "      <td>0.100224</td>\n",
       "      <td>0.102098</td>\n",
       "      <td>0.111641</td>\n",
       "      <td>0.117238</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.132438</td>\n",
       "      <td>0.157122</td>\n",
       "      <td>0.136426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169450</td>\n",
       "      <td>0.223381</td>\n",
       "      <td>0.232963</td>\n",
       "      <td>0.208126</td>\n",
       "      <td>0.200375</td>\n",
       "      <td>0.233497</td>\n",
       "      <td>0.180277</td>\n",
       "      <td>0.183632</td>\n",
       "      <td>0.359644</td>\n",
       "      <td>0.205340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.105478</td>\n",
       "      <td>0.106666</td>\n",
       "      <td>0.105458</td>\n",
       "      <td>0.108459</td>\n",
       "      <td>0.117684</td>\n",
       "      <td>0.117153</td>\n",
       "      <td>0.125460</td>\n",
       "      <td>0.130169</td>\n",
       "      <td>0.157623</td>\n",
       "      <td>0.136275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174428</td>\n",
       "      <td>0.223987</td>\n",
       "      <td>0.241597</td>\n",
       "      <td>0.213183</td>\n",
       "      <td>0.201934</td>\n",
       "      <td>0.247410</td>\n",
       "      <td>0.187330</td>\n",
       "      <td>0.190953</td>\n",
       "      <td>0.356926</td>\n",
       "      <td>0.261624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.115069</td>\n",
       "      <td>0.117782</td>\n",
       "      <td>0.094159</td>\n",
       "      <td>0.103272</td>\n",
       "      <td>0.112277</td>\n",
       "      <td>0.117048</td>\n",
       "      <td>0.128633</td>\n",
       "      <td>0.136184</td>\n",
       "      <td>0.161319</td>\n",
       "      <td>0.136047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200380</td>\n",
       "      <td>0.251329</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.224820</td>\n",
       "      <td>0.218704</td>\n",
       "      <td>0.249330</td>\n",
       "      <td>0.183085</td>\n",
       "      <td>0.207853</td>\n",
       "      <td>0.337159</td>\n",
       "      <td>0.112799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.108781</td>\n",
       "      <td>0.111929</td>\n",
       "      <td>0.098120</td>\n",
       "      <td>0.103157</td>\n",
       "      <td>0.113062</td>\n",
       "      <td>0.115318</td>\n",
       "      <td>0.125409</td>\n",
       "      <td>0.132575</td>\n",
       "      <td>0.160051</td>\n",
       "      <td>0.134350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192446</td>\n",
       "      <td>0.242369</td>\n",
       "      <td>0.249966</td>\n",
       "      <td>0.221229</td>\n",
       "      <td>0.216472</td>\n",
       "      <td>0.260736</td>\n",
       "      <td>0.177192</td>\n",
       "      <td>0.196422</td>\n",
       "      <td>0.335873</td>\n",
       "      <td>0.149301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.115391</td>\n",
       "      <td>0.118139</td>\n",
       "      <td>0.095383</td>\n",
       "      <td>0.103383</td>\n",
       "      <td>0.112254</td>\n",
       "      <td>0.116072</td>\n",
       "      <td>0.128743</td>\n",
       "      <td>0.136579</td>\n",
       "      <td>0.162685</td>\n",
       "      <td>0.136907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203882</td>\n",
       "      <td>0.254537</td>\n",
       "      <td>0.251825</td>\n",
       "      <td>0.226887</td>\n",
       "      <td>0.222954</td>\n",
       "      <td>0.253934</td>\n",
       "      <td>0.179220</td>\n",
       "      <td>0.205629</td>\n",
       "      <td>0.334271</td>\n",
       "      <td>0.104921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.114347</td>\n",
       "      <td>0.117193</td>\n",
       "      <td>0.096004</td>\n",
       "      <td>0.103271</td>\n",
       "      <td>0.112312</td>\n",
       "      <td>0.115842</td>\n",
       "      <td>0.128243</td>\n",
       "      <td>0.135983</td>\n",
       "      <td>0.162427</td>\n",
       "      <td>0.136586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202523</td>\n",
       "      <td>0.253050</td>\n",
       "      <td>0.252082</td>\n",
       "      <td>0.226293</td>\n",
       "      <td>0.222675</td>\n",
       "      <td>0.255960</td>\n",
       "      <td>0.178292</td>\n",
       "      <td>0.203795</td>\n",
       "      <td>0.333690</td>\n",
       "      <td>0.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.115407</td>\n",
       "      <td>0.118154</td>\n",
       "      <td>0.095544</td>\n",
       "      <td>0.103402</td>\n",
       "      <td>0.112254</td>\n",
       "      <td>0.115969</td>\n",
       "      <td>0.128754</td>\n",
       "      <td>0.136615</td>\n",
       "      <td>0.162829</td>\n",
       "      <td>0.137001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204250</td>\n",
       "      <td>0.254881</td>\n",
       "      <td>0.252231</td>\n",
       "      <td>0.227130</td>\n",
       "      <td>0.223418</td>\n",
       "      <td>0.254432</td>\n",
       "      <td>0.178906</td>\n",
       "      <td>0.205412</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.104188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.115295</td>\n",
       "      <td>0.118054</td>\n",
       "      <td>0.095608</td>\n",
       "      <td>0.103388</td>\n",
       "      <td>0.112258</td>\n",
       "      <td>0.115944</td>\n",
       "      <td>0.128701</td>\n",
       "      <td>0.136552</td>\n",
       "      <td>0.162802</td>\n",
       "      <td>0.136967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204102</td>\n",
       "      <td>0.254721</td>\n",
       "      <td>0.252256</td>\n",
       "      <td>0.227064</td>\n",
       "      <td>0.223388</td>\n",
       "      <td>0.254645</td>\n",
       "      <td>0.178797</td>\n",
       "      <td>0.205208</td>\n",
       "      <td>0.333932</td>\n",
       "      <td>0.104687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.115408</td>\n",
       "      <td>0.118155</td>\n",
       "      <td>0.095564</td>\n",
       "      <td>0.103405</td>\n",
       "      <td>0.112255</td>\n",
       "      <td>0.115959</td>\n",
       "      <td>0.128755</td>\n",
       "      <td>0.136618</td>\n",
       "      <td>0.162846</td>\n",
       "      <td>0.137013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204291</td>\n",
       "      <td>0.254917</td>\n",
       "      <td>0.252278</td>\n",
       "      <td>0.227159</td>\n",
       "      <td>0.223471</td>\n",
       "      <td>0.254498</td>\n",
       "      <td>0.178874</td>\n",
       "      <td>0.205386</td>\n",
       "      <td>0.333974</td>\n",
       "      <td>0.104136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.115397</td>\n",
       "      <td>0.118146</td>\n",
       "      <td>0.095567</td>\n",
       "      <td>0.103402</td>\n",
       "      <td>0.112254</td>\n",
       "      <td>0.115956</td>\n",
       "      <td>0.128750</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>0.162841</td>\n",
       "      <td>0.137007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204270</td>\n",
       "      <td>0.254898</td>\n",
       "      <td>0.252273</td>\n",
       "      <td>0.227147</td>\n",
       "      <td>0.223460</td>\n",
       "      <td>0.254502</td>\n",
       "      <td>0.178860</td>\n",
       "      <td>0.205365</td>\n",
       "      <td>0.333960</td>\n",
       "      <td>0.104160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.145761</td>\n",
       "      <td>0.145214</td>\n",
       "      <td>0.135486</td>\n",
       "      <td>0.140397</td>\n",
       "      <td>0.144661</td>\n",
       "      <td>0.148751</td>\n",
       "      <td>0.157935</td>\n",
       "      <td>0.170342</td>\n",
       "      <td>0.187894</td>\n",
       "      <td>0.166260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195436</td>\n",
       "      <td>0.233146</td>\n",
       "      <td>0.233078</td>\n",
       "      <td>0.202906</td>\n",
       "      <td>0.196048</td>\n",
       "      <td>0.221306</td>\n",
       "      <td>0.196932</td>\n",
       "      <td>0.200410</td>\n",
       "      <td>0.338005</td>\n",
       "      <td>0.176776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.115663</td>\n",
       "      <td>0.114342</td>\n",
       "      <td>0.109332</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>0.120786</td>\n",
       "      <td>0.118333</td>\n",
       "      <td>0.127467</td>\n",
       "      <td>0.144138</td>\n",
       "      <td>0.159168</td>\n",
       "      <td>0.138272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167045</td>\n",
       "      <td>0.219357</td>\n",
       "      <td>0.213494</td>\n",
       "      <td>0.173874</td>\n",
       "      <td>0.172513</td>\n",
       "      <td>0.216532</td>\n",
       "      <td>0.225875</td>\n",
       "      <td>0.241006</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.051680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.101098</td>\n",
       "      <td>0.099578</td>\n",
       "      <td>0.100142</td>\n",
       "      <td>0.115303</td>\n",
       "      <td>0.122687</td>\n",
       "      <td>0.109372</td>\n",
       "      <td>0.113462</td>\n",
       "      <td>0.132935</td>\n",
       "      <td>0.159297</td>\n",
       "      <td>0.129588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159142</td>\n",
       "      <td>0.213240</td>\n",
       "      <td>0.206185</td>\n",
       "      <td>0.167641</td>\n",
       "      <td>0.158177</td>\n",
       "      <td>0.226736</td>\n",
       "      <td>0.295740</td>\n",
       "      <td>0.318454</td>\n",
       "      <td>0.158080</td>\n",
       "      <td>0.012669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.144603</td>\n",
       "      <td>0.142675</td>\n",
       "      <td>0.134860</td>\n",
       "      <td>0.142581</td>\n",
       "      <td>0.147107</td>\n",
       "      <td>0.148107</td>\n",
       "      <td>0.156550</td>\n",
       "      <td>0.170555</td>\n",
       "      <td>0.190309</td>\n",
       "      <td>0.167461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>0.240524</td>\n",
       "      <td>0.237117</td>\n",
       "      <td>0.212644</td>\n",
       "      <td>0.210821</td>\n",
       "      <td>0.229187</td>\n",
       "      <td>0.204313</td>\n",
       "      <td>0.205337</td>\n",
       "      <td>0.348561</td>\n",
       "      <td>0.171572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.114984</td>\n",
       "      <td>0.115867</td>\n",
       "      <td>0.111676</td>\n",
       "      <td>0.119774</td>\n",
       "      <td>0.123980</td>\n",
       "      <td>0.124991</td>\n",
       "      <td>0.130147</td>\n",
       "      <td>0.147035</td>\n",
       "      <td>0.164260</td>\n",
       "      <td>0.137296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164309</td>\n",
       "      <td>0.211347</td>\n",
       "      <td>0.201735</td>\n",
       "      <td>0.169862</td>\n",
       "      <td>0.167209</td>\n",
       "      <td>0.192618</td>\n",
       "      <td>0.220977</td>\n",
       "      <td>0.238546</td>\n",
       "      <td>0.227869</td>\n",
       "      <td>0.043138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.104645</td>\n",
       "      <td>0.104506</td>\n",
       "      <td>0.103330</td>\n",
       "      <td>0.112710</td>\n",
       "      <td>0.114568</td>\n",
       "      <td>0.113976</td>\n",
       "      <td>0.118749</td>\n",
       "      <td>0.135161</td>\n",
       "      <td>0.149694</td>\n",
       "      <td>0.130477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159964</td>\n",
       "      <td>0.211572</td>\n",
       "      <td>0.199837</td>\n",
       "      <td>0.164515</td>\n",
       "      <td>0.154683</td>\n",
       "      <td>0.209675</td>\n",
       "      <td>0.238392</td>\n",
       "      <td>0.266042</td>\n",
       "      <td>0.157644</td>\n",
       "      <td>0.012828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "40  0.128830  0.127992  0.118726  0.121073  0.129872  0.125825  0.143405   \n",
       "41  0.150793  0.148571  0.138203  0.144119  0.150309  0.153155  0.166712   \n",
       "42  0.178749  0.171786  0.156821  0.163722  0.169222  0.171404  0.184932   \n",
       "43  0.194662  0.189832  0.172645  0.180108  0.185264  0.184918  0.196313   \n",
       "44  0.194662  0.189832  0.172645  0.180108  0.185264  0.184918  0.196313   \n",
       "45  0.163155  0.158840  0.146996  0.151665  0.157261  0.154408  0.169332   \n",
       "46  0.194662  0.189832  0.172645  0.180108  0.185264  0.184918  0.196313   \n",
       "47  0.194662  0.189832  0.172645  0.180108  0.185264  0.184918  0.196313   \n",
       "48  0.194662  0.189832  0.172645  0.180108  0.185264  0.184918  0.196313   \n",
       "49  0.194662  0.189832  0.172645  0.180108  0.185264  0.184918  0.196313   \n",
       "50  0.194355  0.189322  0.171370  0.178322  0.178693  0.184371  0.196938   \n",
       "51  0.170215  0.164194  0.153358  0.159825  0.162326  0.167673  0.178210   \n",
       "52  0.165747  0.156142  0.149591  0.155305  0.158747  0.164318  0.168215   \n",
       "53  0.129004  0.124238  0.124487  0.129580  0.134219  0.137023  0.147482   \n",
       "54  0.101948  0.104714  0.100224  0.102098  0.111641  0.117238  0.124400   \n",
       "55  0.105478  0.106666  0.105458  0.108459  0.117684  0.117153  0.125460   \n",
       "56  0.115069  0.117782  0.094159  0.103272  0.112277  0.117048  0.128633   \n",
       "57  0.108781  0.111929  0.098120  0.103157  0.113062  0.115318  0.125409   \n",
       "58  0.115391  0.118139  0.095383  0.103383  0.112254  0.116072  0.128743   \n",
       "59  0.114347  0.117193  0.096004  0.103271  0.112312  0.115842  0.128243   \n",
       "60  0.115407  0.118154  0.095544  0.103402  0.112254  0.115969  0.128754   \n",
       "61  0.115295  0.118054  0.095608  0.103388  0.112258  0.115944  0.128701   \n",
       "62  0.115408  0.118155  0.095564  0.103405  0.112255  0.115959  0.128755   \n",
       "63  0.115397  0.118146  0.095567  0.103402  0.112254  0.115956  0.128750   \n",
       "64  0.145761  0.145214  0.135486  0.140397  0.144661  0.148751  0.157935   \n",
       "65  0.115663  0.114342  0.109332  0.118835  0.120786  0.118333  0.127467   \n",
       "66  0.101098  0.099578  0.100142  0.115303  0.122687  0.109372  0.113462   \n",
       "67  0.144603  0.142675  0.134860  0.142581  0.147107  0.148107  0.156550   \n",
       "68  0.114984  0.115867  0.111676  0.119774  0.123980  0.124991  0.130147   \n",
       "69  0.104645  0.104506  0.103330  0.112710  0.114568  0.113976  0.118749   \n",
       "\n",
       "          7         8         9   ...        11        12        13        14  \\\n",
       "40  0.148971  0.170613  0.138813  ...  0.198101  0.236531  0.235390  0.216867   \n",
       "41  0.177205  0.196732  0.170339  ...  0.203971  0.236841  0.229373  0.218389   \n",
       "42  0.195081  0.217322  0.196213  ...  0.221653  0.241622  0.231471  0.230134   \n",
       "43  0.209626  0.233869  0.214779  ...  0.234414  0.249615  0.243414  0.242306   \n",
       "44  0.209626  0.233869  0.214779  ...  0.234414  0.249615  0.243414  0.242306   \n",
       "45  0.179154  0.200961  0.174173  ...  0.208623  0.233590  0.229504  0.220924   \n",
       "46  0.209626  0.233869  0.214779  ...  0.234414  0.249615  0.243414  0.242306   \n",
       "47  0.209626  0.233869  0.214779  ...  0.234414  0.249615  0.243414  0.242306   \n",
       "48  0.209626  0.233869  0.214779  ...  0.234414  0.249615  0.243414  0.242306   \n",
       "49  0.209626  0.233869  0.214779  ...  0.234414  0.249615  0.243414  0.242306   \n",
       "50  0.208984  0.230193  0.214545  ...  0.239613  0.263111  0.258003  0.252001   \n",
       "51  0.190755  0.210498  0.195156  ...  0.219120  0.248659  0.246219  0.234280   \n",
       "52  0.183642  0.200599  0.180733  ...  0.205818  0.241110  0.242226  0.224031   \n",
       "53  0.152659  0.173346  0.156367  ...  0.182124  0.227181  0.236529  0.218558   \n",
       "54  0.132438  0.157122  0.136426  ...  0.169450  0.223381  0.232963  0.208126   \n",
       "55  0.130169  0.157623  0.136275  ...  0.174428  0.223987  0.241597  0.213183   \n",
       "56  0.136184  0.161319  0.136047  ...  0.200380  0.251329  0.248200  0.224820   \n",
       "57  0.132575  0.160051  0.134350  ...  0.192446  0.242369  0.249966  0.221229   \n",
       "58  0.136579  0.162685  0.136907  ...  0.203882  0.254537  0.251825  0.226887   \n",
       "59  0.135983  0.162427  0.136586  ...  0.202523  0.253050  0.252082  0.226293   \n",
       "60  0.136615  0.162829  0.137001  ...  0.204250  0.254881  0.252231  0.227130   \n",
       "61  0.136552  0.162802  0.136967  ...  0.204102  0.254721  0.252256  0.227064   \n",
       "62  0.136618  0.162846  0.137013  ...  0.204291  0.254917  0.252278  0.227159   \n",
       "63  0.136612  0.162841  0.137007  ...  0.204270  0.254898  0.252273  0.227147   \n",
       "64  0.170342  0.187894  0.166260  ...  0.195436  0.233146  0.233078  0.202906   \n",
       "65  0.144138  0.159168  0.138272  ...  0.167045  0.219357  0.213494  0.173874   \n",
       "66  0.132935  0.159297  0.129588  ...  0.159142  0.213240  0.206185  0.167641   \n",
       "67  0.170555  0.190309  0.167461  ...  0.203236  0.240524  0.237117  0.212644   \n",
       "68  0.147035  0.164260  0.137296  ...  0.164309  0.211347  0.201735  0.169862   \n",
       "69  0.135161  0.149694  0.130477  ...  0.159964  0.211572  0.199837  0.164515   \n",
       "\n",
       "          15        16        17        18        19        20  \n",
       "40  0.217294  0.252656  0.165098  0.207704  0.413091  0.204060  \n",
       "41  0.216171  0.219378  0.186594  0.209407  0.401551  0.293040  \n",
       "42  0.225353  0.214348  0.208362  0.219176  0.433413  0.398673  \n",
       "43  0.233050  0.219496  0.208842  0.201767  0.451029  0.473576  \n",
       "44  0.233050  0.219496  0.208842  0.201767  0.451029  0.473575  \n",
       "45  0.219289  0.227049  0.173709  0.193486  0.400236  0.266321  \n",
       "46  0.233050  0.219496  0.208842  0.201767  0.451029  0.473575  \n",
       "47  0.233050  0.219496  0.208842  0.201767  0.451029  0.473575  \n",
       "48  0.233050  0.219496  0.208842  0.201767  0.451029  0.473575  \n",
       "49  0.233050  0.219496  0.208842  0.201767  0.451029  0.473575  \n",
       "50  0.238267  0.220348  0.208775  0.177433  0.498094  0.498094  \n",
       "51  0.221801  0.209147  0.212068  0.185294  0.423436  0.404619  \n",
       "52  0.212559  0.202540  0.229328  0.202455  0.416717  0.397779  \n",
       "53  0.204655  0.207860  0.210443  0.191292  0.363283  0.308275  \n",
       "54  0.200375  0.233497  0.180277  0.183632  0.359644  0.205340  \n",
       "55  0.201934  0.247410  0.187330  0.190953  0.356926  0.261624  \n",
       "56  0.218704  0.249330  0.183085  0.207853  0.337159  0.112799  \n",
       "57  0.216472  0.260736  0.177192  0.196422  0.335873  0.149301  \n",
       "58  0.222954  0.253934  0.179220  0.205629  0.334271  0.104921  \n",
       "59  0.222675  0.255960  0.178292  0.203795  0.333690  0.109800  \n",
       "60  0.223418  0.254432  0.178906  0.205412  0.334000  0.104188  \n",
       "61  0.223388  0.254645  0.178797  0.205208  0.333932  0.104687  \n",
       "62  0.223471  0.254498  0.178874  0.205386  0.333974  0.104136  \n",
       "63  0.223460  0.254502  0.178860  0.205365  0.333960  0.104160  \n",
       "64  0.196048  0.221306  0.196932  0.200410  0.338005  0.176776  \n",
       "65  0.172513  0.216532  0.225875  0.241006  0.267442  0.051680  \n",
       "66  0.158177  0.226736  0.295740  0.318454  0.158080  0.012669  \n",
       "67  0.210821  0.229187  0.204313  0.205337  0.348561  0.171572  \n",
       "68  0.167209  0.192618  0.220977  0.238546  0.227869  0.043138  \n",
       "69  0.154683  0.209675  0.238392  0.266042  0.157644  0.012828  \n",
       "\n",
       "[30 rows x 21 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ipcw_calc = ipcw_fitter(S= S, window =window)\n",
    "test_ipcw_calc.fit(data= test_lm_cont, T = T_col, E = E_col)\n",
    "test_ipcw_pred = test_ipcw_calc.predict(data= test_lm_cont)\n",
    "\n",
    "# i for model, j for landmarked time\n",
    "brier_score_list = []\n",
    "for i in range(baseline_pred.shape[1]) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        value = brier_score_loss(y_true = abs(test_lm_cont[E_col]-1)[test_lm_cont['LM'] == j], \n",
    "                         y_prob = pd.DataFrame(baseline_pred)[test_lm_cont['LM'] == j][i], \n",
    "                         sample_weight= test_ipcw_pred[test_lm_cont['LM'] == j])\n",
    "        temp.append(value)        \n",
    "    brier_score_list.append(temp)\n",
    "    \n",
    "pd.DataFrame(brier_score_list).iloc[40:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8141643d-6daa-4aec-94f1-5c968ae40bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.123691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.121054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.123544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.124807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.139030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.149734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.164642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.142257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.175720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.187064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.226977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.228176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.216857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.214052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.240214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.220091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.270736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.303167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.163445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.123691\n",
       "1   0.121054\n",
       "2   0.111176\n",
       "3   0.117647\n",
       "4   0.123544\n",
       "5   0.124807\n",
       "6   0.139030\n",
       "7   0.149734\n",
       "8   0.164642\n",
       "9   0.142257\n",
       "10  0.175720\n",
       "11  0.187064\n",
       "12  0.226977\n",
       "13  0.228176\n",
       "14  0.216857\n",
       "15  0.214052\n",
       "16  0.240214\n",
       "17  0.220091\n",
       "18  0.270736\n",
       "19  0.303167\n",
       "20  0.163445"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_nnls = [ ]\n",
    "for j in S : \n",
    "    value = brier_score_loss(y_true = abs(test_lm_cont[E_col]-1)[test_lm_cont['LM'] == j], \n",
    "                     y_prob = nnls_pred[test_lm_cont['LM'] == j], \n",
    "                     sample_weight= test_ipcw_pred[test_lm_cont['LM'] == j])\n",
    "    brier_nnls.append(value)        \n",
    "\n",
    "pd.DataFrame(brier_nnls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3de2ba-d3fa-426d-822f-71b568b53c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31ab4236-99fa-48e0-81e8-f470a61d82d1",
   "metadata": {},
   "source": [
    "## C-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b1e5be06-a668-4d29-bfd8-3ad9b2a830f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.912042</td>\n",
       "      <td>0.902712</td>\n",
       "      <td>0.911624</td>\n",
       "      <td>0.898618</td>\n",
       "      <td>0.887468</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.879558</td>\n",
       "      <td>0.837460</td>\n",
       "      <td>0.830073</td>\n",
       "      <td>0.817844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740984</td>\n",
       "      <td>0.720635</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.647436</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.873821</td>\n",
       "      <td>0.873408</td>\n",
       "      <td>0.868664</td>\n",
       "      <td>0.866155</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.833149</td>\n",
       "      <td>0.824543</td>\n",
       "      <td>0.821516</td>\n",
       "      <td>0.773234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757377</td>\n",
       "      <td>0.720635</td>\n",
       "      <td>0.687732</td>\n",
       "      <td>0.768559</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.839791</td>\n",
       "      <td>0.854363</td>\n",
       "      <td>0.839172</td>\n",
       "      <td>0.830261</td>\n",
       "      <td>0.838022</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.762431</td>\n",
       "      <td>0.807320</td>\n",
       "      <td>0.795844</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740984</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.702602</td>\n",
       "      <td>0.790393</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.909424</td>\n",
       "      <td>0.903892</td>\n",
       "      <td>0.896497</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.878090</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>0.828848</td>\n",
       "      <td>0.821516</td>\n",
       "      <td>0.817844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.713755</td>\n",
       "      <td>0.790393</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.912042</td>\n",
       "      <td>0.904481</td>\n",
       "      <td>0.898089</td>\n",
       "      <td>0.890169</td>\n",
       "      <td>0.877238</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>0.821313</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.815985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.914136</td>\n",
       "      <td>0.907429</td>\n",
       "      <td>0.906847</td>\n",
       "      <td>0.899386</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.874033</td>\n",
       "      <td>0.826695</td>\n",
       "      <td>0.825183</td>\n",
       "      <td>0.827138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747541</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>0.786026</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.912042</td>\n",
       "      <td>0.904481</td>\n",
       "      <td>0.899682</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.878090</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.866298</td>\n",
       "      <td>0.821313</td>\n",
       "      <td>0.820293</td>\n",
       "      <td>0.817844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.908901</td>\n",
       "      <td>0.902712</td>\n",
       "      <td>0.902866</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.876385</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>0.868508</td>\n",
       "      <td>0.823466</td>\n",
       "      <td>0.821516</td>\n",
       "      <td>0.817844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.908377</td>\n",
       "      <td>0.903302</td>\n",
       "      <td>0.901274</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.875533</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.868508</td>\n",
       "      <td>0.823466</td>\n",
       "      <td>0.821516</td>\n",
       "      <td>0.817844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.908377</td>\n",
       "      <td>0.903302</td>\n",
       "      <td>0.901274</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.874680</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.868508</td>\n",
       "      <td>0.823466</td>\n",
       "      <td>0.821516</td>\n",
       "      <td>0.819703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750820</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.710037</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.854974</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>0.839968</td>\n",
       "      <td>0.831029</td>\n",
       "      <td>0.825234</td>\n",
       "      <td>0.8060</td>\n",
       "      <td>0.769061</td>\n",
       "      <td>0.800861</td>\n",
       "      <td>0.788509</td>\n",
       "      <td>0.762082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>0.602230</td>\n",
       "      <td>0.585153</td>\n",
       "      <td>0.660256</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.757592</td>\n",
       "      <td>0.775059</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0.759217</td>\n",
       "      <td>0.757033</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>0.724862</td>\n",
       "      <td>0.743272</td>\n",
       "      <td>0.722494</td>\n",
       "      <td>0.727695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675410</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.566914</td>\n",
       "      <td>0.572052</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.675258</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.878534</td>\n",
       "      <td>0.884434</td>\n",
       "      <td>0.877389</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>0.841432</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.805525</td>\n",
       "      <td>0.829925</td>\n",
       "      <td>0.816626</td>\n",
       "      <td>0.799257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.758730</td>\n",
       "      <td>0.669145</td>\n",
       "      <td>0.711790</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.923037</td>\n",
       "      <td>0.919222</td>\n",
       "      <td>0.914013</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.890878</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.886188</td>\n",
       "      <td>0.869752</td>\n",
       "      <td>0.861858</td>\n",
       "      <td>0.868030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832787</td>\n",
       "      <td>0.806349</td>\n",
       "      <td>0.754647</td>\n",
       "      <td>0.838428</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.907330</td>\n",
       "      <td>0.904481</td>\n",
       "      <td>0.902866</td>\n",
       "      <td>0.891705</td>\n",
       "      <td>0.879795</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.870718</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.855746</td>\n",
       "      <td>0.866171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.736059</td>\n",
       "      <td>0.807860</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.892670</td>\n",
       "      <td>0.889151</td>\n",
       "      <td>0.917994</td>\n",
       "      <td>0.893241</td>\n",
       "      <td>0.877238</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.855249</td>\n",
       "      <td>0.844995</td>\n",
       "      <td>0.832518</td>\n",
       "      <td>0.834572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744262</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.736059</td>\n",
       "      <td>0.794760</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.902094</td>\n",
       "      <td>0.899175</td>\n",
       "      <td>0.913217</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.875533</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>0.877348</td>\n",
       "      <td>0.848224</td>\n",
       "      <td>0.837408</td>\n",
       "      <td>0.856877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.765079</td>\n",
       "      <td>0.728625</td>\n",
       "      <td>0.790393</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.894241</td>\n",
       "      <td>0.890330</td>\n",
       "      <td>0.917994</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.874680</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.847147</td>\n",
       "      <td>0.832518</td>\n",
       "      <td>0.836431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.724907</td>\n",
       "      <td>0.786026</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.894764</td>\n",
       "      <td>0.890920</td>\n",
       "      <td>0.914013</td>\n",
       "      <td>0.890937</td>\n",
       "      <td>0.875533</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.843918</td>\n",
       "      <td>0.830073</td>\n",
       "      <td>0.840149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.724907</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.685897</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.894241</td>\n",
       "      <td>0.890330</td>\n",
       "      <td>0.916401</td>\n",
       "      <td>0.889401</td>\n",
       "      <td>0.872975</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.844995</td>\n",
       "      <td>0.832518</td>\n",
       "      <td>0.838290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.724907</td>\n",
       "      <td>0.786026</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.894241</td>\n",
       "      <td>0.890330</td>\n",
       "      <td>0.915605</td>\n",
       "      <td>0.889401</td>\n",
       "      <td>0.872975</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.843918</td>\n",
       "      <td>0.831296</td>\n",
       "      <td>0.838290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.724907</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.894241</td>\n",
       "      <td>0.890330</td>\n",
       "      <td>0.916401</td>\n",
       "      <td>0.889401</td>\n",
       "      <td>0.872975</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.844995</td>\n",
       "      <td>0.832518</td>\n",
       "      <td>0.838290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.724907</td>\n",
       "      <td>0.786026</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.894241</td>\n",
       "      <td>0.890330</td>\n",
       "      <td>0.916401</td>\n",
       "      <td>0.889401</td>\n",
       "      <td>0.872975</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.854144</td>\n",
       "      <td>0.844995</td>\n",
       "      <td>0.832518</td>\n",
       "      <td>0.838290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.724907</td>\n",
       "      <td>0.786026</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.649485</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.874346</td>\n",
       "      <td>0.872936</td>\n",
       "      <td>0.843949</td>\n",
       "      <td>0.850614</td>\n",
       "      <td>0.846121</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.847514</td>\n",
       "      <td>0.827772</td>\n",
       "      <td>0.823961</td>\n",
       "      <td>0.796468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.771375</td>\n",
       "      <td>0.825328</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.894241</td>\n",
       "      <td>0.894458</td>\n",
       "      <td>0.880573</td>\n",
       "      <td>0.867127</td>\n",
       "      <td>0.877238</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.892818</td>\n",
       "      <td>0.862217</td>\n",
       "      <td>0.858191</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813115</td>\n",
       "      <td>0.774603</td>\n",
       "      <td>0.743494</td>\n",
       "      <td>0.812227</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.895288</td>\n",
       "      <td>0.900354</td>\n",
       "      <td>0.880573</td>\n",
       "      <td>0.870200</td>\n",
       "      <td>0.861893</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.899448</td>\n",
       "      <td>0.856835</td>\n",
       "      <td>0.856968</td>\n",
       "      <td>0.804833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813115</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.806691</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.867277</td>\n",
       "      <td>0.865861</td>\n",
       "      <td>0.849124</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.807758</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.846961</td>\n",
       "      <td>0.817546</td>\n",
       "      <td>0.816626</td>\n",
       "      <td>0.799257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.685874</td>\n",
       "      <td>0.794760</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.895812</td>\n",
       "      <td>0.892689</td>\n",
       "      <td>0.876592</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.871270</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.877348</td>\n",
       "      <td>0.847147</td>\n",
       "      <td>0.845966</td>\n",
       "      <td>0.815985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816393</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>0.769517</td>\n",
       "      <td>0.838428</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.887958</td>\n",
       "      <td>0.890920</td>\n",
       "      <td>0.878185</td>\n",
       "      <td>0.878648</td>\n",
       "      <td>0.888321</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.895028</td>\n",
       "      <td>0.869752</td>\n",
       "      <td>0.864303</td>\n",
       "      <td>0.830855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.784387</td>\n",
       "      <td>0.838428</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4       5         6   \\\n",
       "40  0.912042  0.902712  0.911624  0.898618  0.887468  0.9120  0.879558   \n",
       "41  0.900000  0.873821  0.873408  0.868664  0.866155  0.8650  0.833149   \n",
       "42  0.839791  0.854363  0.839172  0.830261  0.838022  0.8020  0.762431   \n",
       "43  0.909424  0.903892  0.896497  0.892473  0.878090  0.9030  0.872928   \n",
       "44  0.912042  0.904481  0.898089  0.890169  0.877238  0.9020  0.867403   \n",
       "45  0.914136  0.907429  0.906847  0.899386  0.884058  0.9070  0.874033   \n",
       "46  0.912042  0.904481  0.899682  0.890937  0.878090  0.9030  0.866298   \n",
       "47  0.908901  0.902712  0.902866  0.890937  0.876385  0.9010  0.868508   \n",
       "48  0.908377  0.903302  0.901274  0.890937  0.875533  0.9000  0.868508   \n",
       "49  0.908377  0.903302  0.901274  0.890937  0.874680  0.9000  0.868508   \n",
       "50  0.500000  0.500000  0.500000  0.500000  0.500000  0.5000  0.500000   \n",
       "51  0.854974  0.861439  0.839968  0.831029  0.825234  0.8060  0.769061   \n",
       "52  0.757592  0.775059  0.742038  0.759217  0.757033  0.7405  0.724862   \n",
       "53  0.878534  0.884434  0.877389  0.848694  0.841432  0.8370  0.805525   \n",
       "54  0.923037  0.919222  0.914013  0.904762  0.890878  0.9030  0.886188   \n",
       "55  0.907330  0.904481  0.902866  0.891705  0.879795  0.8900  0.870718   \n",
       "56  0.892670  0.889151  0.917994  0.893241  0.877238  0.8730  0.855249   \n",
       "57  0.902094  0.899175  0.913217  0.892473  0.875533  0.8930  0.877348   \n",
       "58  0.894241  0.890330  0.917994  0.890937  0.874680  0.8720  0.854144   \n",
       "59  0.894764  0.890920  0.914013  0.890937  0.875533  0.8740  0.854144   \n",
       "60  0.894241  0.890330  0.916401  0.889401  0.872975  0.8720  0.854144   \n",
       "61  0.894241  0.890330  0.915605  0.889401  0.872975  0.8720  0.854144   \n",
       "62  0.894241  0.890330  0.916401  0.889401  0.872975  0.8710  0.854144   \n",
       "63  0.894241  0.890330  0.916401  0.889401  0.872975  0.8720  0.854144   \n",
       "64  0.874346  0.872936  0.843949  0.850614  0.846121  0.8740  0.847514   \n",
       "65  0.894241  0.894458  0.880573  0.867127  0.877238  0.9210  0.892818   \n",
       "66  0.895288  0.900354  0.880573  0.870200  0.861893  0.9060  0.899448   \n",
       "67  0.867277  0.865861  0.849124  0.826421  0.807758  0.8705  0.846961   \n",
       "68  0.895812  0.892689  0.876592  0.866359  0.871270  0.9050  0.877348   \n",
       "69  0.887958  0.890920  0.878185  0.878648  0.888321  0.9180  0.895028   \n",
       "\n",
       "          7         8         9   ...        11        12        13        14  \\\n",
       "40  0.837460  0.830073  0.817844  ...  0.740984  0.720635  0.710037  0.777293   \n",
       "41  0.824543  0.821516  0.773234  ...  0.757377  0.720635  0.687732  0.768559   \n",
       "42  0.807320  0.795844  0.706320  ...  0.740984  0.698413  0.702602  0.790393   \n",
       "43  0.828848  0.821516  0.817844  ...  0.750820  0.739683  0.713755  0.790393   \n",
       "44  0.821313  0.820293  0.815985  ...  0.750820  0.736508  0.710037  0.781659   \n",
       "45  0.826695  0.825183  0.827138  ...  0.747541  0.730159  0.706320  0.786026   \n",
       "46  0.821313  0.820293  0.817844  ...  0.750820  0.736508  0.710037  0.781659   \n",
       "47  0.823466  0.821516  0.817844  ...  0.750820  0.739683  0.710037  0.777293   \n",
       "48  0.823466  0.821516  0.817844  ...  0.750820  0.739683  0.710037  0.777293   \n",
       "49  0.823466  0.821516  0.819703  ...  0.750820  0.739683  0.710037  0.777293   \n",
       "50  0.500000  0.500000  0.500000  ...  0.500000  0.500000  0.500000  0.500000   \n",
       "51  0.800861  0.788509  0.762082  ...  0.734426  0.695238  0.602230  0.585153   \n",
       "52  0.743272  0.722494  0.727695  ...  0.675410  0.634921  0.566914  0.572052   \n",
       "53  0.829925  0.816626  0.799257  ...  0.786885  0.758730  0.669145  0.711790   \n",
       "54  0.869752  0.861858  0.868030  ...  0.832787  0.806349  0.754647  0.838428   \n",
       "55  0.867600  0.855746  0.866171  ...  0.800000  0.777778  0.736059  0.807860   \n",
       "56  0.844995  0.832518  0.834572  ...  0.744262  0.742857  0.736059  0.794760   \n",
       "57  0.848224  0.837408  0.856877  ...  0.770492  0.765079  0.728625  0.790393   \n",
       "58  0.847147  0.832518  0.836431  ...  0.737705  0.730159  0.724907  0.786026   \n",
       "59  0.843918  0.830073  0.840149  ...  0.737705  0.730159  0.724907  0.777293   \n",
       "60  0.844995  0.832518  0.838290  ...  0.737705  0.730159  0.724907  0.786026   \n",
       "61  0.843918  0.831296  0.838290  ...  0.737705  0.730159  0.724907  0.781659   \n",
       "62  0.844995  0.832518  0.838290  ...  0.737705  0.730159  0.724907  0.786026   \n",
       "63  0.844995  0.832518  0.838290  ...  0.737705  0.730159  0.724907  0.786026   \n",
       "64  0.827772  0.823961  0.796468  ...  0.811475  0.788889  0.771375  0.825328   \n",
       "65  0.862217  0.858191  0.832714  ...  0.813115  0.774603  0.743494  0.812227   \n",
       "66  0.856835  0.856968  0.804833  ...  0.813115  0.815873  0.806691  0.851528   \n",
       "67  0.817546  0.816626  0.799257  ...  0.754098  0.728571  0.685874  0.794760   \n",
       "68  0.847147  0.845966  0.815985  ...  0.816393  0.796825  0.769517  0.838428   \n",
       "69  0.869752  0.864303  0.830855  ...  0.819672  0.800000  0.784387  0.838428   \n",
       "\n",
       "          15        16        17        18        19        20  \n",
       "40  0.647436  0.618557  0.794521  0.628571  0.800000  0.954545  \n",
       "41  0.615385  0.608247  0.780822  0.628571  0.714286  1.000000  \n",
       "42  0.666667  0.670103  0.780822  0.571429  0.771429  0.954545  \n",
       "43  0.628205  0.608247  0.780822  0.600000  0.685714  0.954545  \n",
       "44  0.628205  0.608247  0.794521  0.600000  0.685714  0.909091  \n",
       "45  0.641026  0.628866  0.794521  0.628571  0.685714  0.863636  \n",
       "46  0.628205  0.608247  0.794521  0.600000  0.685714  0.909091  \n",
       "47  0.634615  0.608247  0.794521  0.600000  0.685714  0.909091  \n",
       "48  0.634615  0.608247  0.794521  0.600000  0.685714  0.909091  \n",
       "49  0.634615  0.608247  0.794521  0.600000  0.685714  0.909091  \n",
       "50  0.500000  0.500000  0.500000  0.500000  0.500000  0.500000  \n",
       "51  0.660256  0.670103  0.808219  0.685714  0.714286  0.863636  \n",
       "52  0.737179  0.675258  0.650685  0.628571  0.628571  0.704545  \n",
       "53  0.730769  0.628866  0.808219  0.685714  0.714286  0.772727  \n",
       "54  0.788462  0.670103  0.808219  0.685714  0.714286  0.909091  \n",
       "55  0.756410  0.690722  0.794521  0.657143  0.714286  0.818182  \n",
       "56  0.705128  0.649485  0.767123  0.600000  0.771429  0.954545  \n",
       "57  0.698718  0.618557  0.794521  0.685714  0.771429  0.954545  \n",
       "58  0.698718  0.649485  0.780822  0.628571  0.800000  0.954545  \n",
       "59  0.685897  0.639175  0.794521  0.657143  0.800000  0.954545  \n",
       "60  0.698718  0.649485  0.780822  0.628571  0.800000  0.954545  \n",
       "61  0.698718  0.649485  0.780822  0.628571  0.800000  0.954545  \n",
       "62  0.698718  0.649485  0.780822  0.628571  0.800000  0.954545  \n",
       "63  0.698718  0.649485  0.780822  0.628571  0.800000  0.954545  \n",
       "64  0.762821  0.690722  0.808219  0.685714  0.771429  1.000000  \n",
       "65  0.743590  0.659794  0.863014  0.742857  0.714286  1.000000  \n",
       "66  0.782051  0.752577  0.863014  0.771429  0.771429  1.000000  \n",
       "67  0.743590  0.659794  0.780822  0.600000  0.657143  1.000000  \n",
       "68  0.762821  0.721649  0.849315  0.742857  0.742857  1.000000  \n",
       "69  0.756410  0.721649  0.863014  0.742857  0.714286  1.000000  \n",
       "\n",
       "[30 rows x 21 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i for model, j for landmarked time\n",
    "c_index_list = []\n",
    "for i in range(baseline_pred.shape[1]) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        c_index_value = concordance_index(event_times = test_lm_cont[test_lm_cont['LM'] == j][T_col], \n",
    "                                          predicted_scores = pd.DataFrame(baseline_pred)[test_lm_cont['LM'] == j][i],\n",
    "                                          event_observed = test_lm_cont[test_lm_cont['LM'] == j][E_col])\n",
    "        temp.append(c_index_value)        \n",
    "    c_index_list.append(temp)\n",
    "    \n",
    "pd.DataFrame(c_index_list).iloc[40:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254e974-5972-4b5f-aa5b-af8b585fd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i for model, j for landmarked time\n",
    "\n",
    "\n",
    "brier_score_list = []\n",
    "for i in range(baseline_pred.shape[1]) : \n",
    "    temp = []\n",
    "    for j in S : \n",
    "        value = brier_score_loss(y_true = abs(test_lm_cont[E_col]-1)[test_lm_cont['LM'] == j], \n",
    "                         y_prob = nnls_pred, \n",
    "                         sample_weight= test_ipcw_pred[test_lm_cont['LM'] == j])\n",
    "        temp.append(value)        \n",
    "    brier_score_list.append(temp)\n",
    "    \n",
    "pd.DataFrame(brier_score_list).iloc[40:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd5693-d46e-454a-9aa0-b8bffea46875",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnls_pred = nnls.predict(baseline_pred)\n",
    "hill_pred = hill.predict(baseline_pred)\n",
    "rf_pred = ipcw_rf.predict_proba(baseline_pred)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cad9e-4e4c-4557-bfb3-ed04443ca11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da292a52-d851-4285-ba71-f277cb7a1b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ccffe8-c179-4fa9-9f56-d6e760856d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48492f45-2519-4c9b-be45-6b2a5c8ac835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63accd27-aa4f-4a25-9045-a8cb4b2a6fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58a66fd8-b115-44f2-b9a5-61a58c24e0ba",
   "metadata": {},
   "source": [
    "1. 트레인용&발리데이션 셋(테스트) 들어옴\n",
    "2. 트레인a용에서 ipcaw, perhaps bagging weight 먼저 피팅해서 발리데이션 셋에 적용\n",
    "3. \n",
    "aaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62529ae7-2ac3-4e59-9d5a-b7dd1b65a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "module_tree = getattr(baseline_model_list[200],'__module__',None)\n",
    "parent = module_tree.split('.')[0] if module_tree else None\n",
    "\n",
    "if parent == lifelines.__name__:\n",
    "    print('yes')\n",
    "else :\n",
    "    print('no')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc5b8fe-e693-4ad8-9b8e-c601baf198e3",
   "metadata": {},
   "source": [
    "# 4. Fitting Part(Bootstrapping models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4c6dd-2f2d-459c-a4a7-ee6e02138eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
